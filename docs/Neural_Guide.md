Client: Jan Kis, [IMC](IMC "wikilink") <Jan.Kis@imc.com>

The NeuralTalk Model Zoo provides pre-trained deep neural net models
that can be used to generate text descriptions of unseen images. In
principle, such sentence generation could be used to assist blind
people, allowing them to point their mobile phone at a scene, upload the
camera image to a server, and receive the predicted text as synthesised
speech. The results are likely to be far less reliable than for images
from the NeuralTalk demo database, so you will probably have to provide
audio or tactile feedback on image quality, prediction confidence, and
guidance to help the user point the phone in a more productive
direction.