Client: Patrick Wollner <patrickwollner@gmail.com>

It is useful to include emojis in your messages as a quick indicator of
emotional state, but why should you have to call up a special keyboard,
or scroll through many alternatives, when your emotional state could be
read off your face? The goal of this project is to augment the on-screen
keyboard by using the front facing camera (and/or depth data provided by
the device) to just read off the emotional state and put the "right"
emoji in. It could also be useful to use other sensors of the device to
better assess the emotional and physical state of the user in selecting
the fitting emoji.