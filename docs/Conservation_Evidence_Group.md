Phil Martin <pam79@cam.ac.uk>

Curating Conservation Evidence

A core activity of the Cambridge Conservation Science Group is compiling
evidence from research literature, to show which management approaches
are most effective for biodiversity conservation. However, this evidence
is published in many different academic fields. The Group need tools
that can use natural language processing methods to constantly monitor
publications across many different venues, extracting key attributes
such as geography, habitat, threats or interventions and organising
these for thematic browsing or targeted queries without being
constrained by the peculiar formats or terminology of particular
scientific disciplines.

Original query:

I'm part of the Conservation Evidence team in Zoology, where we work on
summarising scientific evidence on the effectiveness of different types
of management for biodiversity conservation.

As part of this process we systematically trawl through the scientific
literature to identify publications that are relevant to us, which can
be extremely time-consuming. We're interested in seeing if someone could
use a machine-learning approach to identify relevant studies based on
their contents. We have a database that contains studies that we have
already identified as relevant that could be used to train the
algorithm. Ideally the tool that would be produced would also classify
the topic of the studies. We estimate that a tool such as this could
save us ~5-15% of the time taken to synthesise evidence.

Does this sound like a good idea for a group project?

Regards,

-- Phil Martin

Postdoctoral Research Associate

Conservation Evidence

Conservation Science Group â€“ University of Cambridge

<http://www.conservationevidence.com/>