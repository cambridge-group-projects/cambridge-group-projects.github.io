{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":""},{"location":"index.html#design-briefs-for-cambridge-university-computer-laboratory-group-design-projects-2025","title":"Design Briefs for Cambridge University Computer Laboratory Group Design Projects 2025","text":"<p>All content on this site has draft status, subject to confirmation by both group project coordinators and project clients. There is no guarantee that these projects will be offered to students, either in the form described here, or at all.</p>"},{"location":"index.html#intellectual-property","title":"Intellectual property","text":"<p>Notes on Intellectual property</p>"},{"location":"index.html#client-briefing","title":"Client briefing","text":"<p>Information on Logistics for Clients</p> <p>Information for students, and course history: http://www.cl.cam.ac.uk/teaching/group-projects</p> <p>Information for Directors of Studies</p> <p>Information for the Coordinators</p>"},{"location":"index.html#management-timetable-for-2025","title":"Management timetable for 2025","text":"<p>Master timetable for the course: https://www.cst.cam.ac.uk/teaching/part-ib/group-projects/important-dates</p>"},{"location":"index.html#work-in-progress-design-briefs-for-2026","title":"Work in progress - design briefs for 2026","text":"<p>Notes on: What makes a goodproject?</p> <p>In 2026, we expect there will be ??? students, so ?? project teams (?? teams of 6 and ?? teams of 5). We aim to advertise at least ?? design briefs, to allow for necessary cancellations.</p>"},{"location":"index.html#proposed-design-briefs-for-2026","title":"Proposed design briefs for 2026","text":"<ol> <li>Drawing Machines</li> </ol>"},{"location":"index.html#candidates-under-discussion","title":"Candidates under discussion","text":"<ul> <li>Who Pays for Roads?</li> <li>Software Inconsistency   Resolver</li> <li>ARM</li> <li>Frontier</li> <li>Jack Ashby, Zoology museum</li> <li>Chris Pointon, Green Economy Infrastructure</li> <li>Simon Pulman-Jones, Evinova / Astra Zeneca</li> <li>Leontien Talboom, University Library</li> </ul>"},{"location":"index.html#projects-under-discussion","title":"Projects under discussion","text":"<ol> <li>Sustainable Electronic     Recycling</li> <li>Semantic Refactoring</li> </ol>"},{"location":"index.html#design-briefs-suggested-to-several-potential-clients","title":"Design briefs suggested to several potential clients","text":"<ol> <li>The Carbon Eye</li> <li>ResponsibleAncestry.com</li> <li>Guitar tab2hand</li> <li>Who Pays for Roads?</li> </ol>"},{"location":"index.html#design-briefs-considered-in-2024-that-might-be-developed","title":"Design briefs considered in 2024 that might be developed","text":"<ol> <li>Dignified Distributed Work</li> <li>The Big Chill</li> <li>Future Health and Fitness</li> <li>AfroInsight</li> <li>Leadership Transition     Simulator</li> <li>Environmental Value Added</li> <li>Just Maps</li> <li>Non-WEIRD Data Science</li> <li>Living Salad Bar</li> </ol>"},{"location":"index.html#potential-clients-for-2025","title":"Potential clients for 2025","text":"<p>Final 2025 list</p> <ul> <li>Alder Hey Children's   Hospital</li> <li>Embecosm</li> <li>SEAT</li> <li>Anthony Harris</li> <li>Rivos Systems</li> <li>AMD</li> <li>Raspberry Pi Foundation</li> <li>Katy Jordan, EdTech Hub</li> <li>Adham Ashton-Butt, British Trust for   Ornithology</li> <li>Adam Devenish, RSPB</li> <li>Maximilian Ge</li> <li>Matthew Postgate</li> </ul>"},{"location":"index.html#incubator-and-network-contacts","title":"Incubator and network contacts","text":"<ul> <li>Centre for Global Equality</li> <li>Barn4</li> <li>Ideaspace</li> <li>Emma Salgard Cunha - humanities at   Cambridge Enterprise</li> <li>Nicola Buckley - policy fellows at CSaP</li> </ul>"},{"location":"index.html#other-client-discussions-last-updated-2023","title":"Other client discussions (last updated 2023)","text":"<ul> <li>SMARTRI Indonesia</li> <li>Mark Gotham</li> <li>Daniel Hall</li> <li>London Stock Exchange Group</li> <li>Neil Walker</li> <li>Milk and More</li> <li>Jane Street</li> <li>Fair Finance</li> <li>The Fusion Works</li> <li>Frontier</li> <li>Amazon</li> <li>Dovetailed</li> <li>JP Morgan</li> <li>Centre for Policy Futures</li> <li>Gardin</li> <li>ICCCAD</li> <li>Antobot</li> <li>Morgan Stanley</li> <li>Curriculum for Life</li> <li>RSPB</li> <li>BigPay</li> <li>British Trust for   Ornithology</li> <li>University Information   Services</li> </ul>"},{"location":"index.html#development-notes-carried-forward-from-2021","title":"Development notes carried forward from 2021","text":"<ul> <li>Frontier - second project</li> <li>NIAB - second project</li> <li>Informetis - topic discussed</li> <li>Giving Voice to Digital   Democracies - topic   suggested, no response</li> <li>ARM - contact identified, but no topic</li> </ul>"},{"location":"index.html#other-clients-from-2021","title":"Other clients from 2021","text":"<ul> <li>MathWorks</li> </ul> <ul> <li>Boeing</li> <li>TechWolf</li> <li>DX Analytics</li> <li>Umbrella Analytics</li> <li>Lyzeum Ltd</li> <li>Broadcom - all contact emails now bounce</li> </ul>"},{"location":"index.html#previous-ideas-that-have-not-been-used","title":"Previous ideas that have not been used","text":"<ul> <li>Calendar Dialogue -   Amazon</li> <li>Auto-Emoji</li> <li>Archaeological databases</li> <li>The Headless Bicycle</li> <li>Emo Face</li> <li>Character Locomotion Middleware - Frontier</li> <li>Automatic accessibility assessor - Frontier</li> <li>City generation - Frontier</li> </ul>"},{"location":"index.html#potential-clients-that-did-not-proceed-but-could-be-considered-in-future","title":"Potential clients that did not proceed, but could be considered in future","text":"<ul> <li>2022: Autodesk</li> <li>2021: FetoLife, Oodle, NHS   Digital, Jump   Trading, Microsoft Africa Research   Institute</li> <li>2020: Argon Design,   Gearset, Thales, Sainsbury   Laboratory</li> <li>2019: Smart Cambridge,   Mindi, Fauna and Flora   International,   Fusepump, Investre,</li> <li>2018: Sparx, Cambridge   Consultants,   Capita, Nominet   Trust, University Information   Services, Sport   England</li> <li>2017: BT, Palantir, Elm   Partners, Lucid /   Cycorp, Microsoft   Research</li> <li>2016: Care Quality Commission,   King Digital Entertainment,   The Fusion Works</li> <li>2015: Thales, Steve   Wade, Cambridge Humanitarian   Centre</li> <li>2014: Broadcom, last.fm,   Rangespan, John   McMillan, Atheon,   OpenMarket, Google,   Repindex</li> <li>2013: Neul.com, Steve Smith, CU Management   Information Systems   Division,   Palantir Technologies, Privacy   International</li> </ul>"},{"location":"index.html#archived-records-of-previous-years","title":"Archived records of previous years","text":"<ul> <li>2025 list of design briefs and playlist of   video presentations (YouTube):   https://www.youtube.com/playlist?list=PLstyePOvf2d1HSBklMXWbdLd_4T2X8pIT</li> <li>2024 list of design briefs and playlist of   video presentations (YouTube):   https://www.youtube.com/watch?v=zeCRJYL3suw&amp;list=PLstyePOvf2d3jOfc6j8cG7CmmVD6LyMe_</li> <li>2023 list of design briefs and playlist of   video presentations (YouTube):   https://www.youtube.com/watch?v=WcITCNXbEzM&amp;list=PLstyePOvf2d2ZvC92BQkpR6WiaiROytev</li> <li>2022 list of design briefs, 2022 - final list   of clients and playlist:   https://www.youtube.com/watch?v=9xs5f6csNiQ&amp;list=PLstyePOvf2d3oPJOBgNoeA-aPA7lhUIGS</li> <li>2021 list of design briefs, 2021 - final list   of clients and playlist:   https://www.youtube.com/watch?v=Wf7zOcZCRTo&amp;list=PLstyePOvf2d2o9O_K3GEY3wAtbqkkYjPm</li> <li>2020 list of design briefs, 2020 - final list   of clients (presentations   disrupted by Covid-19 - no video). Student briefing booklet 2020:   http://www.cl.cam.ac.uk/teaching/group-projects/StudentBriefing_1920.pdf</li> <li>2019 list of design briefs, 2019 - final list   of clients, briefing booklet   http://www.cl.cam.ac.uk/teaching/group-projects/StudentBriefing_1819.pdf,   playlist:   https://youtube.com/playlist?list=PLstyePOvf2d39LYQ3YBcdWUdREimYF8e4&amp;si=RHH_jzctWiQchuH8</li> </ul> <ul> <li>Student briefing booklet 2018:   http://www.cl.cam.ac.uk/teaching/group-projects/StudentBriefing_1718.pdf</li> <li>Playlist of video presentations (YouTube):   https://youtube.com/playlist?list=PLstyePOvf2d0H15TwI6kEZb38ucaUDshQ&amp;si=fS8uf8Db3PjqguBf</li> <li>2018 list of design briefs</li> <li>2018 - final list of   clients</li> </ul> <ul> <li>Student briefing booklet 2017:   http://www.cl.cam.ac.uk/teaching/group-projects/StudentBriefing_1617.pdf</li> <li>Playlist of video presentations (YouTube):   https://youtube.com/playlist?list=PLstyePOvf2d0fbeximiXyWR2gB5KjjjE6&amp;si=dQHg-NFFqSafdtek</li> <li>2017 list of design briefs</li> <li>2017 - final list of   clients</li> </ul> <ul> <li>Student briefing booklet 2016:   http://www.cl.cam.ac.uk/teaching/group-projects/StudentBriefing_1516.pdf</li> <li>Video of presentations:   https://www.youtube.com/watch?v=oxcEQE4FigU&amp;list=PLstyePOvf2d2QbiVFI4naska1n4G0fhSW</li> <li>2016 list of design briefs</li> <li>2016 - final list of   clients</li> </ul> <ul> <li>Student briefing booklet 2015:   http://www.cl.cam.ac.uk/teaching/group-projects/StudentBriefing_1415.pdf</li> <li>Video of presentations:   https://www.youtube.com/playlist?list=PLstyePOvf2d0cPplAB3DxHoaJC6hTYomP</li> <li>2015 list of design briefs</li> <li>2015 - final list of   clients</li> </ul> <ul> <li>Student briefing booklet 2014:   http://www.cl.cam.ac.uk/teaching/group-projects/StudentBriefing_1314.pdf</li> <li>Video of presentations:   https://www.youtube.com/playlist?list=PLstyePOvf2d2A3vWW4DkEGIAUIm4T0fg6</li> <li>2014 - final list of design   briefs</li> <li>2014 - final list of   clients</li> </ul> <ul> <li>Student briefing booklet 2013:   http://www.cl.cam.ac.uk/teaching/group-projects/StudentBriefing_1213.pdf</li> <li>Video of presentations: http://www.sms.cam.ac.uk/collection/1435486</li> <li>2013 - final list of design   briefs</li> <li>2013 - final list of   clients</li> </ul>"},{"location":"index.html#selected-design-briefs-from-earlier-years","title":"Selected design briefs from earlier years","text":"<ul> <li>2010</li> <li>2009</li> <li>2008</li> <li>2006</li> </ul>"},{"location":"index.html#projects-that-have-been-offered-but-not-assigned-to-groups","title":"Projects that have been offered, but not assigned to groups","text":"<p>The usual reason for cancelling a project is that the topic has not attracted sufficient interest from students. It's worth keeping an eye on these, as some topics, or ways of phrasing them, seem less attractive. But fashions change!</p> <ul> <li>2019: Flyathlon (2019 version),   Robot Death Watch, Visual Pick and   Place</li> <li>2018: Citizen Speed Safety, Every   Car in Cambridge</li> <li>2017: Energy with Social   Conscience, Science for   AD2500, Surgery in the   Cloud</li> <li>2016: Pocket Brain Surgeon,   Reducing food waste with   IoT, The Busking   Bus-Stop, Safer Chicken from Farm   to Fork</li> <li>2015: Reinfection Monitor, Online   Identity for the Base of the   Pyramid,   Audio Websites on   Smartphones</li> <li>2014: Locally Augmented Retail,   Set Builder, Employability   Coach, Dance Practice   Assistant, History   Scraper</li> <li>2013: Touch screen prototyping at   school, Measuring   glass-to-glass video-conference   latency,   The Poet Laureate's web   thresholds,   Countryside web server, Science   exhibit interaction   adviser, Personal   status server</li> </ul> <p>This is a test</p>"},{"location":"2006.html","title":"2006","text":""},{"location":"2006.html#alpha-animating-algorithms","title":"Alpha: Animating Algorithms","text":"<p>Much of practical computer science can be explained by drawing boxes and arrows that represent data structures. The contents of the boxes and the connectivity of the lines then changes as an algorithm proceeds. This is difficult to achieve using whiteboards or drawing programs. What is needed is a program that produces slow-motion animated films of data structures and algorithms at work. The system should provide a general mechanism for writing an animation script and connecting it to an implemented algorithm. The user should be able to set up the initial data for the algorithm and then step through to watch its operation. Auxiliary displays showing the time and space requirements of the algorithm might also be shown. The system should be demonstrated by animating at least five different algorithms for two different problems \u2013 say three sorting algorithms and two heap management routines.</p>"},{"location":"2006.html#bravo-book-bluffers-spectacles","title":"Bravo: Book Bluffer's Spectacles","text":"<p>Don't you hate it when somebody is displaying a new book, but you haven't got anything clever to say about it? One day soon, the frame of your spectacles will scan the barcode, then look up the book on the web in order to display an intelligent quote on the inside of your lenses. Your job is to prototype this system. Implement a bar-code reader using the EPXA1 teaching board, then deduce the ISBN number and access an online book review. Some useful information can be found at: http://www.bic.org.uk/bar4book.html Special resources: some technical assistance, including advice on selection and purchase of electronic components, can be provided by Arnab.Banerjee@cl.cam.ac.uk.</p>"},{"location":"2006.html#charlie-reconstructing-sketchpad","title":"Charlie: Reconstructing Sketchpad","text":"<p>Sketchpad was the first interactive graphics program, created by Ivan Sutherland for the TX-2 computer at the MIT Lincoln Labs. It was one of the most influential programs ever written, and provided features that are still not found in commercial products 40 years later. Your goal is to simulate (as a \u201cvirtual TX-2\u201d implemented in Java) as much of the internal architecture as possible. Your system should reproduce the original user interface of Sketchpad, and also provide a visualization of the internal state. Sutherland\u2019s Sketchpad system is described in his PhD thesis, available online at: http://www.cl.cam.ac.uk/TechReports/UCAM-CL-TR-574.pdf</p>"},{"location":"2006.html#delta-digital-logic-simulator","title":"Delta: Digital Logic Simulator","text":"<p>First year computer scientists sometimes have difficulty working out how Boolean logic and finite state machines work. It might be helpful to have a simple graphical simulator that would allow a small circuit diagram to be sketched and then exercised with test signals, and the resulting changes in signals displayed. The user interface should allow the user to select components from a library (including, say, 2- and 3-input NOR and NAND gates, RS-, JK-, D- and T-type flip-flops) and place them on the screen together with switches and LEDs. Connections could then be made between these by drawing lines between specified pins on the components. It would be helpful if the circuit could be saved to a file and restored so that a user can return to an earlier piece of work after a break.</p>"},{"location":"2006.html#echo-extensible-conference-management-system","title":"Echo: Extensible Conference Management System","text":"<p>Create a system to manage the paper-submission and review process for an academic conference, workshop or journal. You should aim to improve on existing systems such as the Editor\u2019s Assistant (http://edas.info/doc/) and ConfMan (http://www.ifi.uio.no/confman/demo/). The system must be easily usable by authors, referees and editors \u2013 with a wide range of computing skill levels.</p>"},{"location":"2006.html#foxtrot-next-generation-museum-guide","title":"Foxtrot: Next-Generation Museum Guide","text":"<p>Visitors to the Fitzwilliam Museum in Cambridge can currently use a handheld eGuide, deployed on PDAs with location sensing infrastructure from local company Hypertag. Your task is to design a next-generation guide aimed at an audience of eight-year olds. The device should enable users to guide the rest of their family around the Museum during their visit. It should also allow users to construct a thematic story inspired by a selection of museum objects. By combining the user's narrative with multimedia material, the system will automatically generate a personalised (HTML-based) videogame that users and their friends can later play online. Special resources: Team members will have the opportunity to visit the Fitzwilliam to discuss this project with museum staff. However there is no need to base your demonstrated system on exhibits or multimedia material from the Fitzwilliam. It may also be possible for the client to arrange loan of a suitable PDA platform, and access to Hypertag technology.</p>"},{"location":"2006.html#golf-distributed-game","title":"Golf: Distributed Game","text":"<p>Take any popular board or card game (preferably one not encumbered with patent or copyright restrictions) and make a computer version of it that can be played over a network. Go and chess are possibilities, but something like Mah-jong or poker with more than two players could be better. The system must enforce the rules and manage the shared state of the game, keeping it consistent between the machines, and display it attractively through a graphical user interface. Ideally, the system should survive failure of some of the participants, and it should be possible for players to join and leave the game at any time. An automatic player can also be provided to make up numbers when there are not enough real players.</p>"},{"location":"2006.html#hotel-student-comfort-system","title":"Hotel: Student Comfort System","text":"<p>The student workstation area in the Gates Building is subject to substantial variations in temperature and humidity, especially during the annual group project demonstration day. Your task is to design an environmental control system that will monitor and predict changing comfort levels. This should be done sufficiently accurately that corrective action can be taken before conditions become too extreme for passive airflow modifications to be effective. You will use a Squirrel environmental datalogger, with sensors to record current environmental conditions and count the number of people entering and leaving. Based on your recordings of the effects of occupancy and incident sunlight, you should develop a predictive model that will then be used to regulate conditions by managing airflow on the final project demonstration day. Special resources: the project client, an engineer from Grant Instruments, will loan a Squirrel datalogger, together with documentation and suitable sensors.</p>"},{"location":"2006.html#india-synthetic-sudoku","title":"India: Synthetic Sudoku","text":"<p>A group project coordinator is addicted to Sudoku. One puzzle a day is no longer enough, so, like many others, he would like an automated Sudoku puzzle generator. This would also allow the generated puzzles to be completed on-screen. If the player gets stuck, he should be able to request a hint at any time. It should be possible to save and restore work in progress. The system should also provide a competition mode, in which two players work on the same puzzle, with each player\u2019s display indicating progress made by the other.</p>"},{"location":"2006.html#juliet-3d-puzzle-experience","title":"Juliet: 3D Puzzle Experience","text":"<p>A local entrepreneur has designed a new logic puzzle, similar to Peter's Black Hole, but with blocks that change colour when they move. Your task is to create a Java applet that could be used to model and demonstrate the behaviour of the new puzzle. It should give applet users a pleasurable experience of understanding and solving the puzzle, and could include animated visualisation of an automatic puzzle-solver working in 3-D. Information on similar puzzles and Java applets is available from Jaap's Puzzle Page: www.geocities.com/jaapsch/puzzles. Special resources: a description of the puzzle can be obtained from the project client, Kelvin Stott kelvin.stott@btinternet.com</p>"},{"location":"2006.html#kilo-programming-for-artists","title":"Kilo: Programming for Artists","text":"<p>Seymour Papert\u2019s Logo, Steven Tanimoto\u2019s Pixel Calculator, and John Maeda\u2019s Design By Numbers have all tried to teach basic computational concepts by focusing on image manipulation. Your task is to design a new educational language, suitable for use by first-year art or architecture students. Your system should offer a sufficiently engaging aesthetic experience to keep art students interested at least until they have acquired the concepts in sections 4.1 to 4.4 of Arthur Norman's Java notes. (You don't have to use Java syntax.)</p>"},{"location":"2006.html#lima-last-resort-pwf-expansion","title":"Lima: Last-Resort PWF Expansion","text":"<p>Security and other administrative considerations cause PWF administrators to take a conservative view of system expansion. This can be inconvenient for more adventurous group projects, as can be confirmed by attempting to connect Bluetooth or other exotic USB devices to a PWF workstation. In the last resort, the only output channel left might be the display screen! Your task is to devise a data communications channel that sends data via the screen to an EPXA1 teaching board, using one or more light sensing devices, along with a suitable transmission protocol. Special resources: some technical assistance, including advice on selection and purchase of electronic components, can be provided by Arnab.Banerjee@cl.cam.ac.uk.</p>"},{"location":"2006.html#mike-mobile-map-service","title":"Mike: Mobile Map Service","text":"<p>One of the challenges of mobile information devices is that the available screen space is so much smaller than on desktop systems. This project is to create a restaurant, shop and entertainment finding service that provides users with attractive maps showing how to get to their advertising clients when users have a web browser, but simpler text instructions (\u201cgo left next corner\u201d etc.) when accessed from a mobile phone. Information about the advertising clients, their location, and layout of local streets will be stored in XML format. Simple graphical maps will be constructed from this information by a Java applet that can be incorporated in web pages. Wireless users will be able to access the same information, but rendered as a series of brief text instructions.</p>"},{"location":"2006.html#november-sampling-synthesiser","title":"November: Sampling Synthesiser","text":"<p>Bands that use sampled sounds often want to adjust the pitch, or even play a tune, as in novelty tracks where a barking dog sings Happy Birthday. The EPXA1 teaching board can be used for simple signal processing. Your task is to turn it into a synthesiser, using sound captured and downloaded from a CD, so that it can be played directly as a musical instrument or used as a remote synthesiser. Special resources: some technical assistance, including advice on selection and purchase of electronic components, can be provided by Jonathan.May@cl.cam.ac.uk.</p>"},{"location":"2006.html#oscar-optical-tomography","title":"Oscar: Optical Tomography","text":"<p>We have some hardware to scan the convex surfaces of objects. The hardware consists of a turntable on top of which the object is placed. On one side of the turntable is an array of LED emitters, and on the other side is a set of optical receivers. By sequencing the LEDs, one can produce a sequence of shadows which are detected by the optical receivers. Rotating the object allows further sets of shadows to be produced. These shadows are then analysed using tomography techniques to determine the shape of the object being scanned. You should use an EPXA1 teaching board to drive the turntable via a stepper motor, to scan the LEDs and optical receivers, and provide video output. You should also implement the tomography code on the ARM processor embedded in the teaching board. Special resources: some technical assistance, including advice on selection and purchase of electronic components, can be provided by Jonathan.May@cl.cam.ac.uk.</p>"},{"location":"2008.html","title":"2008","text":""},{"location":"2008.html#alpha-animating-algorithms","title":"Alpha: Animating Algorithms","text":"<p>Much of practical computer science can be explained by drawing boxes and arrows that represent data structures. The content of the boxes and the connectivity of the lines then changes as an algorithm proceeds. This is difficult to achieve using whiteboards or drawing programs. What is needed is a program that produces slow-motion animated films of data structures and algorithms at work. The system should provide a general mechanism for writing an animation script and connecting it to an implemented algorithm. The user should be able to set up the initial data for a variety of algorithms and then step through to watch their operation. It would be convenient if the resulting movie can be exported in a form suitable for viewing online or including in a PowerPoint presentation.</p>"},{"location":"2008.html#bravo-book-bluffers-spectacles-hardware-project","title":"Bravo: Book Bluffer's Spectacles (hardware project)","text":"<p>Don't you hate it when somebody is displaying a new book, but you haven't got anything clever to say about it? One day soon, the frame of your spectacles will scan the barcode, then look up the book on the web in order to display an intelligent quote on the inside of your lenses. Your job is to prototype this system. Implement a bar-code reader using the DE2 board, then deduce the ISBN number and access an online book review. Some useful information can be found at: http://bic.org.uk/isbnbarcode-rfid.html</p>"},{"location":"2008.html#charlie-wednesday-mash-up","title":"Charlie: Wednesday Mash-up","text":"<p>The public seminars presented at the Computer Laboratory on Wednesday afternoons are accessible online from a video archive. At present, this archive allows viewers to replay the talk, but not index, tag, edit, or link it to other research and teaching material. Design an interactive tool that would allow a wider community of users to restructure and reorganise archived seminars for a greater variety of browsing, viewing and linking. Your tool need not be integrated into a web browser, or use web services for video streaming. A reasonable approach would be to make a special Java client (perhaps based on Java Media Framework) that allows users to download a whole video file and add local structured content that can later be viewed by others using the same client.</p>"},{"location":"2008.html#delta-digital-logic-simulator","title":"Delta: Digital Logic Simulator","text":"<p>First year computer scientists sometimes have difficulty working out how Boolean logic and finite state machines work. It might be helpful to have a simple graphical simulator that would allow a small circuit diagram to be sketched and then exercised with test signals, and the resulting changes in signals displayed. The user interface should allow the user to select components from a library (including, say, 2- and 3-input NOR and NAND gates, RS-, JK-, D- and T-type flip-flops) and place them on the screen together with switches and LEDs. Connections could then be made between these by drawing lines between specified pins on the components. It would be helpful if the circuit could be saved to a file and restored so that a user can return to an earlier piece of work after a break.</p>"},{"location":"2008.html#echo-controllers-for-kids-hardware-project","title":"Echo: Controllers for Kids (hardware project)","text":"<p>The UK school syllabus for Design and Technology encourages kids to gain experience of programming robots and other digitally-controlled gadgets. Those student projects are usually limited by slow hardware and clunky programming interfaces. Your task is to create a compiler that will allow Sixth Form D&amp;T students to draw a state machine on their PC screen, then compile it into a form that can be downloaded and executed on a DE2 board, either as interpreted transition tables or by direct output of ARM instructions. You should build a physical demonstrator machine that shows off the versatility of your control system.</p>"},{"location":"2008.html#foxtrot-next-generation-museum-guide","title":"Foxtrot: Next-Generation Museum Guide","text":"<p>Visitors to the Fitzwilliam Museum in Cambridge can currently use a handheld eGuide, deployed on PDAs with location sensing infrastructure from local company Hypertag. Your task is to design a next-generation guide aimed at an audience of eight-year olds. The device should enable users to guide the rest of their family around the Museum during their visit. It should also allow users to construct a thematic story inspired by a selection of museum objects. By combining the user's narrative with multimedia material, the system will automatically generate a personalised (HTML-based) videogame that users and their friends can later play online.</p>"},{"location":"2008.html#golf-intelligent-schedule-negotiator","title":"Golf: Intelligent Schedule Negotiator","text":"<p>Scheduling problems are notoriously hard. In Cambridge, they are even harder, because Colleges and Departments see the world in different ways. The impact is severe for NatSci Part 1A students, who must take afternoon practical courses managed by multiple departments, under constraints set by multiple colleges. Your task is to design a system that will allow users to propose and negotiate their various constraints, with sophisticated conflict resolutions supported by artificial intelligence techniques. The first stage in the project will require brief interviews with representative users, including some College Directors of Studies, and Part 1A teaching coordinators.</p>"},{"location":"2008.html#hotel-ring-around-the-world","title":"Hotel: Ring around the World","text":"<p>Design a web application that uses the Google Maps API to show the distribution of Computer Lab Ring members around the world. Include a secure protocol such that (with mutual consent) two members can exchange contact details when they live within a specified travelling distance, or are visiting the same location. All personal data must otherwise be securely protected, under the control of a database administrator.</p>"},{"location":"2008.html#india-web-20-research-gateway","title":"India: Web 2.0 Research Gateway","text":"<p>Social networking and user-driven content are making everyone excited about \u201cWeb 2.0\u201d. Could such techniques improve University research? The talks.cam system allows researchers across Cambridge to generate and access descriptions of the latest research. However, talks.cam doesn't include user recommendations, ratings, tagging and the other advanced features you'd expect in Web 2.0 content delivery systems such as Flickr, YouTube and so on. Using the XML interfaces to talks.cam, design a system that offers students, prospective students, and the outside world, direct insight to whatever research is most relevant or exciting to them. See: http://talks.cam.ac.uk/document/specification</p>"},{"location":"2008.html#juliet-pipe-dreams","title":"Juliet: Pipe Dreams","text":"<p>Design an online fantasy game in which players compete to reach items of treasure inside a three-dimensional maze of pipes and tanks. The display need not be three dimensional (it might use 2-D perspective renderings of the pipe interiors), but should give advice on which players have the best chance of reaching each treasure, based on speeds with which players can run around corners of varying radius, climb ladders versus sliding down, etc. Although players only see the inside of the maze, you can create a 3-D visualisation for use by a Game Master, by exporting the whole maze description to a rendering engine.</p>"},{"location":"2008.html#kilo-programming-for-artists","title":"Kilo: Programming for Artists","text":"<p>Seymour Papert\u2019s Logo, Steven Tanimoto\u2019s Pixel Calculator, and John Maeda\u2019s Design By Numbers have all tried to teach basic computational concepts by focusing on image manipulation. Your task is to design a new educational language, suitable for use by first-year art or architecture students. Your system should offer a sufficiently engaging aesthetic experience to keep art students interested at least until they have acquired concepts sufficient to create a simple interactive web animation or illustrated talk.</p>"},{"location":"2008.html#lima-street-video-wall-hardware-project","title":"Lima: Street Video Wall (hardware project)","text":"<p>The public display screens in the Gates Building \u201cStreet\u201d are informative, but don\u2019t showcase the abilities of our students. Using the DE2 teaching boards, it should be possible to create a \u201cvideo wall\u201d that accepts VNC display commands and outputs a large display across multiple screens. Start with four screens, driven from four DE2 boards. Provide a software application interface suitable for use in a student design competition to create an interactive display that will impress visitors. The application interface might also provide audio, motion, SMS, web or environment sensing via the DE2 for multimodal interaction.</p>"},{"location":"2008.html#mike-mobile-map-service","title":"Mike: Mobile Map Service","text":"<p>One of the challenges of mobile information devices is that the available screen space is so much smaller than on desktop systems. This project is to create a restaurant, shop and entertainment finding service that provides users with attractive maps showing how to get to their advertising clients when users have a web browser, but simpler text instructions (\u201cgo left next corner\u201d etc.) when accessed from a mobile phone. Information about the advertising clients, their location, and layout of local streets will be stored in XML format. Simple graphical maps will be constructed from this information by a Java applet that can be incorporated in web pages. SMS users will be able to access the same information, but rendered as a series of brief text instructions.</p>"},{"location":"2008.html#november-sampling-synthesiser-hardware-project","title":"November: Sampling Synthesiser (hardware project)","text":"<p>Bands that use sampled sounds often want to adjust the pitch, or even play a tune, as in novelty tracks where a barking dog sings Happy Birthday. The DE2 board can be used for simple signal processing. Your task is to turn it into a synthesiser, using sound captured and downloaded from a CD, so that it can be played directly as a musical instrument or used as a remote synthesiser.</p>"},{"location":"2008.html#oscar-smart-poster-picker-with-fitzwilliam","title":"Oscar: Smart Poster Picker (with [Fitzwilliam","text":"<p>Museum](Fitzwilliam_Museum \"wikilink\")</p> <p>Many people like to buy poster reproductions of famous artworks. This could be done by using a mobile phone to take a picture of the painting they would like to hang on their wall, and sending an MMS message to a poster distribution service. Design a system that retrieves and ranks probable matching candidates from a database of posters, based on a mobile phone image. A simple metric for matching might be the relative averages or variances of hue in each quadrant of the image. Where the photo is not good enough to provide an effective match, users should also be able to navigate through thumbnails of the available posters, arranged according to the match metric for aesthetic graphical navigation.</p>"},{"location":"2009.html","title":"2009","text":""},{"location":"2009.html#alpha-animating-algorithms","title":"Alpha: Animating Algorithms","text":"<p>Much of practical computer science can be explained by drawing boxes and arrows that represent data structures. The content of the boxes and the connectivity of the lines then changes as an algorithm proceeds. This is difficult to achieve using whiteboards or drawing programs. What is needed is a program that produces slow-motion animated films of data structures and algorithms at work. The system should provide a general mechanism for writing an animation script and connecting it to an implemented algorithm. The user should be able to set up the initial data for a variety of algorithms and then step through to watch their operation. It would be convenient if the resulting movie can be exported in a form suitable for viewing online or including in a PowerPoint presentation.</p>"},{"location":"2009.html#bravo-magic-board-games-hardware-project","title":"Bravo: Magic board games (hardware project)","text":"<p>Find a way to create a \u2018magic\u2019 board game in which a computer opponent moves the pieces invisibly, perhaps with magnets moving under the board. A significant amount of mechanical assembly and experimentation is likely to be necessary. This will be achieved using stepper motors, rotary encoders, and construction using a simple prototyping toolset such as Lego Technic.</p>"},{"location":"2009.html#charlie-wednesday-mash-up","title":"Charlie: Wednesday Mash-up","text":"<p>The public seminars presented at the Computer Laboratory on Wednesday afternoons are accessible online from a video archive. At present, this archive allows viewers to replay the talk, but not index, tag, edit, or link it to other research and teaching material. Design an interactive tool that would allow a wider community of users to restructure and reorganise archived seminars for a greater variety of browsing, viewing and linking. Your tool need not be integrated into a web browser, or use web services for video streaming. A reasonable approach would be to make a special Java client (perhaps based on Java Media Framework) that allows users to download a whole video file and add local structured content that can later be viewed by others using the same client.</p>"},{"location":"2009.html#delta-digital-logic-simulator","title":"Delta: Digital Logic Simulator","text":"<p>\"It would be useful if a first year computer scientist could rapidly prototype a circuit on an Altera DE2 FPGA board without using a hardware description language. The user interface might be presented as a graphical circuit entry system allowing the user to select components from a library (including, 2- and 3-input NOR and NAND gates, RS-latch and D flip-flop) and place them on the screen. Additional components like RAMs and ROMs would be desirable. Switches and LEDs that are present on the DE2 board should be present in the graphical environment to allow circuits to interfaced to them. Saving and loading of circuits is desirable. Circuits created should be simulated on the DE2 board. The transfer of the circuit to the FPGA simulation might happen in real-time (i.e. any change in the circuit is reflected \"instantly\" in the simulation). The simulation might be performed in software by a soft processor on the FPGA. For a high performance implementation, the graphical circuit might also be written out as Verilog and then synthesised for direct implementation on the FPGA.\"</p>"},{"location":"2009.html#echo-controllers-for-kids-hardware-project","title":"Echo: Controllers for Kids (hardware project)","text":"<p>The UK school syllabus for Design and Technology encourages kids to gain experience of programming robots and other digitally-controlled gadgets. Those student projects are usually limited by slow hardware and clunky programming interfaces. Your task is to create a compiler that will allow Sixth Form D&amp;T students to draw a state machine on their PC screen, then compile it into a form that can be downloaded and executed on a DE2 board, either as interpreted transition tables or by direct output of ARM instructions. You should build a physical demonstrator machine that shows off the versatility of your control system.</p>"},{"location":"2009.html#foxtrot-pocket-power-predictor","title":"Foxtrot: Pocket Power Predictor","text":"<p>It's irritating when your mobile shows full battery power for 3 whole days, then suddenly drops to one flashing red bar as you're halfway through a text. It's even more annoying when that happens to your planet. The aim of this project is to design a pocket visualisation, running on Google Android, that will help you anticipate your future energy problems on all scales, from the phone itself, to your home heating and travel needs. The visualisation should also scale up to global problems, when you need rapid data for political debate. Use as many data sources as possible - RSS feeds, live updates on international agency websites, and the many sources of information from www.withouthotair.com</p>"},{"location":"2009.html#golf-statistical-persuasion","title":"Golf: Statistical Persuasion","text":"<p>Maker A well-presented statistical argument is very valuable. Many politicians, policy makers and members of the public find it hard to understand risk factors, likelihood, and what the priorities for action should be in an uncertain world. But Al Gore's film An Inconvenient Truth showed the power of well-designed statistical graphics. Web sites like http://www.gapminder.org/ help people explore political and economic statistics, and sites like http://www.understandinguncertainty.org/ help people understand statistical principles through animations of risk data. But it is hard for regular people to create sites like these (it usually involves a lot of Flash programming). Your task is to create an authoring tool that helps people communicate statistical arguments by creating interactive online graphics. They might get help to structure the arguments, as in http://compendium.open.ac.uk/. They should also be able to collect their own data from online sources, for example using data mashup tools like Yahoo Pipes.</p>"},{"location":"2009.html#hotel-ring-around-the-world","title":"Hotel: Ring around the World","text":"<p>Design a web application that uses the Google Maps API to show the distribution of Computer Lab Ring members around the world. Include a secure protocol such that (with mutual consent) two members can exchange contact details when they live within a specified travelling distance, or are visiting the same location. All personal data must otherwise be securely protected, under the control of a database administrator.</p>"},{"location":"2009.html#india-web-20-for-scholars","title":"India: Web 2.0 for Scholars","text":"<p>Businesses are rapidly moving to adopt \u2018web 2.0\u2019 approaches for product forums, marketing and on. Could such techniques improve academic research? The talks.cam system allows researchers across Cambridge to generate and access descriptions of the latest research. However, talks.cam doesn't include user recommendations, ratings, tagging and the other advanced features you'd expect in Web 2.0 content delivery systems such as Flickr, YouTube and so on. Using the XML interfaces to talks.cam, design a system that offers academics, prospective students, and the outside world, direct insight to whatever research is most relevant or exciting to them. See: http://talks.cam.ac.uk/document/specification</p>"},{"location":"2009.html#juliet-pipe-dreams","title":"Juliet: Pipe Dreams","text":"<p>Design an online fantasy game in which players compete to reach items of treasure inside a three-dimensional maze of pipes and tanks. The display need not be three dimensional (it might use 2-D perspective renderings of the pipe interiors), but should give advice on which players have the best chance of reaching each treasure, based on speeds with which players can run around corners of varying radius, climb ladders versus sliding down, etc. Although players only see the inside of the maze, you can create a 3-D visualisation for use by a Game Master, by exporting the whole maze description to a rendering engine.</p>"},{"location":"2009.html#lima-street-video-wall-hardware-project","title":"Lima: Street Video Wall (hardware project)","text":"<p>The public display screens in the Gates Building \u201cStreet\u201d are informative, but don\u2019t showcase the abilities of our students. Using the DE2 teaching boards, it should be possible to create a \u201cvideo wall\u201d that accepts VNC display commands and outputs a large display across multiple screens. Start with four screens, driven from four DE2 boards. Provide a software application interface suitable for use in a student design competition to create an interactive display that will impress visitors. The application interface might also provide audio, motion, SMS, web or environment sensing via the DE2 for multimodal interaction.</p>"},{"location":"2009.html#mike-mobile-map-service","title":"Mike: Mobile Map Service","text":"<p>One of the challenges of mobile information devices is that the available screen space is so much smaller than on desktop systems. This project is to create a restaurant, shop and entertainment finding service that provides users with attractive maps showing how to get to their advertising clients when users have a web browser, but simpler text instructions (\u201cgo left next corner\u201d etc.) when accessed from a mobile phone. Information about the advertising clients, their location, and layout of local streets will be stored in XML format. Simple graphical maps will be constructed from this information by a Java applet that can be incorporated in web pages. SMS users will be able to access the same information, but rendered as a series of brief text instructions.</p>"},{"location":"2009.html#november-sampling-synthesiser-hardware-project","title":"November: Sampling Synthesiser (hardware project)","text":"<p>Bands that use sampled sounds often want to adjust the pitch, or even play a tune, as in novelty tracks where a barking dog sings Happy Birthday. The DE2 board can be used for simple signal processing. Your task is to turn it into a synthesiser, using sound captured and downloaded from a CD, so that it can be played directly as a musical instrument or used as a remote synthesiser.</p>"},{"location":"2009.html#oscar-graphical-shared-wiki-editor","title":"Oscar: Graphical Shared Wiki Editor","text":"<p>TinyMCE is a platform independent WYSIWYG editor for HTML that is a popular component of web content management systems. A typical application is a wiki-style environment, allowing users to click on a button in the page, after which their browser loads an editor window containing the page content, with formatting controls that save the resulting changes as HTML. The disadvantage of TinyMCE is that it doesn't allow multiple users to make edits at the same time (it would be necessary to handle contention between users), and it doesn't support advanced diagrammatic elements such as SVG. Your task is to make a multi-user collaborative editor that runs within a browser and generates wiki pages incorporating HTML and SVG.</p>"},{"location":"2010.html","title":"2010","text":""},{"location":"2010.html#alpha-accelerated-interaction","title":"Alpha: Accelerated Interaction","text":"<p>The iPhone and iPod Touch include an accelerometer, but few Apps make good use of it. Driving and steering games work pretty well, as do some novelty items like beerglasses and spirit levels. But gestures like \u2018shake to clear the screen\u2019 are appalling. Your task is to design a useful and usable user interface (not a game) that can be controlled through tilt and gestures alone. Note that iPhone programming uses the slightly odd Objective C language, and the OSX operating system. Interest in learning these, or previous experience, will be beneficial.</p>"},{"location":"2010.html#bravo-critical-care-for-the-world","title":"Bravo: Critical Care for the World","text":"<p>In wealthy countries, hospital intensive care units often use sophisticated data monitoring and capture systems like IMDsoft MetaVision to enforce procedures and collect information about various drugs and patient vital signs. The World Health Organisation needs to establish more rigorous care and data collection for the kinds of emergency field hospital that deal with outbreaks of new viral infections like Ebola. But such a system would need to be customised for each site, by local staff, to deal with the huge variation in local training and resources. Your task is to design a field- customisable critical care system that could report research data to the WHO, while continuing to operate with the range of network connections, power supply and hardware availability typical in remote regions.</p>"},{"location":"2010.html#charlie-robot-chessboard-hardware-project","title":"Charlie: Robot Chessboard (hardware project)","text":"<p>In the first Harry Potter film, chess pieces move themselves around in reponse to moves on the board. Last year a group project team built a robot draughts player where the pieces were moved by magnets. This year we have sophisticated new robot hardware, and a computer vision system should make it possible to build a similarly magical robot chess set.</p>"},{"location":"2010.html#delta-party-line-detection","title":"Delta: Party Line Detection","text":"<p>New online \u2018social media\u2019 products become political tools almost as soon as they are released. But not all politicians realise that online content is more dangerous than traditional party newsletters, because it can be analysed automatically. Your task is to apply the Twitter API to analyse whether UK politicians are showing independent thought when they use Twitter, or are simply following the party line. Are they addressing the same issues as others in their party, perhaps simply reusing material from press releases? Or are they adopting ideas from the opposition agenda? Your system should provide voters with a clear summary and trend analysis, perhaps using visualisations of the kind that are shown on TV on election nights.</p>"},{"location":"2010.html#echo-unified-firmware-development-in-eclipse-hardware-project","title":"Echo: Unified Firmware Development in Eclipse (hardware project)","text":"<p>The aim of this project is to set up a new firmware development tool chain within the Eclipse programming environment. It will apply open source technology from Embecosm for communicating with embedded devices, whether as silicon or model. The target will use a System-on- Chip, implemented with the Altera board FPGA and as high level, cycle accurate and event-driven simulation models. The challenge will be in getting the Eclipse debugger to display non-processor state while debugging (e.g. registers of peripheral logic) with any of the targets and packaging the product in a form suitable for delivery to customers.</p>"},{"location":"2010.html#foxtrot-pedestrian-auto-pilot-hardware-project","title":"Foxtrot: Pedestrian Auto-Pilot (hardware project)","text":"<p>Design a \u2018wearable\u2019 computer (for pocket or beltpack) that keeps track of your location while walking or cycling, at a much finer accuracy than GPS does, by using inertial navigation techiques. When walking indoors, it should be able to remind you which direction to turn to go to your next lecture or supervision, remind you to buy your lunch when near the canteen and so on. The design should take account of known locations (for example when confirming task completion) to counteract the inevitable drift in inertial guidance systems. Your design will be based on the XMOS compact development system, and will include interfacing that system to components for inertial guidance.</p>"},{"location":"2010.html#golf-real-guitar-hero-hardware-project","title":"Golf: Real Guitar Hero (hardware project)","text":"<p>One of the most irritating things about the game Guitar Hero (though there are several candidates) is that it doesn\u2019t even use a real guitar. There is no reason why you shouldn\u2019t connect the pickups of a real guitar to a digital processor board. And you needn\u2019t play guitar hero either - the board can implement digital filters for standard guitar effects, and it can probably correct for the occasional wrong note. Your task is to build a digital guitar interface that uses signal processing techniques to produce a real musical instrument, not just a game.</p>"},{"location":"2010.html#hotel-hyper-resolution-camera","title":"Hotel: Hyper-Resolution Camera","text":"<p>By taking many many pictures of the same scene, it is possible to build gigapixel images, where every new image is aligned with the previous ones and composited together. Develop an application that can be used to create such images, and then to browse them via a mobile or web interface in the style of Google Earth (\u2018flying down\u2019 to zoom into the image, and then using false perspective to fly across the surface).</p>"},{"location":"2010.html#india-i-professor","title":"India: i-Professor","text":"<p>Most knowledge-workers (and professional scholars are no exception) have a serious struggle to differentiate routine correspondence from management of the new ideas that make the job interesting. Design an automated personal assistant that filters email, infers rules on the likely response to routine items, and looks for thematic patterns in the rest. This can be used to track research ideas, or even set up new clusters of collaboration. All rules should be customisable by the user, and confirm proposed actions before sending a message that might be harmful. After a little \u2018bedding-in\u2019, the customised result might be indistinguishable from a real professor.</p>"},{"location":"2010.html#juliet-teach-your-cat-to-twitter-hardware-project","title":"Juliet: Teach your Cat to Twitter (hardware project)","text":"<p>Now that everyone keeps in contact with their friends via Twitter, it\u2019s a shame that your pets can\u2019t send you tweets while you are away from home. This project means they can! Using covert camera products from ZedCam, detect what your cat is doing, and send updates via Twitter or some other Web 2.0 platform. The system should be remotely configurable from the same mobile device you would use to access Twitter.</p>"},{"location":"2010.html#kilo-spot-the-medicine-instant-feedback-from-chemical-structures","title":"Kilo: Spot the Medicine - instant feedback from chemical structures","text":"<p>Computational predictive models that can generate results in fractions of seconds are used in the design of new medicines (e.g. http://www.optibrium.com/stardrop/stardrop-glowing-molecule.php). In addition, many databases exist containing further data about previously synthesised molecules. However, this information can only be predicted or recalled for molecules for which the chemical structures are stored on a computer in some form. Chemists regularly have \u2018visual access\u2019 to molecule structures (papers, meeting presentations, notebooks) with no option but to make a copy and then \u2018draw\u2019 the molecule into their computer at a later time if they wish to find out more information. Your challenge is to design and prototype a method by which a chemist with visual access to a molecule structure can find out information about a molecule within seconds of seeing it, giving real-time feedback to spot potential new medicines.</p>"},{"location":"2010.html#lima-a-virtual-phillips-machine","title":"Lima: A Virtual Phillips Machine","text":"<p>Over in the Economics Department there is a Phillips Machine (aka MONIAC), a 1950\u2019s analogue computer that solves the equations of Keynesian macroeconomics using water flowing through a system of pipes, pumps and pulleys to simulate the flow of money through the national economy. Although more advanced mathematical models now exist, they lack the vivacity and didactic appeal of their hydraulic precursor. The aim of this project is to construct a vivid graphic realisation, possibly using JavaScript or Flash, of a Virtual Phillips Machine - an online demonstrator where valves and other settings can be adjusted in real-time via the mouse to replicate the workings of the original.</p>"},{"location":"2010.html#mike-integrating-phones-with-the-web","title":"Mike: Integrating Phones with the Web","text":"<p>Metaswitch Networks (www.metaswitch.com and previously known as Data Connection Ltd) is a UK-based company which is a market leader in providing next generation, voice over IP telephony equipment. Their equipment provides ways to start phone calls, listen to voicemails, read a web addressbook and get lists of phone calls made and received using JavaScript. The purpose of this project is to work out, build and demonstrate a Web mash-up to include those controls with other Web applications such as Facebook, mySpace, Google Maps or anything else you think would make your life and the way you use the telephone better.</p>"},{"location":"2010.html#november-database-in-the-clouds","title":"November: Database in the clouds","text":"<p>\u2018Cloud\u2019 applications that allow people to create and maintain online shared spreadsheets or word processor documents are becoming pretty common. But there aren\u2019t many good database systems for cloud users. Systems like Amazon SimpleDB and LongJump are aimed at technical users, but it would be good to have a simple, free data management service for use in the voluntary / non-profit / community sector. Your task is to provide extremely simple web-based definition of schemas, end-user query and reporting language, with import/export to formats that are recognisable to non-technical users, such as plain text email, html tables, Word lists and Excel. Imagine your grandparents as the target users, and that they needs this to run membership, event management, collections &amp; libraries for all their different hobby societies and community groups.</p>"},{"location":"2010.html#oscar-hello-theremin-world-hardware-project","title":"Oscar: Hello Theremin World (hardware project)","text":"<p>The Theremin was the first successful electronic musical instrument, like a \u2018Hello World\u2019 application for the whole field of electronic music. 100 years later, many artists and musicians use small digital controllers like the Arduino and mBed to prototype new interactive concepts. But it\u2019s surprisingly difficult for them to implement a simple digital Theremin (it\u2019s easy to do it with electronic parts). Your task is to create an open source toolkit, and a sample hardware demonstrator, that would make it easy for new digital artists to create a simple theremin as their \u2018hello world\u2019 experiment.</p>"},{"location":"2010.html#papa-phone-programming-for-children","title":"Papa: Phone Programming for Children","text":"<p>Design a programming language suitable for use by children, with a sufficiently compact user interface that the development environment can be run on a mobile phone. Children should be motivated to use this language to develop applications that are useful and of interest to them - it shouldn\u2019t be like school! The Android platform will be used.</p>"},{"location":"2010.html#quebec-remote-diy-software-plumbing","title":"Quebec: Remote DIY software plumbing","text":"<p>Systems like readyourmeter.org (from Cambridge) were developed to help remote monitoring of your house from the web. The next step is remote control of your house. Create a web-based programming environment, that will allow homeowners to do DIY software plumbing (scripting and configuration) of home media, energy and control systems.</p>"},{"location":"2013_-_final_list_of_clients.html","title":"2013   final list of clients","text":"<ul> <li>Frontier</li> </ul> <ul> <li>Jeff Patmore, Engineering Design   Centre</li> </ul> <ul> <li>IBM</li> </ul> <ul> <li>Kettles Yard Gallery</li> </ul> <ul> <li>Engineering Design Centre</li> </ul> <ul> <li>Microsoft Research</li> </ul> <ul> <li>Microsoft Research Cambridge (2   projects)</li> </ul> <ul> <li>Cisco</li> </ul> <ul> <li>Nigel Day, ENEA</li> </ul> <ul> <li>Last.fm</li> </ul> <ul> <li>VisualDNA</li> </ul> <ul> <li>Peter Cowley</li> </ul> <ul> <li>United Nations Environment Programme World Conservation Monitoring   Centre</li> </ul> <ul> <li>David Rubin, Bloomberg</li> </ul> <ul> <li>Cambridge Science Centre</li> </ul> <ul> <li>Qualcomm</li> </ul> <ul> <li>BT</li> </ul>"},{"location":"2013_-_final_list_of_design_briefs.html","title":"2013","text":"<ul> <li>Laser cutting round boxes from square   sheets</li> </ul> <ul> <li>Touch screen prototyping at   school</li> </ul> <ul> <li>Measuring glass-to-glass video-conference   latency</li> </ul> <ul> <li>Reliable cycle-aware traffic   light</li> </ul> <ul> <li>Scrobble Exchange: A massively multiplayer   game</li> </ul> <ul> <li>Safer social media</li> </ul> <ul> <li>Personal/national mood   tracker</li> </ul> <ul> <li>The Poet Laureate's web   thresholds</li> </ul> <ul> <li>Countryside web server</li> </ul> <ul> <li>Race the wild</li> </ul> <ul> <li>Password and privacy protection with   Pi</li> </ul> <ul> <li>From Hogwarts to hackers</li> </ul> <ul> <li>A platform for live online   modding</li> </ul> <ul> <li>Hashtag-FollowTheMarket</li> </ul> <ul> <li>Science exhibit interaction   adviser</li> </ul> <ul> <li>Personal status server</li> </ul> <ul> <li>Rule-tris introduction to   programming</li> </ul> <ul> <li>Terabyte threat analysis</li> </ul> <p>Two C# projects:</p> <ul> <li>Friend meeting/tracking application for the   Elderly</li> </ul> <ul> <li>Cycle path mapping with a custom hardware   platform</li> </ul>"},{"location":"2014_-_final_list_of_clients.html","title":"2014   final list of clients","text":"<ul> <li>altfusion</li> </ul> <ul> <li>Potential Difference</li> </ul> <ul> <li>IMC (Netherlands)</li> </ul> <ul> <li>MathWorks</li> </ul> <ul> <li>Frontier</li> </ul> <ul> <li>Entrepreneur First</li> </ul> <ul> <li>Sparrho</li> </ul> <ul> <li>G-Research</li> </ul> <ul> <li>Open Book Publishers</li> </ul> <ul> <li>Cambridge Architectural   Research</li> </ul> <ul> <li>BT</li> </ul> <ul> <li>Illumina</li> </ul> <ul> <li>Cambridge Consultants</li> </ul>"},{"location":"2014_-_final_list_of_design_briefs.html","title":"2014","text":"<ul> <li>Multi Chat</li> </ul> <ul> <li>Recipe Curator</li> </ul> <ul> <li>Multi-touch Conference</li> </ul> <ul> <li>Money World</li> </ul> <ul> <li>Virtual Reality Trading   Desk</li> </ul> <ul> <li>Algo-Trading Game</li> </ul> <ul> <li>Intelligent Graph Reader</li> </ul> <ul> <li>The technical textbook of the   future</li> </ul> <ul> <li>Resilient and Rapid   Raspberries</li> </ul> <ul> <li>Unlocking the graphics power of the Raspberry   Pi</li> </ul> <ul> <li>Purchase Abandonment   Predictor</li> </ul> <ul> <li>Evolve a Pet</li> </ul> <ul> <li>Sound Garden</li> </ul> <ul> <li>Project Darknet</li> </ul> <ul> <li>Transport Game</li> </ul>"},{"location":"2015_-_final_list_of_clients.html","title":"2015   final list of clients","text":"<ul> <li>Morgan Stanley</li> </ul> <ul> <li>ARM</li> </ul> <ul> <li>TPP</li> </ul> <ul> <li>CSR</li> </ul> <ul> <li>Frontier</li> </ul> <ul> <li>BAE Systems Applied   Intelligence</li> </ul> <ul> <li>BAML</li> </ul> <ul> <li>Metaswitch Networks</li> </ul> <ul> <li>IMC</li> </ul> <ul> <li>JPMorgan</li> </ul> <ul> <li>Sparx</li> </ul> <ul> <li>G-Research</li> </ul> <ul> <li>Amazon</li> </ul> <ul> <li>Boeing</li> </ul> <ul> <li>Metaswitch Networks</li> </ul> <ul> <li>Fusepump</li> </ul> <ul> <li>Bloomberg</li> </ul>"},{"location":"2015_list.html","title":"2015","text":"<p>Complete list of design briefs to be advertised to students for 2015 group design projects.</p>"},{"location":"2015_list.html#live-coding-for-blind-children","title":"Live coding for blind children","text":""},{"location":"2015_list.html#planet-builder","title":"Planet Builder","text":""},{"location":"2015_list.html#multi-lingual-sms","title":"Multi-lingual SMS","text":""},{"location":"2015_list.html#building-the-matrix","title":"Building the Matrix","text":""},{"location":"2015_list.html#extrusion-finder","title":"Extrusion finder","text":""},{"location":"2015_list.html#intensive-care-for-ebola","title":"Intensive Care for Ebola","text":""},{"location":"2015_list.html#reinfection-monitor","title":"Reinfection Monitor","text":""},{"location":"2015_list.html#online-advice-assistant","title":"Online advice assistant","text":""},{"location":"2015_list.html#financial-trading-trends","title":"Financial Trading Trends","text":""},{"location":"2015_list.html#online-identity-for-the-base-of-the-pyramid","title":"Online Identity for the Base of the Pyramid","text":""},{"location":"2015_list.html#location-based-teaching","title":"Location-based teaching","text":""},{"location":"2015_list.html#wild-pet-science","title":"Wild Pet Science","text":""},{"location":"2015_list.html#culture-glasses","title":"Culture Glasses","text":""},{"location":"2015_list.html#flash-mob-learning","title":"Flash Mob Learning","text":""},{"location":"2015_list.html#ai-racing-market","title":"AI racing market","text":""},{"location":"2015_list.html#careers-from-here","title":"Careers from Here","text":""},{"location":"2015_list.html#micro-friends-video-diary","title":"Micro-friends video diary","text":""},{"location":"2015_list.html#retail-category-mapper","title":"Retail Category Mapper","text":""},{"location":"2015_list.html#audio-websites-on-smartphones","title":"Audio Websites on Smartphones","text":""},{"location":"2016_-_final_list_of_clients.html","title":"2016   final list of clients","text":"<ul> <li>JPMorgan</li> </ul> <ul> <li>Jagex</li> </ul> <ul> <li>Illumina</li> </ul> <ul> <li>Boeing</li> </ul> <ul> <li>Addenbrookes</li> </ul> <ul> <li>Morgan Stanley</li> </ul> <ul> <li>Frontier</li> </ul> <ul> <li>Bloomberg</li> </ul> <ul> <li>Dovetailed</li> </ul> <ul> <li>G-Research</li> </ul> <ul> <li>King Digital Entertainment</li> </ul> <ul> <li>IMC</li> </ul> <ul> <li>Bohemia Interactive   Simulations</li> </ul> <ul> <li>Metaswitch Networks</li> </ul> <ul> <li>BAML</li> </ul> <ul> <li>Amazon</li> </ul>"},{"location":"2016_list.html","title":"2016","text":"<p>Complete list of design briefs to be advertised to students for 2016 group design projects.</p> <p>(text_transcluded_from_individual_project_descriptions)</p>"},{"location":"2016_list.html#architecture-for-a-video-facebook","title":"Architecture for a Video Facebook","text":""},{"location":"2016_list.html#citizen-science-for-cancer","title":"Citizen Science for Cancer","text":""},{"location":"2016_list.html#digital-currency-for-public-good","title":"Digital Currency for Public Good","text":""},{"location":"2016_list.html#drive-by-age","title":"Drive by Age","text":""},{"location":"2016_list.html#dynamic-narrative","title":"Dynamic Narrative","text":""},{"location":"2016_list.html#edible-lego","title":"Edible Lego","text":""},{"location":"2016_list.html#equity-exchange","title":"Equity Exchange","text":""},{"location":"2016_list.html#eye-tests-on-demand","title":"Eye-Tests on Demand","text":""},{"location":"2016_list.html#fly-past-finance","title":"Fly-past Finance","text":""},{"location":"2016_list.html#intelligent-game-designer","title":"Intelligent Game Designer","text":""},{"location":"2016_list.html#listening-to-a-million-voices","title":"Listening to a million voices","text":""},{"location":"2016_list.html#pebble-jogging-app","title":"Pebble Jogging App","text":""},{"location":"2016_list.html#pocket-brain-surgeon","title":"Pocket Brain Surgeon","text":""},{"location":"2016_list.html#put-your-phone-to-work","title":"Put your phone to work","text":""},{"location":"2016_list.html#reducing-food-waste-with-iot","title":"Reducing food waste with IoT","text":""},{"location":"2016_list.html#safer-chicken-from-farm-to-fork","title":"Safer Chicken from Farm to Fork","text":""},{"location":"2016_list.html#sailing-by-sound","title":"Sailing by sound","text":""},{"location":"2016_list.html#simulated-stock-exchange","title":"Simulated Stock Exchange","text":""},{"location":"2016_list.html#surprise-the-singularity","title":"Surprise the Singularity","text":""},{"location":"2016_list.html#the-busking-bus-stop","title":"The Busking Bus-Stop","text":""},{"location":"2016_list.html#the-politics-of-wikipedia","title":"The Politics of Wikipedia","text":""},{"location":"2017_-_final_list_of_clients.html","title":"2017   final list of clients","text":"<ul> <li>ARM</li> </ul> <ul> <li>Informetis</li> </ul> <ul> <li>IMC</li> </ul> <ul> <li>Cambridge Legal Risk   Analytics</li> </ul> <ul> <li>Bohemia Interactive   Simulations</li> </ul> <ul> <li>British Antarctic Survey</li> </ul> <ul> <li>JPMorgan</li> </ul> <ul> <li>Morgan Stanley</li> </ul> <ul> <li>Cambridge University Press</li> </ul> <ul> <li>Microsoft</li> </ul> <ul> <li>Altitude Angel</li> </ul> <ul> <li>Frontier</li> </ul> <ul> <li>The Hut Group</li> </ul> <ul> <li>Cantab Capital</li> </ul> <ul> <li>IMC</li> </ul> <ul> <li>Boeing</li> </ul> <ul> <li>Cambridge Museums</li> </ul> <ul> <li>Kynesim</li> </ul> <ul> <li>UNEP World Conservation Monitoring   Centre</li> </ul> <ul> <li>Cydar</li> </ul>"},{"location":"2017_list.html","title":"2017","text":"<p>Complete list of design briefs to be advertised to students for 2017 group design projects.</p> <p>(text_transcluded_from_individual_project_descriptions)</p>"},{"location":"2017_list.html#air-quality-radar","title":"Air Quality Radar","text":""},{"location":"2017_list.html#antarctic-chasm-one","title":"Antarctic Chasm One","text":""},{"location":"2017_list.html#auto-archive","title":"Auto-Archive","text":""},{"location":"2017_list.html#class-y-action","title":"Class-y Action","text":""},{"location":"2017_list.html#drone-safety","title":"Drone Safety","text":""},{"location":"2017_list.html#eco-location","title":"Eco-Location","text":""},{"location":"2017_list.html#energy-with-social-conscience","title":"Energy with Social Conscience","text":""},{"location":"2017_list.html#financial-battlefield","title":"Financial Battlefield","text":""},{"location":"2017_list.html#history-phone","title":"History Phone","text":""},{"location":"2017_list.html#hololens-escape-room","title":"Hololens Escape Room","text":""},{"location":"2017_list.html#learn-to-be-an-alien","title":"Learn to be an Alien","text":""},{"location":"2017_list.html#micro-volunteering","title":"Micro-Volunteering","text":""},{"location":"2017_list.html#neural-guide","title":"Neural Guide","text":""},{"location":"2017_list.html#personal-reality","title":"Personal Reality","text":""},{"location":"2017_list.html#retail-startup-automator","title":"Retail Startup Automator","text":""},{"location":"2017_list.html#science-for-ad2500","title":"Science for AD2500","text":""},{"location":"2017_list.html#simulation-and-warning-for-cyclists","title":"Simulation and Warning for Cyclists","text":""},{"location":"2017_list.html#surgery-in-the-cloud","title":"Surgery in the Cloud","text":""},{"location":"2017_list.html#survey-swarm","title":"Survey Swarm","text":""},{"location":"2017_list.html#the-deep-learning-society","title":"The Deep Learning Society","text":""},{"location":"2017_list.html#vr-algorave-dj","title":"VR Algorave DJ","text":""},{"location":"2017_list.html#whos-at-my-party","title":"Who's at my party?","text":""},{"location":"2018_-_final_list_of_clients.html","title":"2018   final list of clients","text":"<ul> <li>Cambridge Museums</li> <li>Argon Design</li> <li>IMC</li> <li>Boeing</li> <li>Informetis</li> <li>Smart Cambridge</li> <li>JP Morgan</li> <li>Leapian</li> <li>Frontier</li> <li>Hamilton Kerr Institute</li> <li>Satavia</li> <li>Amazon</li> <li>UNEP World Conservation Monitoring   Centre</li> <li>Frontier</li> <li>Bohemia Interactive   Simulations</li> <li>Addenbrookes</li> </ul>"},{"location":"2018_list.html","title":"2018","text":"<p>Complete list of design briefs to be advertised to students for 2018 group design projects.</p> <p>(text transcluded from individual project descriptions - click on project title to edit original page)</p>"},{"location":"2018_list.html#anthropometrics-today","title":"Anthropometrics Today","text":""},{"location":"2018_list.html#audible-appliances","title":"Audible Appliances","text":""},{"location":"2018_list.html#augmented-reality-furnishing","title":"Augmented Reality Furnishing","text":""},{"location":"2018_list.html#autonomous-highway-system","title":"Autonomous highway system","text":""},{"location":"2018_list.html#citizen-speed-safety","title":"Citizen Speed Safety","text":""},{"location":"2018_list.html#energy-budget","title":"Energy Budget","text":""},{"location":"2018_list.html#every-car-in-cambridge","title":"Every Car in Cambridge","text":""},{"location":"2018_list.html#from-pdf-to-practice","title":"From PDF to Practice","text":""},{"location":"2018_list.html#mixed-reality-pdf-editor","title":"Mixed-reality PDF editor","text":""},{"location":"2018_list.html#opposing-views","title":"Opposing Views","text":""},{"location":"2018_list.html#pigment-analysis","title":"Pigment Analysis","text":""},{"location":"2018_list.html#predictive-aircraft-maintenance","title":"Predictive aircraft maintenance","text":""},{"location":"2018_list.html#real-time-ai-research","title":"Real-time AI research","text":""},{"location":"2018_list.html#sustainable-gaming","title":"Sustainable Gaming","text":""},{"location":"2018_list.html#the-adaptive-web","title":"The Adaptive Web","text":""},{"location":"2018_list.html#vr-ai-ping-pong-trainer","title":"VR AI Ping Pong Trainer","text":""},{"location":"2018_list.html#virtual-world-generator","title":"Virtual World Generator","text":""},{"location":"2018_list.html#way-to-the-clinic","title":"Way to the Clinic","text":""},{"location":"2018_list.html#wearable-house-control","title":"Wearable house control","text":""},{"location":"2019_-_final_list_of_clients.html","title":"2019   final list of clients","text":""},{"location":"2019_-_final_list_of_clients.html#confirmed-clients-for-2019","title":"Confirmed clients for 2019","text":"<ul> <li>ARM</li> </ul> <ul> <li>TPP</li> </ul> <ul> <li>Magna</li> </ul> <ul> <li>G-Research</li> </ul> <ul> <li>Infectious Diseases Institute   Kampala</li> </ul> <ul> <li>IMC</li> </ul> <ul> <li>SimPrints</li> </ul> <ul> <li>British Trust for   Ornithology</li> </ul> <ul> <li>British Antarctic Survey</li> </ul> <ul> <li>Jagex</li> </ul> <ul> <li>Lexsnap</li> </ul> <ul> <li>Argon Design</li> </ul> <ul> <li>Cambridge University   Herbarium</li> </ul> <ul> <li>Morgan Stanley</li> </ul> <ul> <li>Faraday Predictive</li> </ul> <ul> <li>KisanHub</li> </ul> <ul> <li>Frontier</li> </ul> <ul> <li>Studio Above&amp;Below</li> </ul>"},{"location":"2019_list.html","title":"2019","text":"<p>Complete list of design briefs to be advertised to students for 2019 group design projects.</p> <p>(text transcluded from individual project descriptions - click on project title to edit original page)</p>"},{"location":"2019_list.html#ai-chef","title":"AI Chef","text":""},{"location":"2019_list.html#bone-doctor","title":"Bone Doctor","text":""},{"location":"2019_list.html#clean-cycle","title":"Clean Cycle","text":""},{"location":"2019_list.html#competing-for-autonomy","title":"Competing for Autonomy","text":""},{"location":"2019_list.html#distributed-microcontracts","title":"Distributed Microcontracts","text":""},{"location":"2019_list.html#eyes-on-the-road","title":"Eyes on the Road","text":""},{"location":"2019_list.html#eyes-in-the-sky","title":"Eyes in the Sky","text":""},{"location":"2019_list.html#fever-finder","title":"Fever Finder","text":""},{"location":"2019_list.html#flyathlon-2019-version","title":"Flyathlon (2019 version)","text":""},{"location":"2019_list.html#grand-remote","title":"Grand Remote","text":""},{"location":"2019_list.html#groundwater-app","title":"Groundwater App","text":""},{"location":"2019_list.html#heroes-in-conference","title":"Heroes in Conference","text":""},{"location":"2019_list.html#lawbot","title":"LawBot","text":""},{"location":"2019_list.html#meeting-zoom","title":"Meeting Zoom","text":""},{"location":"2019_list.html#million-plant-map","title":"Million Plant Map","text":""},{"location":"2019_list.html#probable-causes","title":"Probable Causes","text":""},{"location":"2019_list.html#robot-death-watch","title":"Robot Death Watch","text":""},{"location":"2019_list.html#text-farming","title":"Text Farming","text":""},{"location":"2019_list.html#visual-pick-and-place","title":"Visual Pick and Place","text":""},{"location":"2019_list.html#vr-avatar","title":"VR Avatar","text":""},{"location":"2019_list.html#west-augmentation","title":"West Augmentation","text":""},{"location":"2020_-_final_list_of_clients.html","title":"2020   final list of clients","text":""},{"location":"2020_-_final_list_of_clients.html#confirmed-clients-for-2020","title":"Confirmed clients for 2020","text":"<ul> <li>Frontier</li> <li>Informetis</li> <li>CambridgeSpark</li> <li>NIAB</li> <li>Microsoft Research</li> <li>UNEP-WCMC</li> <li>UMZC</li> <li>Dovetailed</li> <li>Ocado</li> <li>IMC</li> <li>Ubisense</li> <li>Africas Voices Foundation</li> <li>Vet School</li> <li>MathWorks</li> <li>Grakn Labs</li> <li>Google UK</li> </ul>"},{"location":"2020_list.html","title":"2020","text":"<p>Complete list of design briefs to be advertised to students for 2020 group design projects.</p> <p>(text transcluded from individual project descriptions - click on project title to edit original page)</p>"},{"location":"2020_list.html#accessibility-assessor","title":"Accessibility Assessor","text":""},{"location":"2020_list.html#activity-analysis-from-smart-meter-data","title":"Activity Analysis from Smart Meter Data","text":""},{"location":"2020_list.html#automatic-assessment-of-r-code","title":"Automatic Assessment of R Code","text":""},{"location":"2020_list.html#automating-crop-canopy-data-collection-for-crop-management","title":"Automating Crop Canopy Data Collection for Crop Management","text":""},{"location":"2020_list.html#azure-sphere-for-citizen-science","title":"Azure Sphere for Citizen Science","text":""},{"location":"2020_list.html#collecting-farm-sourced-data-on-pest-and-disease-pressure","title":"Collecting Farm-sourced Data on Pest and Disease Pressure","text":""},{"location":"2020_list.html#ecosystem-game","title":"Ecosystem Game","text":""},{"location":"2020_list.html#electronically-cataloguing-butterflies","title":"Electronically Cataloguing Butterflies","text":""},{"location":"2020_list.html#ethical-surgery-assistant","title":"Ethical Surgery Assistant","text":""},{"location":"2020_list.html#feeding-body-and-mind","title":"Feeding Body and Mind","text":""},{"location":"2020_list.html#green-eyes","title":"Green Eyes","text":""},{"location":"2020_list.html#live-lecture-comprehension","title":"Live Lecture Comprehension","text":""},{"location":"2020_list.html#online-ticking-markbook","title":"Online Ticking Markbook","text":""},{"location":"2020_list.html#planning-tools-for-large-scale-location-tracking","title":"Planning Tools for Large Scale Location Tracking","text":""},{"location":"2020_list.html#probably-helpful-planning","title":"Probably Helpful Planning","text":""},{"location":"2020_list.html#remote-animal-recovery-monitoring","title":"Remote Animal Recovery Monitoring","text":""},{"location":"2020_list.html#robot-backgammon-arm","title":"Robot Backgammon Arm","text":""},{"location":"2020_list.html#robotic-warehouse-design-suite","title":"Robotic Warehouse Design Suite","text":""},{"location":"2020_list.html#supervisor-matching-system","title":"Supervisor Matching System","text":""},{"location":"2020_list.html#support-sustainable-wildlife-trade","title":"Support Sustainable Wildlife Trade","text":""},{"location":"2020_list.html#testing-a-logical-query-language","title":"Testing a Logical Query Language","text":""},{"location":"2020_list.html#trading-assistant","title":"Trading Assistant","text":""},{"location":"2020_list.html#travelling-businesswoman-problem","title":"Travelling Businesswoman Problem","text":""},{"location":"2020_list.html#workout-help-with-android-and-wearos","title":"Workout Help with Android and WearOS","text":""},{"location":"2021_-_final_list_of_clients.html","title":"2021   final list of clients","text":"<ul> <li>Ab Initio Software</li> <li>The Fusion Works</li> <li>TechWolf</li> <li>IMC</li> <li>DX Analytics</li> <li>Digital Boost</li> <li>Frontier</li> <li>Cambridge Conservation   Initiative</li> <li>Umbrella Analytics</li> <li>NIAB</li> <li>Boeing</li> <li>Lyzeum Ltd</li> <li>Metropolitan Police</li> <li>MathWorks</li> <li>Royal College of Paediatrics and Child   Health</li> <li>Microsoft Research</li> <li>Department of Zoology</li> <li>RSPB</li> </ul>"},{"location":"2021_list.html","title":"2021","text":"<p>Complete list of design briefs to be advertised to students for 2021 group design projects.</p> <p>(text transcluded from individual project descriptions - click on project title to edit original page)</p>"},{"location":"2021_list.html#aerial-video-selfies","title":"Aerial Video Selfies","text":""},{"location":"2021_list.html#augmented-room-dressing-for-zoom","title":"Augmented Room Dressing for Zoom","text":""},{"location":"2021_list.html#boosting-skills-after-covid-19","title":"Boosting Skills after COVID-19","text":""},{"location":"2021_list.html#cascading-galton-boards","title":"Cascading Galton Boards","text":""},{"location":"2021_list.html#clinical-nursing-for-children","title":"Clinical Nursing for Children","text":""},{"location":"2021_list.html#computing-for-bird-colonies","title":"Computing for Bird Colonies","text":""},{"location":"2021_list.html#consignment-tetris","title":"Consignment Tetris","text":""},{"location":"2021_list.html#crossing-the-bubbles","title":"Crossing the Bubbles","text":""},{"location":"2021_list.html#de-biasing-the-employment-process","title":"De-biasing the Employment Process","text":""},{"location":"2021_list.html#deliberative-social-media","title":"Deliberative Social Media","text":""},{"location":"2021_list.html#galapagoan-machine-learning","title":"Galapagoan Machine Learning","text":""},{"location":"2021_list.html#instrument-landing-app","title":"Instrument Landing App","text":""},{"location":"2021_list.html#intelligent-tools-for-coeliac-disease-diagnosis","title":"Intelligent Tools for Coeliac Disease Diagnosis","text":""},{"location":"2021_list.html#managing-agile-researchers","title":"Managing Agile Researchers","text":""},{"location":"2021_list.html#mapping-the-missing","title":"Mapping the Missing","text":""},{"location":"2021_list.html#online-loop-jam","title":"Online Loop Jam","text":""},{"location":"2021_list.html#remote-reading","title":"Remote Reading","text":""},{"location":"2021_list.html#speeding-up-evidence-synthesis-for-conservation","title":"Speeding Up Evidence Synthesis for Conservation","text":""},{"location":"2021_list.html#the-new-internet-of-things","title":"The New Internet of Things","text":""},{"location":"2021_list.html#virtual-agronomist","title":"Virtual Agronomist","text":""},{"location":"2021_list.html#west-cambridge-airfreight","title":"West Cambridge Airfreight","text":""},{"location":"2021_list.html#zoom-into-books","title":"Zoom into Books","text":""},{"location":"2022_-_final_list_of_clients.html","title":"2022   final list of clients","text":"<ul> <li>The Fusion Works</li> <li>Frontier</li> <li>Amazon</li> <li>Dovetailed</li> <li>JP Morgan</li> <li>Centre for Policy Futures</li> <li>Gardin</li> <li>ICCCAD</li> <li>Antobot</li> <li>IMC</li> <li>Morgan Stanley</li> <li>Cambridge Enterprise</li> <li>Curriculum for Life</li> <li>RSPB</li> <li>BigPay</li> <li>Royal College of Music</li> <li>British Trust for   Ornithology</li> <li>University Information   Services</li> </ul>"},{"location":"2022_list.html","title":"2022","text":"<p>Complete list of design briefs to be advertised to students for 2022 group design projects.</p> <p>(text transcluded from individual project descriptions - click on project title to edit original page)</p>"},{"location":"2022_list.html#carbon-accounting","title":"Carbon Accounting","text":""},{"location":"2022_list.html#conservation-evidence-synthesis","title":"Conservation Evidence Synthesis","text":""},{"location":"2022_list.html#creative-community","title":"Creative Community","text":""},{"location":"2022_list.html#empathetic-chatbot","title":"Empathetic Chatbot","text":""},{"location":"2022_list.html#exhibition-inference","title":"Exhibition Inference","text":""},{"location":"2022_list.html#flyathlon","title":"Flyathlon","text":""},{"location":"2022_list.html#global-ground-truth","title":"Global Ground Truth","text":""},{"location":"2022_list.html#green-maps","title":"Green Maps","text":""},{"location":"2022_list.html#household-payment-pool","title":"Household Payment Pool","text":""},{"location":"2022_list.html#international-treasury-service","title":"International Treasury Service","text":""},{"location":"2022_list.html#migration-simulation","title":"Migration Simulation","text":""},{"location":"2022_list.html#mobilising-the-university","title":"Mobilising the University","text":""},{"location":"2022_list.html#online-programming-game","title":"Online Programming Game","text":""},{"location":"2022_list.html#personal-ambiguator","title":"Personal Ambiguator","text":""},{"location":"2022_list.html#reading-the-leaves","title":"Reading the Leaves","text":""},{"location":"2022_list.html#smart-climate-goals","title":"SMART Climate Goals","text":""},{"location":"2022_list.html#smart-bins","title":"Smart Bins","text":""},{"location":"2022_list.html#social-media-wellbeing-filter","title":"Social Media Wellbeing Filter","text":""},{"location":"2022_list.html#strawberry-fields","title":"Strawberry Fields","text":""},{"location":"2022_list.html#the-automatic-accountant","title":"The Automatic Accountant","text":""},{"location":"2022_list.html#urban-stories","title":"Urban Stories","text":""},{"location":"2022_list.html#video-bones","title":"Video Bones","text":""},{"location":"2022_list.html#wiki-editor-editor","title":"Wiki Editor-Editor","text":""},{"location":"2022_list.html#youth-led-future","title":"Youth-led Future","text":""},{"location":"2023_list.html","title":"2023","text":"<p>Complete list of design briefs to be advertised to students for 2023 group design projects.</p> <p>(text transcluded from individual project descriptions - click on project title to edit original page)</p>"},{"location":"2023_list.html#a-teaspoon-of-video","title":"A Teaspoon of Video","text":""},{"location":"2023_list.html#ai-hype-monitor","title":"AI Hype Monitor","text":""},{"location":"2023_list.html#automatic-entrepreneur","title":"Automatic Entrepreneur","text":""},{"location":"2023_list.html#autonomous-trucking","title":"Autonomous Trucking","text":""},{"location":"2023_list.html#dont-stop-the-music","title":"Don\u2019t Stop the Music","text":""},{"location":"2023_list.html#electric-motor-optimisation","title":"Electric Motor Optimisation","text":""},{"location":"2023_list.html#email-diplomacy","title":"Email Diplomacy","text":""},{"location":"2023_list.html#fossil-or-future","title":"Fossil or Future?","text":""},{"location":"2023_list.html#genomics-for-the-covid-endemic","title":"Genomics for the COVID Endemic","text":""},{"location":"2023_list.html#imoji","title":"iMoji","text":""},{"location":"2023_list.html#just-maps","title":"Just Maps","text":""},{"location":"2023_list.html#keeping-key-workers","title":"Keeping Key-Workers","text":""},{"location":"2023_list.html#likeness-trainer","title":"Likeness Trainer","text":""},{"location":"2023_list.html#modularsynthio","title":"ModularSynth.io","text":""},{"location":"2023_list.html#nfts-for-digital-cvs","title":"NFTs for Digital CVs","text":""},{"location":"2023_list.html#physical-computing-for-beginners","title":"Physical Computing for Beginners","text":""},{"location":"2023_list.html#rational-trading","title":"Rational Trading","text":""},{"location":"2023_list.html#real-life-arabic","title":"Real Life Arabic","text":""},{"location":"2023_list.html#responsible-ai-copilot","title":"Responsible AI Copilot","text":""},{"location":"2023_list.html#responsible-construction","title":"Responsible Construction","text":""},{"location":"2023_list.html#robot-farm-monitor","title":"Robot Farm Monitor","text":""},{"location":"2023_list.html#signs-of-our-times","title":"Signs of our Times","text":""},{"location":"2023_list.html#speak-in-the-country","title":"Speak in the Country","text":""},{"location":"2024_list.html","title":"2024","text":"<p>Complete list of design briefs to be advertised to students for 2024 group design projects.</p> <p>(text transcluded from individual project descriptions - click on project title to edit original page)</p>"},{"location":"2024_list.html#acoustic-land-management","title":"Acoustic Land Management","text":""},{"location":"2024_list.html#braille-predictive-text","title":"Braille Predictive Text","text":""},{"location":"2024_list.html#climate-foresight","title":"Climate Foresight","text":""},{"location":"2024_list.html#component-quest","title":"Component Quest","text":""},{"location":"2024_list.html#copilot-for-business","title":"Copilot for Business","text":""},{"location":"2024_list.html#creative-writing-coach","title":"Creative Writing Coach","text":""},{"location":"2024_list.html#disability-bias-explorer","title":"Disability Bias Explorer","text":""},{"location":"2024_list.html#dos-d-stress","title":"DoS D-Stress","text":""},{"location":"2024_list.html#engaging-everyone","title":"Engaging Everyone","text":""},{"location":"2024_list.html#envisioning-nairobi","title":"Envisioning Nairobi","text":""},{"location":"2024_list.html#heterodox-economic-modeller","title":"Heterodox Economic Modeller","text":""},{"location":"2024_list.html#influencing-health","title":"Influencing Health","text":""},{"location":"2024_list.html#investment-provenance","title":"Investment Provenance","text":""},{"location":"2024_list.html#memories-retold","title":"Memories Retold","text":""},{"location":"2024_list.html#optimising-music-notation","title":"Optimising Music Notation","text":""},{"location":"2024_list.html#p2p-social-network","title":"P2P Social Network","text":""},{"location":"2024_list.html#ramping-up-sustainable-crops","title":"Ramping Up Sustainable Crops","text":""},{"location":"2024_list.html#real-pedia","title":"Real-pedia","text":""},{"location":"2024_list.html#supply-chain-resilience","title":"Supply Chain Resilience","text":""},{"location":"2024_list.html#talking-music","title":"Talking Music","text":""},{"location":"2024_list.html#taste-movies-x-books-x-music","title":"Taste: Movies x Books x Music","text":""},{"location":"2024_list.html#testing-for-humans","title":"Testing for Humans","text":""},{"location":"2024_list.html#visiting-the-forest-stream","title":"Visiting the Forest Stream","text":""},{"location":"2024_list.html#wearable-sleep-coach","title":"Wearable Sleep Coach","text":""},{"location":"2024_list.html#world-craft","title":"World Craft","text":""},{"location":"2025_list.html","title":"2025 list","text":"<p>Complete list of design briefs to be advertised to students for 2025 group design projects.</p> <p>(text transcluded from individual project descriptions - click on project title to edit original page)</p>"},{"location":"2025_list.html#agent-of-things","title":"Agent of Things","text":""},{"location":"2025_list.html#atmospheric-metaverse","title":"Atmospheric Metaverse","text":""},{"location":"2025_list.html#bs-meter","title":"BS-meter","text":""},{"location":"2025_list.html#care-phone","title":"Care Phone","text":""},{"location":"2025_list.html#chat-twin","title":"Chat-twin","text":""},{"location":"2025_list.html#checkpoint-alternatives","title":"Checkpoint Alternatives","text":""},{"location":"2025_list.html#chesspuzzy","title":"ChessPuzzy","text":""},{"location":"2025_list.html#code-explain-ai-assistant","title":"Code Explain AI Assistant","text":""},{"location":"2025_list.html#computing-physical-calculus","title":"Computing Physical Calculus","text":""},{"location":"2025_list.html#conversational-patient-history","title":"Conversational Patient History","text":""},{"location":"2025_list.html#cuda-support-for-clangir","title":"CUDA Support for ClangIR","text":""},{"location":"2025_list.html#delivery-radar","title":"Delivery Radar","text":""},{"location":"2025_list.html#driverless-humans","title":"Driverless Humans","text":""},{"location":"2025_list.html#grasping-concept-spaces","title":"Grasping Concept Spaces","text":""},{"location":"2025_list.html#navigating-evolving-music","title":"Navigating Evolving Music","text":""},{"location":"2025_list.html#paper-simulator","title":"Paper Simulator","text":""},{"location":"2025_list.html#personalised-eula-visualisation","title":"Personalised EULA Visualisation","text":""},{"location":"2025_list.html#promptpatrol","title":"PromptPatrol","text":""},{"location":"2025_list.html#robot-science-ambassador","title":"Robot Science Ambassador","text":""},{"location":"2025_list.html#soft-music-notation","title":"Soft Music Notation","text":""},{"location":"2025_list.html#speech-error-detection-and-correction","title":"Speech Error Detection and Correction","text":""},{"location":"2025_list.html#talk-interactive","title":"Talk Interactive","text":""},{"location":"2025_list.html#training-investigative-interviewers","title":"Training Investigative Interviewers","text":""},{"location":"2025_list.html#visual-analytics-for-hardware-design","title":"Visual Analytics for Hardware Design","text":""},{"location":"2025_list.html#zeitgeist-map","title":"Zeitgeist Map","text":""},{"location":"AI_Chef.html","title":"AI Chef","text":"<p>Isabella.Gottardi@arm.com</p> <p>Arm is creating optimised computer vision and machine learning libraries for processors like the one in your phone. Anyone can train a neural network using these libraries to recognize images of vegetables, animals, objects, etc so long as they have enough examples of labelled classification decisions. In a vegetable market, the stallholder has \"labelled\" all the vegetables by putting them in different bins. So AI Chef aims to train a network that will use those thousands of those labels (from phone video) to solve the eternal dilemma \"what do we eat this evening?\": standing in front of a stall at the Cambridge Sunday market, AI Chef automatically recognizes which vegetables are on sale, identifies a recipe based on them and provides you with a shopping list of the other things you need to buy before you go home to cook.</p>"},{"location":"AI_Hype_Monitor.html","title":"AI Hype Monitor","text":"<p>Tomasz Hollanek, LCFI th536@cam.ac.uk</p> <p>Researchers critical of the persistent 'AI hype' \u2013 driven by flashy headlines and corporate communications \u2013 have pointed to the harmful effects that misrepresentations of AI in the media might have on public perceptions of the technology. Your task is to create an automated monitor of AI hype content, based on a predetermined classification system of particularly problematic metaphors and comparisons common in news articles about AI that circulate on social media. Ideally, the AI Hype Monitor could be used as an add-on filter for chosen social media applications, flagging up problematic content and pointing users to sources that represent current AI capabilities more accurately and responsibly.</p>"},{"location":"AI_racing_market.html","title":"AI racing market","text":"<p>Dominic.Nancekievill@gresearch.co.uk</p> <p>As AI-controlled vehicles like Google's Self-Driving Car become more common, the person who gets to work fastest will be the one with the best algorithms. Your task is to create a competitive market in which members of the public can submit algorithms to see which is the best. You'll need to define a simple scripting language and API suitable for creating the entries. Users should be able to enter their script directly into an interactive game then see its performance in an actual real-time car race created with the Unity graphics engine and physics model. The best entries should be stored and ranked in a leader board, with new players able to see existing code and tweak it for better performance. In future, this kind of algorithm market could be applied to other problem domains such as finance.</p>"},{"location":"AMD.html","title":"AMD","text":"<p>To be followed up with:</p> <p>\"Bonsor-Matthews, Jonathan\" Jonathan.Bonsor-Matthews@amd.com \"McConnell, Daniel\" Daniel.McConnell@amd.com \"Fox, James\" james.fox@amd.com \"Porter, Martin\" martin.porter@amd.com \"Sadleir, Daisy\" daisy.sadleir@amd.com</p>"},{"location":"ARM.html","title":"ARM","text":""},{"location":"ARM.html#2026","title":"2026","text":"<p>Tobias has been in contact with Hrutvik Kanabar Hrutvik.Kanabar2@arm.com, with respect to ISA semantics on ARM and/or exploring Lean as a verification tool.</p>"},{"location":"ARM.html#2021","title":"2021","text":"<p>Pawel Moll Pawel.Moll@arm.com is interested</p>"},{"location":"ARM.html#2020","title":"2020","text":"<p>Pawel Moll Pawel.Moll@arm.com would be happy to receive an invitation</p> <p>federico.garzadeleon@arm.com has been discussing volunteer work on digital projects at the Fitzwilliam Museum, and would like to see a group project on a related topic.</p>"},{"location":"ARM.html#2019","title":"2019","text":"<p>Following discussion led to AI Chef with client Isabella.Gottardi@arm.com</p> <p>Around 466 million people in the world, including 34 million children cannot use communication channels that most of us take for granted. It is estimated that by 2050, one in every ten people will have a disabling hearing loss and many more will suffer some sort of speech disability.</p> <p>In UK, more than 70,000 people use the British Sign Language (BSL) as their main language. BSL has its own vocabulary and structure of grammar and is expressed through hand shapes, facial expression, gestures and body language.</p> <p>Machine Learning and Neural Networks can help to translate gestures into words. We need your help to improve social interaction and bridge the gap between the Deaf and Hearing communities with efficient, interactive communication tools. Be part of the team that through a mobile app and using Arm Machine Learning Software offers a real-time translation from BSL to words.</p>"},{"location":"ARM.html#feedback","title":"feedback","text":"<p>I wasn\u2019t aware that Arm has created a set of Machine Learning tools, and would like to learn more about them. This would certainly be a good technical focus for a project. Are you aware of a training corpus for BSL experiments? I\u2019m not aware that we have any BSL users in our department at present, so if you had connections to a local BSL group, that would be very useful for testing and application focus.</p>"},{"location":"ARM.html#2017","title":"2017","text":"<p>Khaled Benkrid Khaled.Benkrid@arm.com</p> <p>Sean Hong Sean.Hong@arm.com</p> <p>Ashkan Tousimojarad Ashkan.Tousimojarad@arm.com</p> <p>Xabier Iturbe Xabier.Iturbe@arm.com</p> <p>1. Hypbrid IoT System Development Framework</p> <p>The concept of Internet-of-Things (IoT) is becoming a reality. As it evolves, we need ways to control and interact with plethora of connected devices.</p> <p>There are several ways to develop interfaces for IoT devices. However, the range of technologies and skills involved makes the development cost too high for an average developer. In light of the above, our proposal is to develop an IoT system development framework to make it easier to design and build IoT systems.</p> <p>HTML5 mobileUI frameworks, such as Ionic [1], allows for building cross-platform hybrid apps by using web development technologies: HTML5 and JavaScript. We also plan to integrate a cloud based \u201cBackend as a Service\" (BaaS) solution such as Firebase [2] into our framework as a part of cloud data storage (and computing).</p> <p>The proposed hybrid IoT system development framework will include the following capabilities: \u00b7 Easy to use Graphical User Interface (GUI) for app development at hub/cloud level</p> <p>\u00b7 Connectivity utilities, including Wifi and Bluetooth</p> <p>\u00b7 Location utilities, e.g. using GPS or Wifi</p> <p>\u00b7 Embedded systems programming and interfacing at node level (e.g. using ARM mbed [3])</p> <p>At least one demonstrator application will be developed using the above framework (e.g. SWARM Intelligence)</p> <p>[1] http://ionicframework.com/</p> <p>[2] https://firebase.google.com/</p> <p>[3] https://developer.mbed.org/cookbook/Interfacing-with-JavaScript</p> <p>Clarification:</p> <p><code>Since\u00a0this\u00a0is\u00a0for\u00a0second\u00a0year\u00a0students\u00a0and\u00a0there\u00a0are\u00a0time\u00a0constraints,\u00a0we\u00a0might\u00a0need\u00a0to\u00a0simplify\u00a0the\u00a0project.\u00a0We\u00a0are\u00a0also\u00a0open\u00a0about\u00a0the\u00a0demonstrator\u00a0application.\u00a0Swarm\u00a0Intelligence\u00a0is\u00a0just\u00a0an\u00a0option\u00a0(e.g.\u00a0depending\u00a0on\u00a0your\u00a0lab\u00a0facilities,\u00a0a\u00a0dozen\u00a0of\u00a0IoT-aided\u00a0robotic\u00a0swarms\u00a0at\u00a0a\u00a0mission\u00a0in\u00a0a\u00a0hazardous\u00a0environment).\u00a0Please\u00a0feel\u00a0free\u00a0to\u00a0suggest\u00a0other\u00a0applications.</code></p> <p>What lab facilities were you thinking of? We can probably simulate a \u201chazardous\u201d environment for the public demo day - and this could be good fun. We don\u2019t have a dozen robots, though!</p> <p>2. Convolutional Neural Networks \u2013 FPGA Prototyping</p> <p>Convolutional Neural Networks (CNNs) and deep learning are expected to help processing the huge amount of data to be produced by IoT-enabled devices and are already being used in driverless cars to detect pedestrians and recognise traffic signals. The challenge here is to implement a generic and scalable CNN that can be easily adapted for a wide range of different applications.</p> <p>We propose to design a software-configurable CNN and integrate it on an ARM CPU-centric System-on-Chip (SoC) prototyped on an FPGA. This system will be tested using a proof-of-concept application.</p>"},{"location":"ARM.html#2015","title":"2015","text":"<p>Contact in 2015: Dominic Vergine Dominic.Vergine@arm.com</p> <p>'Pawel Moll' Pawel.Moll@arm.com</p> <p>'Lee Smith' Lee.Smith@arm.com</p> <p>Intensive Care for Ebola</p> <p>One of the major challenges in Ebola outbreak regions is information management. Most patient care is done by people with neither medical or IT experience, and often low levels of literacy. Their training is often only 3 or 4 days, mostly focusing on hygiene and use of protective clothing. Your goal is to create an electronic patient record system that will run on a smartphone, suited to the network connections, power supply and hardware limitations in rural Africa. The system should help regular collection and progression monitoring of symptom reports and vital signs as would be done in a hospital intensive care unit. It might also present users with advice on triage and patient care. Deployment should be easily customisable for local languages, and provide mechanisms to feed data back to international coordination bodies such as the World Health Organisation.</p> <p>Online Identity for the Base of the Pyramid</p> <p>Initiatives such as Girl Effect and Africa's Voices provide new content channels for the poorest people in developing countries to gain a visible online identity. How could you minimise the educational and financial obstacles to their visibility in the global media ecosystem? SMS hubs, or Raspberry Pi with cameras? Are keyboards, screens or batteries actually essential? You'll need to consider the whole system: network infrastructure, content propagation if servers aren't powered up 24/7, literacy and appropriate interaction mechanisms for those whose technical expertise may be limited, but who will be empowered by gaining new skills.</p> <p>Wild Pet Science</p> <p>Children are often strong supporters of wildlife conservation, but also have pets of their own. The goal of this project is to help them engage with the science of wildlife tracking (via public data sources such as movebank.org), comparing that data to monitoring information that they collect themselves. Although Movebank uses GPS, sonar and other expensive techniques, you could use simple image analysis from a Raspberry Pi time-lapse camera to identify the position of a goldfish, a guinea pig or a hamster in its cage. Children should be able to use the data they collect to make comparisons between their own pets and wild animals - this might include foraging behaviour, \"migrations\" or seasonal variation in activity.</p> <p>Other ideas::</p> <p>\"I'm sorry Dave, I'm afraid I can't do that\" is one of the iconic quotation in SF cinema history. Let's make it happen again!</p> <p>Raspberry Pi can process images using its camera interface and &gt; audio using external sound interface. Basing on this, build a \"HAL 9001\" &gt; module (as technology moved forward since 2001, it doesn't have to as &gt; big as the original 9000 version, however extra points for a round, &gt; red-glowing eye on its enclosure :-) that will recognize and greet &gt; registered users (and record aliens), answer questions about time, &gt; weather, notify the user about new email and/or social media messages,</p> <p>read day schedule etc.</p> <p>As a stretch goal, HAL 9001 \"IoT Edition\" could be also used to &gt; control external appliances, for example lighting in the room (think \"Computer! &gt; Lights!\" command used every second on board of NCC-1701* ships). &gt; Communication should preferably be using Bluetooth Low Energy based &gt; protocols, with mBed boards as nodes. The \"smart home\" could be also &gt; simulated on an external PC/tablet and controlled via Rapberry Pi's &gt; Ethernet (or WiFi) interface.</p>"},{"location":"A_Teaspoon_of_Video.html","title":"A Teaspoon of Video","text":"<p>Computer Science education expert Mark Guzdial suggests kids can learn effectively from Task-Specific Programming (TSP, or \"teaspoon\") languages that can be learned in a few minutes, teaching one idea from theoretical CS (the medicine?) in the context of a motivational and interesting automation task (like a teaspoon of sugar to help it go down). Your job is to create one of these educational languages, that teaches an important computing concept in a form relevant to processing social media video.</p>"},{"location":"A_platform_for_live_online_modding.html","title":"A platform for live online modding","text":"<p>In sandbox games like Minecraft, the only way to define more interesting game scenarios is to write and install Java mods. It is possible to make automatic behaviours in the Minecraft world, but only using the cumbersome \"redstone\" logic blocks. The goal of this project is to make a new multi-player sandbox game, based on a 2D grid, where users can define more complex behaviours by clicking on a grid element to embed pieces of code written in a scripting language like Lua. You are welcome to use a commercial or open source rendering engine, but maintaining a shared persistent world will still involve solving problems of persistence, networking, live world management and session control.</p>"},{"location":"Ab_Initio_Software.html","title":"Ab Initio Software","text":"<p>Contact for 2022:</p> <p>Lauren Teasdale LTeasdale@ABINITIO.com</p> <p>Idea for 2022:</p> <p>Centralized control of self-driving trucks</p> <p>Autonomous vehicles are likely a wave of the future. A lot of effort is going into automating the control of individual vehicles to provide a self-driving version of our current experience. An alternative is centralized control of fleets of vehicles to optimize large-scale traffic flow. This is a simpler problem which might be very appealing for transport of goods by truck. The brief is to build a simulation environment to demonstrate centralized control of a fleet of trucks. The simulation should consist of three elements: a) a traffic optimization algorithm which achieves maximal transport of goods, given boundary conditions for trucks joining and leaving the flow of traffic, b) a visualization of the traffic flow, c) control of the traffic variables, including highway pattern (on-ramps, off-ramps), rates of trucks entering and leaving the traffic pattern, basic dynamic properties of trucks (e.g. maximum rate of acceleration/deceleration).</p> <p>Potential Client: Arley Anderson</p> <p>2021 project: Crossing the Bubbles</p>"},{"location":"Above_and_Below.html","title":"Above and Below","text":"<p>Introduced by Collusion</p> <p>Contacts:</p> <p>daria@studioaboveandbelow.com</p> <p>\"perry@studioaboveandbelow.com\" perry@studioaboveandbelow.com</p>"},{"location":"Accessibility_Assessor.html","title":"Accessibility Assessor","text":"<p>mjohnson@frontier.co.uk</p> <p>Today, with smart phones being such powerful computational devices equipped with cameras the opportunity to capture data from the world around us has greatly increased. This project aims to produce a piece of software which can be used on a smartphone to capture the 3d shape of an interior environment in order to produce a simplified computer model. This model may then be processed, perhaps by another device in order to produce a node graphed plan of the floorspace. This plan could provide useful views of the space in terms of accessibility and aiding planning usage of existing space.</p>"},{"location":"Acoustic_Land_Management.html","title":"Acoustic Land Management","text":"<p>Land managers are often responsible for restoration projects, in which they make changes expected to benefit wildlife over time. One very useful source of evidence is acoustic data recordings. This project is intended to create an interactive application that can be used by land managers to visualise, make decisions, monitor, and evaluate their interventions, based on bioacoustic survey data processed through the BTO acoustic pipeline and enhanced with machine learning methods.</p>"},{"location":"Activity_Analysis_from_Smart_Meter_Data.html","title":"Activity Analysis from Smart Meter Data","text":"<p>jose.alcala@informetis.com</p> <p>A rapidly aging population means assisted living is fast becoming a major societal challenge. To support \u201cCarers\u201d assisting \u201cCarees\u201d, local technology company Informetis provides smart sensors installed in the fuse-box that determine if household appliances are ON/OFF. As routines are typically closely related to appliance use, this proxies for inhabitants' wellness. Your task is to create an app for carers to support householders when they struggle to perform daily routines. You may choose focus on detection of activities from the raw data, or the interaction design challenges of choosing what should be communicated to the carer and when.</p>"},{"location":"Activity_Recognition_and_Analysis_based_on_Smart_Meter_Data.html","title":"Activity Recognition and Analysis based on Smart Meter Data","text":"<ol> <li>REDIRECT Activity Analysis from Smart Meter     Data</li> </ol>"},{"location":"Addenbrookes.html","title":"Addenbrookes","text":"<p>Original contact: \"Allen, Louise\" louise.allen@addenbrookes.nhs.uk</p>"},{"location":"Addenbrookes.html#2018-agreed","title":"2018 agreed","text":"<p>Way to the Clinic</p> <p>with Stefanie Reichelt reichelt.stefanie@gmail.com</p>"},{"location":"Addenbrookes.html#2016-agreed","title":"2016 agreed","text":"<p>Eye-Tests on Demand</p> <p>Louise notes: If the test is to be useful in clinical practice the matching process is important a 50/50 chance of getting the correct answer won't do!</p>"},{"location":"Addenbrookes.html#earlier-suggestion","title":"earlier suggestion","text":"<p>DIY eye-tests</p> <p>Many people would benefit from a way to take calibrated eye tests at home or in public places, rather than requiring special equipment and professional supervision. Your task is to design a visual acuity test that can be set up and administered using two screens - one four metres away, and one in the user's hand (their own phone or tablet). The distant screen could be anything capable of running a web browser, such as a TV or public display, with authenticated coordination to the user\u2019s phone via a separate HTTP server. Once the test starts, users will need to operate the local device without looking at it - using easy touch controls, with instructions given by audio. You\u2019ll need to investigate the relevant standards and procedures to ensure that the result is clinically valid.</p>"},{"location":"Addenbrookes.html#original-background","title":"Original background","text":"<p>There are two projects, the simplest is a DIY visual acuity testing system for hospitals / vision screening in the community</p> <p>We see over 50,000 patients a year in the eye out patients dept at Addenbrooke's and this sort of number is typical for a large teaching hospital. Every patient has to have a test of visual acuity (threshold of resolution, tested in a clinic setting using a Snellen or LogMAR chart) before they have other tests and their consultation. This is the bottleneck of the clinic because a nurse currently has to do every visual acuity test and we only have 2 nurses to do this despite having 8 doctors seeing patients in clinic. Each test takes about 10 minute so you can see how easy it is to fall behind.</p> <p>I estimate that about 30% of patients would be able to assess their own visual acuity if given an automated process, which is what I am looking to develop. My idea is to have a touch screen tablet in front of the patient which drives a second monitor 4 metres away. Optotype letters would be shown on the distant screen, decreasing in size using a staircase algorithm and the patient would match the letter to one of a number displayed on the tablet screen in front of them until they make 50% errors. This would then give a threshold visual acuity which would be recorded.</p> <p>The optotype standards / sizes are well established. Auditory and visual instructions would need to inform the patients what to do. We could use accepted optotypes for kids - who would probably respond more positively to this as a game than most of the elderly.</p> <p>I imagine that it might be a little like the automated check outs in supermarkets, gradually people will prefer to use the system so they get through quicker!</p> <p>The second project is to work on a visual acuity testing system for pre-verbal children. I have previously developed a system called KidzEyez which is now licenced which uses a webcam feed from the centre of a display screen to monitor the responsive eye movements of an infant to cartoon targets appearing in the periphery of the screen - which informs us about the peripheral visual field of the infant. I have the prototype at Addenbrooke's. Hazel Kay (who developed the established Kays pictures visual acuity cards for children) and I would like to develop a visual acuity test along the same lines - giving the infant two targets of diminishing size to distinguish between and measuring visual acuity as the smallest size of optotype to which the child sees and looks towards. See  for info about Kidzeyez."},{"location":"Aerial_Video_Selfies.html","title":"Aerial Video Selfies","text":"<p>cedric.barreteau@imc.com</p> <p>A recent viral video of a guy singing the Fleetwood Mac song Dreams, while skateboarding down the road, was swiftly followed by a similar video from Mick Fleetwood himself. But isn't it a bit dangerous for 73 year-olds to be filming themselves like that? Your task is to design a drone control system that follows a planned camera path while maintaining focus on a moving person, taking good quality aerial close-up video as they skateboard, bicycle, or just walk. It would be particularly impressive to use information like bluetooth signals and computer vision to automatically recognise and follow even an unplanned path. The result would be great for sports coverage, and could even be the future of mobile Zoom.</p>"},{"location":"Africas_Voices_Foundation.html","title":"Africas Voices Foundation","text":"<p>2020 project: Probably Helpful Planning</p> <p>Draft:</p> <p>Basic idea is to create a front end to a probabilistic programming language (e.g. Stan) that allows evaluation of likelihood models for famine relief scenarios. Results should be usable by UN aid workers. Technical challenge will be creating a geographic distribution model that reflects differing degrees of certainty that a delivery will be made, and compare investment scenarios. There will be an opportunity for members of the team to interact with a student team from Potsdam, also working with AVF.</p>"},{"location":"AfroInsight.html","title":"AfroInsight","text":"<p>AfroBarometer is a pan-African research network that collects public attitude data on a variety of topics, including health. The World Health Organization (WHO) is interested in using AfroBarometer data to inform its global approaches to health information campaigns. However, the data is currently in a proprietary format and can be difficult to access and use, especially for non-technical users. Challenge: Develop a front-end application that allows users to ask questions of AfroBarometer data in a more intuitive and accessible way.</p>"},{"location":"Agent_of_Things.html","title":"Agent of Things","text":"<p>Many people are concerned that their phone provider (whether Apple, Samsung or Google) effectively controls their whole life, tying them in to an ecosystem of other products and services. This is very different from an earlier age, when the Internet of Things was expected to provide \u201cinformation appliances\u201d that offered self-contained functionality rather than surveillance capitalism. Your task is to prototype a privacy-preserving digital twin architecture that allows customers to interface in an intelligent way with specific devices (examples in Cambridge might be a smart bicycle with embedded GoPro, or the door lock of your college room), while strictly constraining the way this functionality gets connected to other parts of their digital life.</p>"},{"location":"Air_Quality_Radar.html","title":"Air Quality Radar","text":"<p>Matthew.Smith@microsoft.com</p> <p>Rain radar apps are familiar and popular - allowing people to plan their activities by approaching rain. This project will create the first \u201cair radar\u201d that uses monitoring of multiple air quality parameters to predict air movement and local variations in pollution. We can provide access to recordings of air quality data streams from multiple locations around Cambridge, and also the Microsoft Cortana Intelligence Suite under Azure. You should use machine learning techniques to predict what happens next. This will involve collecting and integrating other data such as time of day, traffic movements, temperature, wind speed and other factors. Your current situation maps and future trend predictions should be useful not only to cyclists and residents, but to business analysts and city planners concerned with future environmental health.</p>"},{"location":"Air_Radar.html","title":"Air Radar","text":"<ol> <li>REDIRECT Air Quality Radar</li> </ol>"},{"location":"Alder_Hey_Children%27s_Hospital.html","title":"Alder Hey Children's Hospital","text":"<p>Speech Error Detection &amp; Correction Children with cleft palate often experience specific speech errors that require targeted feedback to correct. Traditional speech therapy sessions are time-consuming and may not provide immediate, specific guidance during at-home practice. This project aims to develop an interactive tool that detects cleft-related speech errors and offers real-time, personalised feedback. The tool must create a baseline and then learn as the child practices how they are improving. The goal is to support speech therapists by providing patients with an engaging way to practice and improve their speech outside of clinical sessions, enhancing the overall effectiveness of treatment.</p> <p>Conversational Patient History for ASD and ADHD Waiting lists for Autism Spectrum Disorder (ASD) and Attention Deficit Hyperactivity Disorder (ADHD) assessments are growing, partly due to the extensive time specialists spend on developmental history taking-often hours per patient. This project aims to create a conversational AI tool that allows children and their parents to provide comprehensive patient history in a natural, dialogue-based manner. By engaging users in a conversational interface rather than requiring them to fill out lengthy forms, the system can extract necessary clinical information and automatically format it into a report. This innovation seeks to streamline the initial assessment process, saving specialists' time and potentially reducing waiting lists.</p> <p>Generative Custom Heart Models Communicating complex heart conditions to patients and their families is challenging. Clinicians often resort to hand-drawn diagrams to explain cardiac anatomy, but these are non-standardized, vary in quality, and can be easily lost-leaving parents without a clear understanding. Additionally, patients with multiple defects find that standard diagrams do not accurately represent their unique conditions. This project aims to develop a generative AI tool that allows clinicians to create custom heart models through voice (or other, more applicable) interactions. By simply describing the anatomical issues, the AI will generate accurate, personalised animations illustrating the patient's specific condition. This tool will standardize visual explanations, make information easier to digest for families, enhancing overall understanding and care.</p>"},{"location":"Alexander_Gash.html","title":"Alexander Gash","text":"<p>Alexander Gash alexander.l.gash@gmail.com</p> <p>Something to do with apps and autism</p>"},{"location":"Algo-Trading_Game.html","title":"Algo Trading Game","text":"<p>Radmilo.racic@imc.nl</p> <p>Algorithmic trading is an essential part of today\u2019s financial markets, but releasing an algorithm out in the wild certainly comes with its own hassles. One of the challenges associated with carrying a trading algorithm into production is the evaluation of its performance, preferably under different market conditions, and using different parametrizations of the algorithm. This process, called back-testing, allows one to understand the characteristics of a trading algorithm before it hits the markets. In this project, the aim is to create a game, where users will submit their algorithms to be evaluated under a back-testing framework. An algorithm will pick which products it is interested in, and the framework will supply the historical data for those products. The algorithm can then give trading decisions, which will be evaluated in order to characterize the algorithm.</p>"},{"location":"Altfusion.html","title":"Altfusion","text":"<p>Contact is David Russell (david.russell@altfusion.co.uk)</p> <ul> <li>History Scraper</li> </ul> <p>As discussed we\u2019re a local Cambridge software development business and we like to engage with the local community &amp; university where possible so I\u2019d certainly be interested in attending these presentations. We spoke about helping students with internships and if there\u2019s other ways in which we can help or collaborate then I\u2019m always open to suggestions.</p> <p>http://www.altfusion.co.uk</p>"},{"location":"Altitude_Angel.html","title":"Altitude Angel","text":"<p>(Introduced by Lee Stott at Microsoft)</p> <p>Client: Chris Forster chris@altitudeangel.com</p> <p>Drone Safety</p> <p>When drones fly beyond direct human control, they must plan routes that meet operating and safety criteria. For example, a delivery drone needs to make a number of visits within time constraints, while public safety and policing may require repeated surveys of a specific area. Different drones have different capabilities; some can hover, others cannot, while others require more regular charging. Routing drone traffic safely is also challenging: avoiding airspace restrictions, manned aviation and ground hazards, like crowded roads and pedestrian areas. Your goal is to create a cloud-based air traffic control system that registers flight plans, modifies them in response to hazards based on safety data maintained by Altitude Angel, and makes route alterations in real-time to avoid other drones, as well as gatherings of people identified automatically from real-time Cambridge ground data including WiFi network registrations and public transport locations.</p>"},{"location":"Amazon.html","title":"Amazon","text":"<p>For 2022, we have been asked to contact</p> <p>Chris Power chrpw@amazon.co.uk, who responded after deadline for 2021 proposals but keen to continue</p> <p>For 2018, client was Javier Gonzalez Hernandez gojav@amazon.co.uk</p> <ul> <li>Real-time AI research</li> </ul> <p>For 2016, client was Ben Scott bensc@amazon.co.uk</p> <ul> <li>The Politics of Wikipedia</li> </ul> <p>In 2015, David Hardcastle dhardcas@amazon.co.uk acted as client for public service project with Citizen's Advice Bureau:</p> <ul> <li>Online advice assistant</li> </ul>"},{"location":"Andrew_Grant%2C_Vet_School.html","title":"Andrew Grant, Vet School","text":"<p>University Senior Lecturer in Bacterial Pathogenesis, Department of Veterinary Medicine</p>"},{"location":"Andrew_Grant%2C_Vet_School.html#final-project","title":"Final project","text":"<p>Campy Bird</p>"},{"location":"Andrew_Grant%2C_Vet_School.html#background","title":"Background","text":"<p>Many thanks for taking time to consider the idea that we have for a Public Engagement part on a BBSRC sLoLa Full Proposal that we are putting together - Genomics and Engineering to Target campylobacter (GET Campy).</p> <p>Background to the project: Infection by Campylobacter is the most common cause of bacterial diarrhoeal disease worldwide, responsible for ~500 million cases of gastroenteritis each year. In the UK, Campylobacter is believed to be responsible for 45-75% of the one million cases of foodborne disease each year, involving 22,000 hospitalisations and 110 deaths. Current estimates by the Food Standards Agency indicate that the cost of human campylobacteriosis to the UK is around \u00a3900 million, out of a total of around \u00a31.5 billion for all foodborne infections.</p> <p>Campylobacter is commonly found in the gastrointestinal tracts of animals destined for human consumption, with faecal contamination of meat during processing a recognised route of transmission to humans. It is estimated that up to 80% of raw chicken sold in the UK is contaminated with Campylobacter, and studies suggest that the consumption of poultry is responsible for 50-70% of all infections that are reported. The current level of contamination of raw poultry on sale in the UK presents an unacceptably high public health burden, and reducing cases of Campylobacter is the UK Food Standards Agency\u2019s top food safety priority. Despite this, the number of human campylobacteriosis cases have in fact increased over the last few years. Alternative strategies are needed to reduce Campylobacter in chickens and the Campylobacter-induced disease burden in humans.</p> <p>The project: We contend that a fresh approach is required. We propose to use systems and process engineering approaches to develop a thorough understanding of the poultry production system and combine this with an in depth study of the complex bacterial community as it moves through the system. The former will provide a complete, impartial, overview of the poultry production system, from chick to plate, while the latter will provide insight into the behaviour of complex Campylobacter communities. This will enable us to identify pinch points where interventions should be targeted to reduce bacterial numbers, while avoiding the selection of populations with increased ability to survive those interventions, and/or an increased ability to cause disease. To do this, we have assembled a cross- and multi-disciplinary research programme combining expertise in engineering and biological sciences, systems engineering, molecular biology, microbiology, bioinformatics, biochemistry, and field epidemiology.</p> <p>This research will provide improved understanding of the behaviour of Campylobacter in the food production system in the context of realistic, precisely targeted intervention options. The intended outcome is to provide detailed, extensive data to underpin and support the identification of new strategies for intervention to reduce Campylobacter levels in the food chain, leading to major health and economic benefits.</p> <p>Campylobacter App: From year 2 or 3 of the project, we will use the engineering and bacterial population information collected in years 1 and 2 to provide a model for a game app, in which the user will follow the chicken from farm to fork, attempting to avoid contamination with Campylobacter through a variety of interventions, such as washing, temperature. The game could be played from the perspective of the chicken or the Campylobacter, and would include an element of public health information (such as proper cooking of the poultry prior to consumption will eliminate Campylobacter), as well as improving understanding of the poultry production and processing systems. Anna and I have a rough idea of what it might look like, but we have no idea how much work it is! Andrea had suggested that the project might fit nicely for a Part Ib project? I think that this could be a nice idea and would allow us to combine Public Engagement with training as well (!!), also, it could be something that was developed during the duration of the award, since during the grant we will collect genomic and transcriptomic information of the bacteria, then come up with interventions, then try them in real life production systems and monitor what happens to the bacteria - each year the new information/understanding could be incorporated into the app.</p>"},{"location":"Antarctic_Chasm.html","title":"Antarctic Chasm","text":"<ol> <li>REDIRECT Antarctic Chasm One</li> </ol>"},{"location":"Antarctic_Chasm_One.html","title":"Antarctic Chasm One","text":"<p>Survey](British_Antarctic_Survey \"wikilink\") maine@bas.ac.uk</p> <p>The Brunt Ice Shelf in the Antarctic is growing a massive chasm at the rate of 1.7km a year, that may lead to an area of nearly 1,000 sq km breaking off and taking the Halley VI base with it. Your task is to make a 3D immersive visualisation of this growing chasm, allowing viewers to descend into it in the way that BBC\u2019s Peter Gibbs did on camera (goo.gl/48cVds). You will have access to aerial scans, photographs, video, multispectral satellite imagery, ground penetrating radar of the crack and other data from technical specialists at British Antarctic Survey (BAS). You will use these to extrapolate places where data is missing, and also to model the growth of the chasm for a speeded-up view of the future. For a full immersive effect, spatialized audio would add further realism.</p>"},{"location":"Anthony_Harris.html","title":"Anthony Harris","text":"<p>awh28@cam.ac.uk</p> <p>Digital art history with Hamilton Kerr Institute?</p>"},{"location":"Anthropometrics_Today.html","title":"Anthropometrics Today","text":"<p>In the 1880s students in Cambridge had their head measured to test for correlations between head size and degree class (https://goo.gl/Tbfoww). To celebrate the 200th anniversary of the Cambridge Philosophical Society, a major public exhibition will reconstruct this experience. You will use computer vision to measure visitors' profiles, matching against archive records of thousands of ex-students to identify a (possibly famous) historical twin, and then render a simulation of a new \"handwritten\" record card that can be accessed online to compare your future grades to theirs.</p>"},{"location":"Antobot.html","title":"Antobot","text":"<p>Member of Barn4 incubator</p> <p>Contact: Marc Jones, Antobot marc.jones@antobot.ai</p> <p>2022 project Strawberry Fields</p>"},{"location":"Application_for_the_new_32-bit_XAP6_Processor.html","title":"Application for the new 32 bit XAP6 Processor","text":"<p>Contact: Alistair Morfey alistair.morfey@cambridgeconsultants.com</p> <p>This project needs a clearer target market before proceeding</p> <p>There are now over 2 billion XAP embedded processors in silicon. These are all 16-bit devices. We are about to release a 32-bit XAP6 IP core. It is implemented in Verilog RTL and has a GNU software toolkit (GCC, Binutils) that connects to our xIDE debugger tool (can control a hardware target or instruction-level simulator). We have implemented the XAP6 in hardware on our xEMU mini PCB (that includes a Xilinx Spartan FPGA). The board also contains LCD, buttons, buzzer, Ethernet, RS232, ADC, DAC, 84 IO signals (in two 50-pin connectors) and our SIF debug interface (connects to PC with USB). We want to have interesting applications developed for this platform. Students can chose whatever they like. We simply want things that demonstrate the technology well. This is a good way to see the insides of a processor and gain a deep understanding of how the hardware world joins up with the software world. Alan Mycroft will be interested in this !</p> <p>initial feedback</p> <p>We have often had applications for new single-board devices, often with some kind of FPGA or other specialist functionality. We'd usually try to steer toward a specific market or application area that suits the strengths of the particular board. What do you see as the main technical strengths or market appeal of the dev board you'd like to use?</p> <p>The goal here is to come up with some kind of business opportunity, application or benefit proposition. I may have missed something, but at present this one seems pretty much like \"Here's a computer - what would you like to do with it?\"</p>"},{"location":"Archaeological_databases.html","title":"Archaeological databases","text":"<p>Not originally proposed as a group project, but may be possible - have sent an enquiry</p> <p>\"Adam S. Green\" ag952@cam.ac.uk</p> <p>Thank you for the note! Generally, archaeological data derive from features (material things people make that can be moved), artifacts (material things people make that can be moved), and their context (in time and space). As such there is a strong degree of spatiality to archaeological data, as even temporal context is properly derived from where an artifact or feature was found. A site is a concentration of features and artifacts at a particular location that is subject to formation processes, human and environmental. \u201cRaw\u201d archaeological data is most often tabulated; lists of artifacts or sites and information on the contexts from which they were found.</p> <p>There are a wide range of visualizations archaeologists use to analyze, present, and interpret archaeological data. All manner of graphs and quantifications appear in archaeological research. However, my specialities revolve around digital images and three-dimensional models, relational databases, and geographical information systems that can be used to generate maps. I also do some diagraming to illustrate process and technology, but these tend to be very specialized. Here are some examples:</p> <p>1) Seal density at Mohenjo-daro shows the number of a category of artifact, stamp seals, recovered from different excavated portions of an ancient city. From my thesis.</p> <p>2) Plan of an excavated area from an ancient city that juxtaposes features, colored according to particular period in time, with locations from which artifacts were recovered. From my thesis.</p> <p>3) and 4) Maps illustrating change in settlement location through time from the fore runner to TwoRains. (Singh et al 2011)</p> <p>As an active field and data integration project, TwoRains is different from my thesis. In addition to developing novel and useful ways to visualize these kinds of data, our goal is to consistently capture and integrate data from the artifact to the sites-in-a-region scale, work with existing datasets and facilitate new entries from researchers in the field. The whole endeavor with include thousands of entries, each of may have a different range of fields. I am interested both in useful ways to work with such a heterogenous \u201cbig\u201d dataset, and in ways to develop researcher and public-facing visualizations.</p>"},{"location":"Architecture_for_a_Video_Facebook.html","title":"Architecture for a Video Facebook","text":"<p>richard.jones16@boeing.com</p> <p>Kids love YouTube, but video is currently very one-dimensional - play, rewind, fast-forward. In contrast, the Facebook \"timeline\" is actually a multimedia narrative, weaving in conversations, status updates, links to friends and so on. Your task is to make a video alternative to Facebook, in which videos can be mixed with each other, and with text and drawings, allowing users to create their own narrative storyline - almost like a personalised video game (imagine a Mashup of Sims 3 and Little Big Planet 3). The architecture to support arbitrary non-linear combinations of different media will be a technical challenge. You could model it on the SuperCollider synthesis server for realtime networked music, but substituting (possibly low-res) video and graphics streams for audio data, and image blends or overlays for audio filters. Start with a locally-hosted version, and think about a cloud service version (probably with lots of local media caching) as an extension.</p>"},{"location":"Argon_Design.html","title":"Argon Design","text":"<p>Argon Design has now been acquired by Broadcom - see that page for follow-on projects.</p>"},{"location":"Argon_Design.html#2020","title":"2020","text":"<p>No proposal. Alan Scott alan.scott@broadcom.com expressed interest for future years.</p>"},{"location":"Argon_Design.html#2019-proposal","title":"2019 proposal","text":"<p>Project was Meeting Zoom with client Imdad Sardharwalla imdad.sardharwalla@argondesign.com</p>"},{"location":"Argon_Design.html#original-suggestion","title":"original suggestion","text":"<p>In a group call, Skype and Google Hangouts let you know who's talking by illuminating the speaker's name. But what if many of the participants are in the same room? Perhaps seated around a conference table? Your goal is to develop a system that is tailored to this scenario--it should be able to determine the speaker in a room of participants, and indicate them on a simple map of the room. Your client will provide a microphone array for you to work with.</p>"},{"location":"Argon_Design.html#feedback","title":"feedback","text":"<p>(title - Room-Meet?)</p> <p>I like the idea, and it\u2019s nice for students to have a chance of working with a microphone array. I haven\u2019t used these myself - what kinds of signal processing might students need to do, in order to achieve spatial localisation?</p> <p>I would expect that one or two members of the team might focus on the localisation problem, in which case we\u2019d need to think of other system aspects that the rest of the team might work on. For example, maybe it would be feasible to use a single wide-angle camera (or perhaps two or three, to cover a round table), and automatically zoom the video image in to the current speaker? Simple algorithms for face recognition might be sufficient to estimate the camera geometry in relation to audio localisation model.</p>"},{"location":"Argon_Design.html#2018-project","title":"2018 project","text":"<p>Contact: 'Steve Barlow' steve.barlow@argondesign.com</p> <p>Client: Jack Haughton jack.haughton@argondesign.com</p> <p>Augmented Reality Furnishing</p>"},{"location":"Argon_Design.html#earlier-ideas","title":"earlier ideas","text":"<p>I confirm we\u2019d like to put forward a brief for a project for next year (Lent 2018).</p> <p>My delay in replying was because I was chewing over ideas for possible projects. I\u2019ve still not had an idea I\u2019m really happy with so I thought I\u2019d better reply now and then keep thinking.</p> <p>An FPGA project is nice because it\u2019s different technology. The downside is it takes more work to develop compared with software and so might not do something as obviously impressive. The reasons you would use an FPGA are if you ultimately want to implement something in hardwired logic for lower power or you need throughput or low-latency that is beyond a software solution. My current thought is a hardware corner detector that could provide input to a software SLAM algorithm.</p> <p>I know Simon Moore from a number of years ago, when he was working on asynchronous processors. What FPGA boards do you have? I might alternatively provide a board if that is an easier way of connecting a camera and not having too many FPGA resource constraints.</p> <p>Another possible non-FPGA project direction is \u201cslow cameras\u201d. If you only capture an image every hour, you can spend a long time doing image processing on it on a microcontroller. You don\u2019t need a powerful system. So what could you do to create smart sensors using this?</p> <p>I\u2019ll continue to think over the next couple of months.</p>"},{"location":"Argon_Design.html#response","title":"response","text":"<p>Simon Moore does still teach undergrad classes with FPGA boards, and we have quite often used these in the group design projects in the past. As you say, it is usually a little more difficult to bootstrap novel FPGA code to the level of getting an impressive application result, but our audience do appreciate the challenge, and give students credit for their achievements!</p> <p>Information on their FPGA course is here: http://www.cl.cam.ac.uk/teaching/1718/ECAD+Arch/</p> <p>They start with SystemVerilog, then FPGA synthesis using Altera Quartus and Qsys tools. The hardware is a DE1-SoC board from Terasic with our own custom I/O attached.</p> <p>There are some further details of the hardware here. It looks as though it includes an LCD touch panel, but no camera input http://www.cl.cam.ac.uk/teaching/1718/ECAD+Arch/additional.html</p> <p>Terasic seem to provide accessories including image capture devices: http://www.terasic.com.tw/cgi-bin/page/archive.pl?Language=English&amp;CategoryNo=65#Category68</p> <p>Hardware feature detectors for SLAM sound ambitious for undergrads! But would be exciting if this is feasible. If you want to pursue that, I should probably introduce you to one of Simon\u2019s team, to discuss the level of skill that can be expected from students. I\u2019ve had undergrads use SLAM libraries, but wouldn\u2019t expect them to have much detailed understanding of the implementation in second year.</p>"},{"location":"Atheon.html","title":"Atheon","text":"<p>Guy Cuthbert guy.cuthbert@atheon.co.uk</p> <p>For 2023 - Konrad Maliszewski konrad.maliszewski@atheon.co.uk</p> <p>Idea for consideration, as proposed by AFB:</p> <p>Keeping Key-Workers</p> <p>The design strategy of \u201cgamification\u201d uses familiar features of videogames like high scores, personal bests or daily streaks to improve incentives and enjoyment of everyday life. In the retail logistics sector, especially key-worker areas like food retail, there are many data feeds and performance measures available. Some retail sites do provide game-like feedback to staff and customers, but there are many opportunities to make this enjoyable rather than an oppressive obligation. Your client is a leader in retail data science, and you\u2019ll have an opportunity to work with real data from real stores to see how key-worker\u2019s lives might be improved.</p> <p>Other topics for discussion in 2023:</p> <p>The projects would be carried out with the support from the Atheon\u2019s product team and would be related to our core offering, SKUtrak. SKUtrak is the UK\u2019s leading grocery supply chain analytics platform with over 1,700 supermarket suppliers using a selection of SaaS tools on a freemium business model. Over 130 premium (paying) customers include 37 of the world\u2019s top 50 global CPGs.</p> <p>1. Evaluating the impact of data availability</p> <p>There is a growing body of evidence and agreement both in the academic and practitioners discourse that data is absolutely essential for effective decision making in the 21st century. In the industry, considerable effort goes into building infrastructures that ingest, clean, store, enhance and present the data. However, the key question remains of how exactly the benefits of the available data are realised by the end user, whether it is an individual or a firm. Through a set of related projects we would like to investigate the impact of increased data availability and access to state-of-the-art analytics tools on various firm and individual performance metrics, including quantitative and qualitative ones.</p> <p>Retail data availability - All 1,500 of Morrisons suppliers have gained access to their retail data via SKUtrak. However, not all of them are using it, and some are using it to a much greater extent than others. What are the differences between the segments? What difference does the platform use make to firms\u2019 performance?</p> <p>Increased analytics opportunities - Our premium customers receive access to substantially more granular and nuanced data and an improved suite of analytics tools, including machine learning solutions. What difference does it make to their performance? Quantitatively (use metrics &gt; performance metrics) Qualitatively (use &gt; culture, decision-making practices)</p> <p>Use patterns and user segmentation - Actual use of our platform varies greatly between individual firms and users. We would like to investigate if distinctive use patterns can be identified with regard to frequency and depth of use over time. How to explain them?</p> <p>Optimal level of information sharing - Invariably various actors make choices as to which and how much data should be shared between retailers and suppliers (supply chain partners). We would like to investigate how to better understand which and how much data should be shared to achieve the best outcomes for the involved parties.</p> <p>2. Fostering effective analytics engagements</p> <p>Having access to clean and trustworthy data is only the first step in the sensemaking process and improved decision-making. There are various ways in which decision makers can be assisted in effective sensemaking. Through a number of projects we would like to explore new and validate the existing approaches to driving effective engagements with analytical tools.</p> <p>Valuable and effective SKUtrak use - linked to the project above on use patterns but more focused on which actions users take while on SKUtrak deliver value. But also a broader question of what valuable engagements are; how to define and measure them.</p> <p>Suggesting dashboards - SKUtrak offers a suite of dashboards. We would like to explore computational solutions to identifying the best dashboard to suggest to each user in order to assist them in their exploratory journey.</p> <p>Gamification in B2B contexts - Gamification has been shown as an effective tool driving user engagement. However, most of the use cases are in hedonistic and voluntary contexts or internal employee engagement contexts. We are interested in what scope there is for a gamification engine in a B2B context, and what an implementation of such a solution might look like.</p> <p>Visualisations effectiveness - A distinctive feature of our analytical tools are advanced visualisations. They were created by leading industry experts in order to support our clients in effective sensemaking of complex data. However, we would like to test some of our assumptions in a more rigorous way incorporating the latest findings from the visualisation research (e.g. as a laboratory/online experiment).</p> <p>3. Getting the most of supply chain data</p> <p>Atheon tools focus on the flow of goods analytics assisting various stakeholders managing complex grocery supply chains. The crux of this matter is effective demand modelling to know where and when to send which product(s). Most of what we do is based on the imperfect supply chain data provided by grocery retailers and their suppliers. We would like to investigate certain aspects of this problem in order to enhance the data at hand.</p> <p>Improved demand modelling - Most of the retailers show stock cover as an average across all depots without the explicit link between depots and stores. We would like to explore a modelling approach which would calculate stock cover by depot.</p> <p>Managing demand by better understanding of store characteristics - Each store is characterised by its surrounding catchment area and what it sells. Based on that information we would like to cluster similar stores in order to better understand demand signals for certain products / product categories.</p> <p>Cloud marketplaces and open data - A leading cloud database provider, Snowflake, recently introduced a new feature of a data marketplace. Every registered company can make data easily available for other people to access. We would like to experiment with making some datasets available to evaluate the scope for such a solution to deliver revenue.</p>"},{"location":"Atmospheric_Metaverse.html","title":"Atmospheric Metaverse","text":"<p>Lecture Theatre 1 in the Gates Building is packed with environmental sensors that collect all sorts of historical information about air quality. Imagine if the Metaverse gave you superpowers to go back in time, and drill in to sensors to find out what data they had collected. Your task is to create this demonstrator, where VR interaction allows you to dive in to any sensor and find out what it knows, not simply flying around in 3D, but entering the unexplored fourth Metaverse dimension: time itself!</p>"},{"location":"Audible_Appliances.html","title":"Audible Appliances","text":"<p>Many home appliances would be perfectly usable by visually impaired users, except for interaction via a display screen. An example is the exercise bicycle owned by your client. Your task is to create a simple accessory that can be attached to the bicycle display screen, using a Raspberry Pi camera to find and decode relevant parts of the display, and read necessary information out loud during an exercise session. In principle, this functionality could provide a customisable screen reader that might be attached to any kind of device to add screen reader functionality.</p>"},{"location":"Audio_Websites_on_Smartphones.html","title":"Audio Websites on Smartphones","text":"<p>dfang14@bloomberg.net</p> <p>Mobile phones have revolutionised the developing world making information easily available to those even in the most remote parts of the world. However, the smartphone has yet to make a big impact there. This may be due to users having limited technical or even literacy skills. You will create an app which people can use on their smartphones to create audio websites, for example to advertise their agricultural products. This will allow others in similar geographical locations to make contact and perhaps even purchase directly from the seller using audio as well.</p>"},{"location":"Augmented_Reality_Furnishing.html","title":"Augmented Reality Furnishing","text":"<p>jack.haughton@argondesign.com</p> <p>It's often difficult to follow furniture assembly instructions, but augmented reality could make it easy. The Holokit is an exciting low cost phone accessory with development tools providing the capabilities of Microsoft's Hololens, but so cheaply that a furniture company could include one in every pack. The goal here is to provide an AR overlay that shows customers how to orient parts relative to each other, apply tools, and any other advice right where it is needed. Your client will provide a furniture kit, and a phone if you need it.</p>"},{"location":"Augmented_Room_Dressing_for_Zoom.html","title":"Augmented Room Dressing for Zoom","text":"<p>mjohnson@frontier.co.uk, working with Olly Powell opowell@frontier.co.uk</p> <p>In these times of Covid-19, many of us are spending much more time alone and interacting with colleagues and peers via webcams in virtual meetings. In the spirit of light relief, we would like the client to produce a fun application which would capture the video feed from a webcam, augment it with entertaining elements such as models, images or animations (For example, one option may be to provide a virtual set of bookshelves in the background to allow the user to appear better read for an interview!). The application should be able to work with some captured 3d information about the scene in order to place the friendly or amusing augmentations to brighten up the room of the user, or even provide some interactive background elements. The output should then be supplied as a virtual camera feed which may be consumed by applications such as Zoom or Teams.</p>"},{"location":"Auto-Archive.html","title":"Auto Archive","text":"<p>rrw@semiramis.org.uk</p> <p>Everybody has a different approach to organising email and documents, but nobody has time to do it properly. Your challenge is to create a new kind of mail-plus client that uses unsupervised machine learning techniques to help run a small business. It should recognise clusters of email that the user can deal with as a batch, using the IMAP protocol to create and populate archive folders on the mail server, or (if feeling brave) automatically reply to them. Since much email content simply repeats existing documents (whether as attachments or with repeated text), your system should also scan for valuable data that is *not* in the email archive - for example as disk files or on the local network. These ought to be archived too, and somehow associated with relevant email. But take care not to waste space by backing up too many similar copies - prioritise information that seems to be important and unique.</p>"},{"location":"Auto-Emoji.html","title":"Auto Emoji","text":"<p>It's useful to include emojis in your messages as a quick indicator of emotional state, but why should you have to call up a special keyboard, or scroll through many alternatives, when your emotional state could be read off your face? The goal of this project is to augment the on-screen keyboard by using the front facing camera to just read off the emotional state (using a standard facial emotion classifier) and put the right emotion in. It could also be useful to use the rear camera to capture suitable non-emotional emojis, such as recognising a burger, a champagne glass, a cute puppy and so on.</p> <p>An earlier version of this project was offered (but did not proceed) with the following description:</p> <p>Client: James Jillians, Sparx James.Jillians@sparx.co.uk</p> <p>People increasingly rely on emoji to express the tone of digital communications. But as the set of emoji icons grows, it is frustrating and time-consuming to select the right one. The OpenFace library (originally developed in Cambridge) is an open source facial behaviour analysis toolkit, that can monitor a webcam to detect emotional state via action units, such as smiling or raised eyebrows. Your task is to build a custom keyboard app that can insert appropriate emojis directly into the text, based on \u201ccommands\" directly received from the user\u2019s face.</p>"},{"location":"Autodesk.html","title":"Autodesk","text":"<p>Current contact was a client at his previous employer: Imdad Sardharwalla imdad.sardharwalla@gmail.com</p> <p>Previous contact: Luke Edwards luke.edwards@autodesk.com</p> <p>2019 discussion - One of the things Autodesk are looking to do in the next few years in move manufacturing to the cloud. We are in the early stages at the moment but should have technology more mature in the next 12 months. At that point I think there could be a number of opportunities for projects that your students would be interested in where they could happily take the IP. From stringing together microservices to automate manufacturing processes to using machining data to optimise processes\u2026</p> <p>Sadly at present I only have time to mentor on projects where we would want to retain IP.</p>"},{"location":"Autodesk.html#response","title":"response","text":"<p>I know that some other universities (mainly outside the UK) charge a fee for participation in this kind of programme, or even offer contracted student time as work for hire. In those arrangements, there would obviously be contractual terms for transfer of IP. I\u2019m always interested in considering ways to extend our programme.</p>"},{"location":"Automatic_Assessment_of_R_Code.html","title":"Automatic Assessment of R Code","text":"<p>raoul@cambridgespark.com</p> <p>Cambridge Spark\u2019s EDUKATE.AI platform gives students automated feedback on Python and Java code based on functionality and code quality. Students write code and submit it for processing by a set of tests running in Docker containers, resulting in errors, failures and other data subsequently used to provide feedback to the student about what failed and why, plus metrics of code quality. We wish you to add support for R to the platform, potentially to the extent of providing an SDK to help for exercise developers to write exercises and associated tests more quickly.</p>"},{"location":"Automatic_Entrepreneur.html","title":"Automatic Entrepreneur","text":"<p>daniel.organisciak@luminance.com</p> <p>The skill of a business entrepreneur is turning a few key terms, and some names of people and places, together with some financial figures, into a compelling narrative. Until now, it has been time consuming to manually extract relevant names and figures from reports filed at Companies House. It requires hard thought and creativity to write about the business opportunity. Your project has two parts. The first is automatic extraction of pertinent information from company filings, using methods such as syntactic parsers or named entity recognition. The second part is to use a combination of visual design and generative language models to create web pages that pitch the business to new investors, or perhaps provide the template for a competing start-up.</p> <p>This project team has used public datasets via the API from Alpha Vantage: https://www.alphavantage.co</p>"},{"location":"Automating_Crop_Canopy_Data_Collection_for_Crop_Management.html","title":"Automating Crop Canopy Data Collection for Crop Management","text":"<p>Michael.Gifford@niab.com</p> <p>Models to optimise potato crop production forecast yield and schedule irrigation use manually collected data on leaf canopy coverage to quantify light interception and evapotranspiration -- time-consuming, expensive and often inaccurate. Such data can be collected by satellite but optical sensing is impeded by cloud cover in Northern Europe. Synthetic Aperture Radar (SAR) imagery from the Copernicus Programme is collected through clouds and during the night but there is no available service for estimating canopy cover from SAR imagery. Your challenge is to develop a machine learning system to estimate canopy cover from SAR imagery and integrate with existing models.</p>"},{"location":"Automating_the_collection_of_crop_canopy_data_to_improve_crop_management.html","title":"Automating the collection of crop canopy data to improve crop management","text":"<ol> <li>REDIRECT Automating Crop Canopy Data Collection for Crop     Management</li> </ol>"},{"location":"Autonomous_Trucking.html","title":"Autonomous Trucking","text":"<p>Software](Ab_Initio_Software \"wikilink\") arley@abinitio.com</p> <p>Autonomous vehicles are likely a wave of the future. A lot of effort is going into automating the control of individual vehicles to provide a self-driving version of our current experience. An alternative is centralized control of fleets of vehicles to optimize large-scale traffic flow. This is a simpler problem which might be very appealing for transport of goods by truck. The brief is to build a simulation environment to demonstrate centralized control of a fleet of trucks. The simulation should consist of three elements: a) a traffic optimization algorithm which achieves maximal transport of goods, given boundary conditions for trucks joining and leaving the flow of traffic, b) a visualization of the traffic flow, c) control of the traffic variables, including highway pattern (on-ramps, off-ramps), rates of trucks entering and leaving the traffic pattern, basic dynamic properties of trucks (e.g. maximum rate of acceleration/deceleration).</p>"},{"location":"Autonomous_highway_system.html","title":"Autonomous highway system","text":"<p>Highway congestion is a never ending problem. One way to increase the throughput of the highway is to group vehicles into platoons to shorten the distance between two consecutive cars. Further advantages of vehicle platooning are decreased fuel consumption and emissions and increased safety and comfort. Design an automated platooning system in which multiple vehicles autonomously follow the leader. Safety is of paramount importance, each vehicle should do its best to avoid collisions. The goal is to develop a platoon simulation which can be backtested with 3 Lego Mindstorms vehicles.</p>"},{"location":"Azure_Sphere_for_Citizen_Science.html","title":"Azure Sphere for Citizen Science","text":"<p>Research](Microsoft_Research \"wikilink\") jws@microsoft.com</p> <p>This project will use the Microsoft Azure Sphere IoT platform to fulfill a citizen science goal. The team is free to select the goal so long as it uses at least one environmental sensor (temperature, pressure, etc) and an output (e.g. LED), and at least 5 devices are deployed for a week or more, with the Azure IoT Central service used to collate data for visualisation. The design of the system should be documented openly (e.g. on github) to enable reuse. Hardware (Azure Sphere development kits and sensors) will be provided.</p>"},{"location":"BAE_Systems.html","title":"BAE Systems","text":"<ol> <li>REDIRECT BAE Systems Applied     Intelligence</li> </ol>"},{"location":"BAE_Systems_Applied_Intelligence.html","title":"BAE Systems Applied Intelligence","text":"<p>Reinfection Monitor</p> <p>Original suggestion ...</p> <p>No-hassle internet security</p> <p>Client: James Dickin, BAE Systems Applied Intelligence james.dickin@baesystems.com</p> <p>How easy do you find it to set up and maintain internet security on your computer? How about your parents? Or your grandparents? For some people setting up and maintaining anti-virus software, differentiating between real and fake pop-up security warnings, recognising the difference between genuine and phishing emails and keeping their computer malware-free is an insurmountable challenge.</p> <p>ISPs struggle to differentiate themselves solely though pricing and connection speeds so increasingly look for \u201cvalue add\u201d features that they can offer their customers. An ISP could offer their customers \u201cno-hassle internet security\u201d in the cloud, in the user\u2019s home router or in the form of a \u201cdongle\u201d that sits between the user\u2019s computer and their home router.</p> <p>Produce a prototype of this security dongle using a standard desktop computer with two Ethernet interfaces \u2013 one internet-facing and one user-facing. The dongle should be zero-maintenance and must protect the user from virus, malware and email threats, taking sensible action to protect the user without confusing them.</p> <p>Feedback:</p> <p>From this description, I'm not completely certain of the intended scope, and whether it would be feasible for an undergraduate team to achieve anything along these lines within 7 weeks. The functionality described for the \"dongle\" seems very close to that of a conventional firewall, but with additional intelligent features that would outperform existing spam filtering services. Have I misunderstood?</p> <p>Response:</p> <p>Thanks for the feedback. I've received the following from my colleague James Dickin, who proposed the project idea.</p> <p>\"Alan's understanding is correct. I deliberately left the form of the solution in my description quite open however so that the students could propose their own solution to the problem I presented.</p> <p>I was hoping that the students might, for instance, write code that pipes the user's data through industry tools such as ClamAV (Linux antivirus) and SNORT (Linux intrusion detection system), modifying it as appropriate when threats are detected. They could write stubs for the industry tools to emulate the detection of threats so that they don't have to handle infected data. The data modification in response to detection is the most interesting bit and the place where the students could do the most innovation.</p> <p>They actually don't need to use a stand-alone machine with two Ethernet ports - if they want to use the university's existing dev systems they could run this either as a VM or just run it on the same machine as the 'user'.</p> <p>Alan makes a fair point on the feasibility of the students achieving anything in the 30-60 hours they're expected to spend on this project however - I'd guess that even the simplest solution to this problem could take more time than this.\"</p> <p>More feedback:</p> <p>I think you're right - data modification in response to detection would be an interesting challenge, perhaps more than the routing and configuration involved in piping the data through standard Linux tools. I believe that most current firewalls simply block infected content, or at best offer the user a yes/no decision for which the user must pay attention and take responsibility. What kinds of data modification do you think might be feasible, and what threat models would be addressed? I guess we need to think of a scenario in which (say) a phishing email contained some data that might still be of value to the user - or else a situation in which a normal email has been mistakenly classified as a phishing email, but has some other automated action taken.</p>"},{"location":"BAML.html","title":"BAML","text":"<p>(Bank of America)</p> <p>Letizia Pepe letizia.pepe@baml.com</p> <p>Piers Thompson piers.thompson@baml.com</p>"},{"location":"BAML.html#2016","title":"2016","text":"<p>We are thinking of asking the students to develop a platform that allows trading algorithms to be interactively developed and tested (both back-tested and tested against live market data) and compare performance.</p> <p>Feedback: Your suggestion has some similarities to this project form 2014, so you might like to think of ways that it could be updated or adapted: Algo-Trading Game</p> <p>Edited to length:</p> <p>Simulated Stock Exchange</p>"},{"location":"BAML.html#previous-2015-project","title":"Previous (2015) project","text":"<p>Financial Trading Trends</p> <p>Global real-time information rules the financial markets. Institutions need to make use of complex modelling tools to predict trends and stay ahead of the curve. However, it's currently very difficult to get access to this information without a subscription to various services (e.g. Bloomberg).</p> <p>With the abundance of data on the web, we now think that there is an opportunity to go outside the usual sources and begin sourcing data from places outside of the norm. For example, as the influence of social networks continues to increase, so does the likelihood of stories and individuals influencing global markets on a more regular basis. Think how a possible tweet from a high profile celebrity may adversely affect the stock price of a certain consumer product, for instance.</p> <p>The goal of this project is to create a system that models the impact of various sites on financial trends. The system will update itself with information on financial markets and then detect the trends between this data and various news sources. It should potentially look to gather data from a variety of different sources, and build out a model that represents the relations between stories and financial information, presenting it for the user to browse.</p> <p>Some areas we would consider thinking about are: how you model the data both financially and news related, how you store the scraped data, how to identify a tolerance for variations and the ability to allow a user to specify their own data source.</p> <p>Revision:</p> <p>Data analytics on actual trades</p> <p>Aim: Parties involved in OTC trading are obliged to make public the details of trades, in real time. This was intended to increase the transparency, fairness and efficiency of the OTC markets. However, although the data is public, it is not easy to view and analyse and therefore the aim of increased transparency is imperfectly realised. The aim of this project is to provide a convenient means of accessing, viewing and analysing OTC trade data.</p> <p>Differences in pricing models used by the participants in OTC market result in inconsistencies in prices at which derivatives products are traded. Market participants can benefit from seeing, in real time, the current prices at which the derivatives are being traded.</p> <p>A U.S. regulation requires that all firms under its jurisdiction report their trades, with limited details, to a common repository within a set time since they were traded. This repository is available for public viewing and contains information about OTC product volumes and prices.</p> <p>For this project we would like you to provide a convenient user-interface for this data. This should allow users to see current and historic prices for selected derivatives products. Additional functionality might be added as time allows, such as the automated identification of pricing anomalies, trending and alerts.</p> <p>Further revision:</p> <p>Over-the-counter (OTC) trading of financial products is less regulated than exchange trading, but also less transparent. To improve market fairness and efficiency, near-realtime details of OTC trades must therefore be placed in a public repository. However, since this data is not easy to view and analyse, the aim of increased transparency has not been achieved. The aim of this project is to provide a convenient means of accessing, viewing and analysing OTC trade data. This should provide realtime data on current prices and trading volumes, historic trends, and automated identification of pricing anomalies and trend alerts.</p> <p>Can you give a reference to the repository that the team would be relying on, and specification of its public interfaces?</p>"},{"location":"BS-meter.html","title":"BS meter","text":"<p>chris.newfield@isrf.org</p> <p>Recent research has used machine learning methods to apply the language philosophy of Wittgenstein, in a way that can quantify the likelihood of any particular text being bulls**t. These results have extraordinarily exciting implications for political discussion, journalism, corporate press releases, even the content of Facebook or eX-Twitter. Your task is to create a BS-meter that uses these methods to produce an intuitive test device accessible to anyone, perhaps with an international authentication body that can apply validated BS stamps to any text that deserves it.</p>"},{"location":"BSmeter.html","title":"BSmeter","text":"<p>Recent research has used machine learning methods to apply the language philosophy of Wittgenstein, in a way that can quantify the likelihood of any particular text being bulls**t. These results have extraordinarily exciting implications for political discussion, journalism, corporate press releases, even the content of Facebook or eXTwitter. Your task is to create a BSmeter that uses these methods to produce an intuitive test device accessible to anyone, perhaps with an international authentication body that can apply validated BS stamps to any text that deserves it.</p>"},{"location":"BT.html","title":"BT","text":"<p>Potential contact for 2020:</p> <p>alex.healing@bt.com</p> <p>On 31 Oct 2019: Just a note to let you know that due to time constraints I will be unable to submit a brief this year I'm afraid.</p> <p>On 7 Feb 2019, Alex says: Many thanks, I'll have a think and see what we can suggest that is likely to fit the brief and be in touch I come up with anything.</p> <p>Previous contact: Daniel Garner, daniel.garner@bt.com</p> <p>Daniel says:</p> <p>We generate that brochure once a year during the summer, with the aim of making it available to the universities that we are partnered with during the start of term when students are choosing their projects. The ideas come from all over the department, from tech's with problems they want to learn about, to strategists with big new ideas.</p> <p>I'm the point of contact between GES and universities across the East of England, so I'm here to foster the relationships we have. My main role here is technical so I can answer most queries, those I can't I'm able to find someone who can.</p> <p>Perhaps this year we should open a dialog when we begin compiling that brochure, that way we can find some projects specifically tailored to match our interests and yours.</p>"},{"location":"BT.html#analysis-of-suggestions-for-2016-a-plausible","title":"Analysis of suggestions for 2016 - (A) PLAUSIBLE","text":""},{"location":"BT.html#am-i-where-i-think-i-am","title":"Am I where I think I am?","text":""},{"location":"BT.html#original-suggestion","title":"Original suggestion","text":"<p>Today over1 billion Android smart phones rely on Google Location Services to tell their users where they are and where they are going, every day. Given the growing reliance on this information, how can users be sure the location data they are relying on is accurate, reliable and safe? How can they be certain that when they don\u2019t want to disclose their location, their device isn\u2019t continuing to do so behind their backs?</p> <p>This project addresses the first concern by finding ways of trusting location providers, so that users can place greater confidence in the service they\u2019re receiving. We suggest approaching the disclosure concern by reviewing ways of locating a device, such as through connectivity, sensors, and the immediate environment. Once we understand the options for locating the device, we can implement ways of safeguarding prevention of data collection. That way your private business meeting really does stay private.</p> <p>The outcomes of the project will be an improved understanding of how location based services work, their strengths and weaknesses, and a tool demonstrating the most significant aspects.</p>"},{"location":"BT.html#alan-comment","title":"Alan comment:","text":"<p>Outcome of \"improved understanding\" is not within our scope, so we need to focus on the \"tool demonstrating aspects\". This needs to be rephrased so that \"finding ways\", or \"reviewing ways\" are specified as features of that \"tool\"</p>"},{"location":"BT.html#ian-comment","title":"Ian comment","text":"<p>Andy Rice could advise on this. Seems to me this requires a shim to track information leaving the phone.</p>"},{"location":"BT.html#andy-comment","title":"Andy comment","text":"<p>This is very vague. Is this about attacks where an attacker tries to trick someone's phone in to thinking its somewhere where it isn't - what's the threat model here? Or is it about reliability and detecting failures in location estimates - like when you rely on a wifi fingerprint for location and then the base station gets moved? I guess you could build a tool to check whether the location estimates from the device from different providers are consistent. To do this properly you'd need your own database of cell fingerprints and wifi fingerprints because its totally opaque in the android stack if you let google do it for you.</p> <p>Tracking information leaving the phone is a serious undertaking. There have been projects such as taint tracking and secure multiexecution looking at catching dynamic information flows and so detecting leaks of private information but this is beyond the scope of a 1B group project.</p> <p>Potentially one could do a project about location granularity reduction. This would be an app that lets you share your location with others and choose whether you share point, city, country level etc. You can build this with an offline database from openstreetmap and then use some crypto on the server to limit the dissemination of your location to the provider etc.</p>"},{"location":"BT.html#automated-network-provisioning","title":"Automated network provisioning","text":""},{"location":"BT.html#original-suggestion_1","title":"Original suggestion","text":"<p>Teams of all sizes are embracing virtual environments for their servers and processing needs, but often they still deploy the networking elements of a system on physical network devices. The alternative is that their administrators have to engage in a long and complex configuration process to make a virtual network that fills their needs.</p> <p>The aim of this project is to automate the creation of virtual networks, with minimal user direction and configuration. The outcome should be some software that can capture a user\u2019s high-level requirements, inspect the layout of virtual machines deployed on common hypervisors like vSphere and OpenStack, and then automatically create and configure the network infrastructure. The project would likely take a phased approach, starting with simple networks and one hypervisor, but the potential scope is huge.</p>"},{"location":"BT.html#ian-comment_1","title":"Ian comment:","text":"<p>Once involved in a start-up to do some of this. I think the problem here is going to be translating the problem - the guts of this would be a graph algorithm and possibly not a hugely difficult one. I would worry that second year students won't have enough exposure to real-world networking infrastructure in order to understand requirements. The effort would go into this rather than generating a body of software.</p> <p>This could be averted if BT are happy to provide the underlying input information and dependency constraints. Clarification required.</p>"},{"location":"BT.html#detecting-power-cuts-from-internet-data","title":"Detecting power cuts from internet data","text":""},{"location":"BT.html#original-suggestion_2","title":"Original suggestion","text":"<p>Companies providing a service that relies on the UK\u2019s power and network infrastructure need to know when things go wrong as quickly as possible. But with so much legacy infrastructure out in the wild, monitoring it all becomes a complex and expensive task.</p> <p>There may be an answer based on how traffic flows across the internet. Can we inspect the data flowing across our network, and find a way to detect a number of service deterioration events, or disconnection events, and cluster them? If so, can we begin at a high level, for instance clustering service disruption in order to localise it to a particular failing device in the core of the BT network, before going down to a low level, for instance clustering within a postcode?</p> <p>The outcomes of this project will be a study of search algorithms that allow us to detect power loss events, and a software tool that implements it and maps the likely fault area. In order to make this realistic, we expect to provide real anonymised data from the BT network.</p>"},{"location":"BT.html#alan-comment_1","title":"Alan comment:","text":"<p>Sounds good. We need to find out what the data is.</p>"},{"location":"BT.html#what-can-my-second-factor-be","title":"What can my second factor be?","text":""},{"location":"BT.html#original-suggestion_3","title":"Original suggestion","text":"<p>Two factor authentication improves security of normal username and password authentication by exploiting the \u201csomething I have, and something I know\u201d approach. The widest application of this is in the banking sector, where a user authenticating online typically receives a onetime code via SMS, which the website verifies. Other popular online service providers, such as Google, Facebook and Dropbox, all offer similar two-factor authentication systems too.</p> <p>The aim of this project is to find new and unusual forms for the \u201csomething I have\u201d part. This must not have a negative impact on the user experience, and not require a change of user behaviour. What about using near field communication readers in mobile phones to read some details from a credit card, or using session data in a user\u2019s device to see that they are using their home machine? Suh and Devadas wrote a paper for the ACM entitled \u201cPhysical Unclonable Functions for Device Authentication and Secret Key Generation\u201d, in which they set out the properties and examples of good unclonable functions. The paper may serve as a good starting point for this project.</p> <p>The outcomes of this project will be an evaluation of a range of novel second factors, including an implementation of each. Each will need a thorough analysis, so that we can understand how easy and secure each option is. It should round up with a recommendation of the best of the bunch.</p>"},{"location":"BT.html#alan-comment_2","title":"Alan comment:","text":"<p>How close is this to the Pico project, or other security group work? Should check with them. \"evaluation of a range\" of options is not an approach we have recommended to group projects in the past, but could conceivably be done.</p>"},{"location":"BT.html#ian-comment_2","title":"Ian comment:","text":"<p>Agree. Is this a study or an implementation. One could take one factor and feed it in. Talk to John Daugman???</p>"},{"location":"BT.html#auditing-smart-phone-permissions","title":"Auditing smart phone permissions","text":""},{"location":"BT.html#original-suggestion_4","title":"Original suggestion","text":"<p>Most users have dozens of free apps installed on their smart phones, and many users don\u2019t check what permissions are requested as they install them. As businesses begin to champion bring-your-own-device schemes in the workplace, understanding the vulnerabilities of these unknown devices will be of paramount importance to system administrators.</p> <p>The outcome of this project will be a smart phone app, which users can install on their devices, and will give them informative output about what applications have what permissions granted to them. In addition it should highlight anything consider a specific threat, or any applications with permissions that don\u2019t align with its overt purpose.</p>"},{"location":"BT.html#alan-comment_3","title":"Alan comment:","text":"<p>Ask advice from ARB - perhaps add the root-kit functionality to here?</p>"},{"location":"BT.html#ian-comment_3","title":"Ian comment:","text":"<p>(or Andrew Rice, but yes)</p>"},{"location":"BT.html#andy-comment_1","title":"Andy comment","text":"<p>This would be an app like this one I guess: https://play.google.com/store/apps/details?id=com.fsecure.app.permissions.privacy</p> <p>I don't know how you would identify applications with permissions that don't align with their overt purpose.</p> <p>You could however extend this idea a bit to have options like 'give me a notification whenever an app which can cost me money is running'</p>"},{"location":"BT.html#new-suggestions-for-2016-b-unlikely","title":"New suggestions for 2016 - (B) UNLIKELY","text":""},{"location":"BT.html#imsi-grabbing","title":"IMSI Grabbing","text":""},{"location":"BT.html#alan-comment_4","title":"Alan comment:","text":"<p>Sounds plausible - need an application idea that incorporates this technique.</p>"},{"location":"BT.html#ian-comment_4","title":"Ian comment:","text":"<p>I am not sure I understand this. If a mobile device is broadcasting the IMIS every so often then I don't see how you can detect a grab. If the mobile device is being tricked into broadcasting this then it is a bit like the location project (you need a shim). If the mobile device is responding to a legitimate request and someone is eavesdropping, you are pretty much back in periodic broadcast cast.</p>"},{"location":"BT.html#andy-comment_2","title":"Andy comment","text":"<p>I guess they are referring to this project: &lt;https://github.com/SecUpwN/Android-IMSI-Catcher-Detector&gt;. I can imagine a group being able to build this but how would be provide them with any way of testing it - are we going to get some catcher hardware for them to use? I don't know too much about IMSI catching or how plausible it is with 3g or what countermeasures a phone can take</p>"},{"location":"BT.html#original-suggestion_5","title":"Original suggestion","text":"<p>An IMSI is an International mobile subscriber identity - every mobile phone has one, and they are unique. Because mobile devices broadcast their IMSI, threat actors have the opportunity to detect the presence of a device. For individuals who are at risk from physical attack, such as when carrying valuable goods or sensitive information between offices, accidentally announcing their location may be unwise.</p> <p>This project builds on the Open Source Android IMSI-Catcher Detector, which implements ways of detecting IMSI grab attempts. We want to take an extra step, and detect the attempt by device and radio behaviour, rather than relying on whitelisting safe cell sites.</p> <p>The outcomes of the project will be a tool that announces to the user that their device has had an IMSI grab attempt directed at it. The ideal solution will go one step further, by reporting on and implementing a technique to prevent the threat actors from receiving the device\u2019s IMSI.</p>"},{"location":"BT.html#has-my-mobile-device-been-rooted","title":"Has my mobile device been rooted?","text":""},{"location":"BT.html#alan-comment_5","title":"Alan comment:","text":"<p>Not enough work for a team. Combine with one of the other projects, such as permissions above?</p>"},{"location":"BT.html#ians-comment","title":"Ian's comment:","text":"<p>Not sure about that. I am sure this is undecidable at some level. Andy/Alastair consult?</p>"},{"location":"BT.html#andy-comment_3","title":"Andy comment","text":"<p>This is a research question. Rootkit detection is hard and is an arms race with rootkit manufacturers. Malware detection is easier. Quallcom just announced this: https://www.qualcomm.com/products/snapdragon/security/smart-protect which captures events and then uses a classifier to identify malicious apps. That's probably do-able for a group project (if you don't care about the overhead of running the tracker).</p>"},{"location":"BT.html#original-suggestion_6","title":"Original suggestion","text":"<p>Rooting is the process of allowing users of smartphones, tablets and other devices running the Android mobile operating system to attain privileged control (known as root access) over various Android's subsystems. For many people this is a good thing, because it enables them to perform operations the platform normally prevents them from doing. But what if someone else rooted the device without them knowing?</p> <p>This project aims to find ways of detecting if the device has been rooted without the knowledge of its user. Current techniques to do this are weak, leaving ways to evade their detection.</p> <p>The outcome of the project will report on and demonstrate an Android application that implements novel methods of detecting the rooted state. It will show how difficult it is to circumvent the detection, perhaps backed up by evidence from the behaviour of real malware.</p>"},{"location":"BT.html#can-you-hack-my-iot-device","title":"Can you hack my IOT device?","text":""},{"location":"BT.html#alan-comment_6","title":"Alan comment:","text":"<p>Where would the students get the devices from? Group coordination would be tricky, but perhaps interesting. Danger that one student could find the whole thing trivial, leaving others with nothing to do.</p>"},{"location":"BT.html#ian-comment_5","title":"Ian comment:","text":"<p>Don't think there will be a problem finding devices. The real question is whether a group can come up with a coherent harness that test's devices without someone having to sit in front of protocol analysers.</p>"},{"location":"BT.html#original-suggestion_7","title":"Original suggestion","text":"<p>The concept of the internet of things (IOT) is the driving force that is beginning to flood the market with small, often simple devices that communicate over the internet. As the demand for these surges, how well are designers taking care of security?</p> <p>The aim of this project is to analyse popular IOT devices, such as smart home sensors and smart watches, and see how they respond to well-known network attacks such as man in the middle and data spoofing. Where there are vulnerabilities, what data do they disclose? The outcomes of the project should be an analysis of the vulnerabilities of these types of devices and the consequences of their exploitation.</p>"},{"location":"BT.html#new-suggestions-for-2016-c-inappropriate","title":"New suggestions for 2016 - (C) INAPPROPRIATE","text":""},{"location":"BT.html#am-i-over-sharing","title":"Am I over sharing?","text":""},{"location":"BT.html#ian-comment_6","title":"Ian comment:","text":"<p>Pandora's box. Best left to graduate students....</p>"},{"location":"BT.html#alan-comment_7","title":"Alan comment:","text":"<p>How much is \"over\"? Could this be extended to consider people who are invisible on the web, or don't have easily verified identities (perhaps because of common name)? It's going to require a search index, and I can't imagine any serious alternative to using Google API (or perhaps a Google alternative?) Wouldn't want to encourage 1b students to create indexing spiders.</p>"},{"location":"BT.html#original-suggestion_8","title":"Original suggestion","text":"<p>In recent years, many people have protested about how complex the privacy settings of many widely used social media sites. Social media sites like Facebook are not the only source of personal information that is freely available online: there are professional sites like LinkedIn, as well as less obvious sources such as electoral registers and local planning authorities. Including privileged sources enriches the available data even further, including things like credit checks.</p> <p>The complexity arises from understanding and quantifying the reliability of sources, and unifying different data sources. There should also be consideration about how relevant the information is and which sources are most trusted.</p> <p>The aim of this project is to find a way to discover and present the user with an assessment of how much personal data they have exposed online. This method must be easy to use, and ideally, provide recommendations about how to improve the situation if required.</p>"},{"location":"BT.html#sudo-and-network-security","title":"Sudo and network security","text":""},{"location":"BT.html#alan-comment_8","title":"Alan comment:","text":"<p>Framed as a consultancy report - not enough design content.</p>"},{"location":"BT.html#original-suggestion_9","title":"Original suggestion","text":"<p>Understanding security is of crucial importance to business, for the protection and availability of their IT infrastructure, and the protection of intellectual property and customer data stored on it.</p> <p>The best practice is to apply security in layers, but any security is only as good as its weakest link, with perceived risk balanced against the initial and ongoing cost of a solution. This project is to understand what protection we can apply through skilful use of the Sudo command set to a program or application, running on Linux and UNIX devices hosted on a network operating Active directory.</p> <p>The outcome of this project is to find, document and demonstrate ways to enhance security using the Sudo command set. The main areas to address are:</p> <ul> <li>Protection of the Sudoers file</li> <li>User account and role separation</li> <li>Protection against Sudo weaknesses that could lead to account   compromise</li> <li>Applying penetration testing to demonstrate the strengths and   weaknesses of the solution Further scope could include a cost, risk   and benefits analysis, an analysis of usability and management   overhead, and a comparison with other solutions.</li> </ul>"},{"location":"BT.html#anonymisation-of-big-data-sets","title":"Anonymisation of big data sets","text":""},{"location":"BT.html#alan-comment_9","title":"Alan comment:","text":"<p>Not appropriate for group project. Perhaps a technically minded student at JBS?</p>"},{"location":"BT.html#original-suggestion_10","title":"Original suggestion","text":"<p>Big data and data security make up two of today\u2019s hot topics. People make use of these big data sets for research, system testing, freedom of information disclosures, and even as resources in innovation competitions. In order to safeguard the privacy of the people described in this data, it must go through some anonymisation process. Narayanan et al have written an insightful paper on the subject, titled \u201cA Precautionary Approach to Big Data Privacy\u201d, that forms a good starting point for this project. The Information Commissioners Office publishes a Code of Practice about anonymisation, which sets out the reasons for and standards expected of a solution.</p> <p>This project aims to understand the anonymisation problem by understanding the state of play in research and practice, and then developing, or pointing at, robust but practical tools. These tools should would work in both trusted, for instance audit use, and open, for instance publicly released online, environments.</p> <p>It should justify the value of data anonymity traded off against retention of the statistical properties of the data. As an extra step, the project could contrast research and system test value of anonymised data with synthetically generated data sets.</p>"},{"location":"BT.html#hunting-domain-generation-algorithms","title":"Hunting domain generation algorithms","text":""},{"location":"BT.html#alan-comment_10","title":"Alan comment:","text":"<p>Looks more like a Part II project - explore a single data set, with not much for a team to do.</p>"},{"location":"BT.html#original-suggestion_11","title":"Original suggestion","text":"<p>Malware deployed on the internet relies on contacting servers for its command and control. There is a battle going on between the malware designers and internet providers, where the designers open a new control server, and the providers try to find it and block it as quickly as they can to protect their customers.</p> <p>The malware designer\u2019s best weapon is the domain generation algorithm. It is there to generate new domain names for the control servers dynamically, so that the malware implants don\u2019t have to contain a list of control servers that they will use in the future, meaning internet providers can\u2019t pre-emptively block their URLs.</p> <p>The aim of this project is to look into the DNS data flowing across the BT network, and find ways to detect the activity of a domain generation algorithm. When it identifies a generated domain, it should try to cluster similar instances, and then try to classify it against known malware. The ideal outcome is that we find new malware very quickly, allowing us to block it or capture it for static analysis. In order to make this project realistic, we expect to provide real anonymised data from the BT network.</p> <p>The outcome of the project should be software that can examine network data, and carry out the clustering and classification. You could apply many techniques, likely focussing around machine learning.</p>"},{"location":"BT.html#improving-the-performance-of-facial-recognition-algorithms","title":"Improving the performance of facial recognition algorithms","text":""},{"location":"BT.html#alan-comment_11","title":"Alan comment:","text":"<p>Unlikely that 1B students would make progress on this. Could perhaps focus on small dataset for candidate matches, in order to use a quick and dirty algorithm rather than state of the art.</p>"},{"location":"BT.html#original-suggestion_12","title":"Original suggestion","text":"<p>Computer Vision forms a field of its own in research, and people have made exciting breakthroughs in how well software can recognise and identify individuals in an image. The process is still computationally expensive, and when resource constrained, slow.</p> <p>We would like to port the functionality to mobile devices, so that for instance security personnel carrying cameras can have individuals around them identified against known images in real time.</p> <p>The outcome of this project would be a theoretical explanation and demonstrable improvement in the time taken for identification. This project would suit an advanced student with a background in computer vision.</p>"},{"location":"BT.html#last-year-2014","title":"Last year - 2014","text":"<p>Contacts: fraser.burton@bt.com</p> <p>Projects proceeding:</p> <ul> <li>Multi-touch Conference</li> <li>Money World</li> </ul>"},{"location":"BT.html#original-suggestions","title":"original suggestions","text":"<p>Project 1 : How important is visual feedback to the success of in air gesture UIs ?</p> <p>Catherine White</p> <p>In air gesture control has been imagined for decades and was popularized by the film Minority Report. In recent years, hardware such as Kinect and Leap Motion have transformed the concept to technical reality. However, no really pervasive in air gesture control UI has emerged. One hypothesis for this lack of success is that lack of visual feedback make such UIs difficult to control, requiring too much conscious effort. You will investigate how providing visual feedback affects the ease of use of an in air UI. You will consider the users awareness of himself and his state of interaction with the system. You will develop a UI for the purposes of running experiments (based on Leap Motion or Kinect hardware) and run experiments to determine effortlessness of use. You will choose whether to design a UI to be fully intuitive, or to develop a UI which requires learning but is then very easy to use. The types of visual feedback that you could consider providing to the user include: wire frame models of the user interacting with the system; abstract geometric representations (such as an bounding ellipsoid mapped to a hand, or cursors mapped to the end of each finger); or variations of colour, shade and shadow on the screen.</p> <p>Project 2: Collaborative Multitouch Interfaces</p> <p>Catherine White</p> <p>10 point multitouch screens are now widely available, and continuous surface touch interfaces are also technically possible. How can two or more people make use of such an interface on a large screen or surface, for collaborative activities? You can draw on examples from social activities, games or the workplace and will think of a concept, develop and implement it. Finally, you will need to design and run usability tests of your idea to assess whether it has potential.</p> <p>Project 3: Novel interactive data visualisations and UI demo</p> <p>Ben Azvine</p> <p>BT\u2019s networks are a source of huge quantities of time-varying data which have many variables. A wealth of information can be extracted from such data, but initial exploration of the dataset may be formidable, particularly when the features of the dataset are initially completely unknown. There are a few standard means of data visualisation including trend graphs, bubble diagrams, network diagrams, pie charts, geographical maps, sun ray diagrams, and radial views. This project asks you to discover alternative Opensource visualisation techniques beyond these methods and to build an interface using one of these for the purpose of exploring a large, complex graph dataset visually in a way that allows discovery of correlations and clusters in the dataset (such as relatedness in a single or multiple category).</p>"},{"location":"BT.html#2013","title":"2013","text":"<p>Contacts: paul.reid@bt.com james.mistry@bt.com oliver.newbury@bt.com</p> <p>Final project was: Terabyte threat analysis</p> <p>Original introduction via Calum Eadie</p>"},{"location":"Barn4.html","title":"Barn4","text":"<p>Cambridge-based AgriTech incubator - current contact is via Charles Gentry and Michael Gifford at NIAB</p>"},{"location":"BeatGPT.html","title":"BeatGPT","text":"<p>Suggestion by Bhasi Nair (needs some additional technical elements, and likely to name a colleague as client):</p> <p>ChatGPT is reasonably good at answering general knowledge questions, perhaps far better than the average human. However we can expect the average human's capacity for theory of mind to far exceed any capabilities of ChatGPT to imitate a capacity for theory of mind, in the correct context. In contexts where the wisdom of the crowd fails, it has been shown that a follow-up question probing the crowd's expectations about the answers of others (a theory of mind question) can be used to arrive at the correct answer. Can this method, known as the \"surprisingly popular algorithm,\" be used as a source of inspiration to engineer prompts that can function as (noisy) Turing tests? And can such prompts be generated at scale?</p> <p>My original:</p> <p>ChatGPT is very good at answering the kinds of question where everybody already knows the answer. It is terrible in situations where the \u201cwisdom of crowds\u201d fails, and the Internet (or Reddit) never had the right answer. There are known strategies to compensate for this. Your task is to build an online platform for question answering that does exactly what ChatGPT can\u2019t, by using those social metrics to reliably identify the answers that are surprising but true.</p>"},{"location":"Beer_Goggles.html","title":"Beer Goggles","text":"<p>Augmented reality project for Google Glass that displays the distance to the nearest pub and shows the direction to go to get there. Obviously, this could be made more general to provide directions to other types of destination, either at a street level, or for example giving directions to a user in an unfamiliar building, but the name wouldn\u2019t work then!</p> <p>We\u2019d provide one pair of Google Glass glasses (to be returned!).</p> <p>Feedback: We'd like to include some Google Glass apps this year, and I'm sure students would be interested. However, we have done quite a few navigation apps in the past, so I'd like to extend this one (also slightly concerned that we had to cancel a project called \"wine goggles\" last year after lack of interest from students, who perhaps are not so interested in alcohol as we might assume).</p>"},{"location":"Bicycle_retailer_example.html","title":"Bicycle retailer example","text":"<ul> <li>Accessories &gt; Keyrings</li> <li>Accessories &gt; Water Bottle Cages</li> <li>Accessories &gt; Water Bottles</li> <li>Accessories &gt; Miscellaneous</li> <li>Accessories &gt; Watches</li> <li>Accessories &gt; Sunglasses</li> <li>Accessories &gt; Computers</li> <li>Accessories &gt; Locks</li> <li>Accessories &gt; First Aid Kits</li> <li>Accessories &gt; Umbrellas</li> <li>Accessories &gt; Mugs &amp; Glasses</li> <li>Accessories &gt; Cycle Mirrors</li> <li>Accessories &gt; Lanyards</li> <li>Accessories &gt; Number Plates &amp; Numbers</li> <li>Accessories &gt; Bags</li> <li>Accessories &gt; Baskets</li> <li>Accessories &gt; Bells</li> <li>Accessories &gt; Lights</li> <li>Accessories &gt; Magazines</li> <li>Accessories &gt; Movies</li> <li>Accessories &gt; Mudguards</li> <li>Accessories &gt; Pumps</li> <li>Accessories &gt; Stickers</li> <li>Accessories &gt; Timing</li> <li>Accessories &gt; Helmet Cameras</li> <li>Accessories &gt; Bike Covers</li> <li>Accessories &gt; Bike Racks</li> <li>Accessories &gt; Child Seats</li> <li>Accessories &gt; Gift Vouchers</li> <li>Accessories &gt; Hydration Packs</li> <li>Accessories &gt; Maps &amp; Books</li> <li>Accessories &gt; Pannier Racks</li> <li>Clothing &gt; Gloves</li> <li>Clothing &gt; Base Layers</li> <li>Clothing &gt; Compression Wear</li> <li>Clothing &gt; High Viz</li> <li>Clothing &gt; Sports Bras</li> <li>Clothing &gt; Tee Shirts</li> <li>Clothing &gt; Tights</li> <li>Clothing &gt; Swimwear</li> <li>Clothing &gt; Tri Race Wear</li> <li>Clothing &gt; Wetsuits</li> <li>Clothing &gt; Swim Accessories</li> <li>Clothing &gt; Swim Training Aids</li> <li>Clothing &gt; Clothing Accessories</li> <li>Clothing &gt; Shirts</li> <li>Clothing &gt; Running Accessories</li> <li>Clothing &gt; Arm Warmers</li> <li>Clothing &gt; Leg Warmers</li> <li>Clothing &gt; Beanies and Caps</li> <li>Clothing &gt; Jackets - Casual</li> <li>Clothing &gt; Jeans &amp; Pants</li> <li>Clothing &gt; Shorts - Casual</li> <li>Clothing &gt; Cycle Caps</li> <li>Clothing &gt; Gilets - Cycle</li> <li>Clothing &gt; Jackets - Cycle</li> <li>Clothing &gt; Jerseys - Cycle</li> <li>Clothing &gt; Pants - Cycle</li> <li>Clothing &gt; Shorts - Cycle</li> <li>Clothing &gt; Gilets - Run</li> <li>Clothing &gt; Jackets - Run</li> <li>Clothing &gt; Shorts - Run</li> <li>Clothing &gt; Socks</li> <li>Clothing &gt; Sports Headwear</li> <li>Clothing &gt; Swim Caps</li> <li>Clothing &gt; Clothing Care</li> <li>Clothing &gt; Trouser Clips</li> <li>Clothing &gt; Wallets</li> <li>Clothing &gt; Anti-Pollution Masks</li> <li>Clothing &gt; Belts</li> <li>Clothing &gt; Tops</li> <li>Frames &amp; Forks &gt; Forks</li> <li>Frames &amp; Forks &gt; BMX Frames</li> <li>Frames &amp; Forks &gt; Cyclo-X Frames</li> <li>Frames &amp; Forks &gt; Frame Protection</li> <li>Frames &amp; Forks &gt; Frame Spares</li> <li>Frames &amp; Forks &gt; MTB Frames</li> <li>Frames &amp; Forks &gt; Road Frames</li> <li>Frames &amp; Forks &gt; TT Frames</li> <li>Nutrition &amp; Training &gt; Body Maintenance</li> <li>Nutrition &amp; Training &gt; GPS</li> <li>Nutrition &amp; Training &gt; Nutrition</li> <li>Nutrition &amp; Training &gt; Heart Rate Monitors</li> <li>Nutrition &amp; Training &gt; Training Aids</li> <li>Nutrition &amp; Training &gt; Tri Accessories</li> <li>Nutrition &amp; Training &gt; Turbo Trainers</li> <li>Wheels &amp; Tyres &gt; Bargain Wheels</li> <li>Wheels &amp; Tyres &gt; Hubs</li> <li>Wheels &amp; Tyres &gt; Nipples</li> <li>Wheels &amp; Tyres &gt; Quick Releases</li> <li>Wheels &amp; Tyres &gt; Rim Tape</li> <li>Wheels &amp; Tyres &gt; Rims</li> <li>Wheels &amp; Tyres &gt; Spokes</li> <li>Wheels &amp; Tyres &gt; Tubeless Kits</li> <li>Wheels &amp; Tyres &gt; Tubes</li> <li>Wheels &amp; Tyres &gt; Tyres</li> <li>Wheels &amp; Tyres &gt; Wheels</li> <li>Wheels &amp; Tyres &gt; Valve Caps</li> <li>Wheels &amp; Tyres &gt; Power Meter Wheels</li> <li>Wheels &amp; Tyres &gt; Power Meter Hubs</li> <li>Workshop &gt; Pressure Washers</li> <li>Workshop &gt; Bolts</li> <li>Workshop &gt; Lubes Cleaning</li> <li>Workshop &gt; Maintenance Books</li> <li>Workshop &gt; Tools</li> <li>Workshop &gt; Workstands</li> <li>Footwear &gt; Shoes - Casual</li> <li>Footwear &gt; Shoes - Cycle</li> <li>Footwear &gt; Overshoes</li> <li>Footwear &gt; Shoes - Run</li> <li>Footwear &gt; Sandals</li> <li>Components &gt; Chain Guides</li> <li>Components &gt; Crank Bolts</li> <li>Components &gt; Handlebar Tape</li> <li>Components &gt; Power Meters</li> <li>Components &gt; Rear Shocks</li> <li>Components &gt; Seatclamps</li> <li>Components &gt; Gear Shifters</li> <li>Components &gt; Brakes</li> <li>Components &gt; Derailleurs</li> <li>Components &gt; Groupsets</li> <li>Components &gt; Bar Ends</li> <li>Components &gt; BMX Seats</li> <li>Components &gt; Brake Cables</li> <li>Components &gt; Brake Levers</li> <li>Components &gt; Brake Pads</li> <li>Components &gt; Brake Spares</li> <li>Components &gt; Gear Cables</li> <li>Components &gt; Headset Spacers</li> <li>Components &gt; Rear Shock Springs</li> <li>Components &gt; Grips</li> <li>Components &gt; Handlebars</li> <li>Components &gt; Saddles</li> <li>Components &gt; Seatposts</li> <li>Components &gt; Stems</li> <li>Components &gt; Headsets</li> <li>Components &gt; Pedals</li> <li>Components &gt; Pegs</li> <li>Components &gt; Chains</li> <li>Components &gt; Chainrings</li> <li>Components &gt; Cranksets</li> <li>Components &gt; Cassettes</li> <li>Components &gt; Bar End Plugs</li> <li>Components &gt; Bash Guards</li> <li>Components &gt; Bottom Brackets</li> <li>Components &gt; Chain Tugs</li> <li>Components &gt; Chainring Bolts</li> <li>Bikes &gt; Road Bikes</li> <li>Bikes &gt; TT Bikes</li> <li>Bikes &gt; BMX Bikes</li> <li>Bikes &gt; Bike Trailers</li> <li>Bikes &gt; Cyclo Cross Bikes</li> <li>Bikes &gt; Folding Bikes</li> <li>Bikes &gt; Hybrid &amp; City Bikes</li> <li>Bikes &gt; Kids Bikes</li> <li>Bikes &gt; Mountain Bikes</li> <li>Protection &gt; Goggles</li> <li>Protection &gt; Helmets</li> <li>Protection &gt; Body Armour</li> <li>Protection &gt; Neck Braces</li> </ul>"},{"location":"BigPay.html","title":"BigPay","text":"<p>Proposed projects for 2022:</p> <ul> <li>International Treasury   Service</li> <li>Household Payment Pool</li> </ul> <p>Two suggestions:</p> <p>(a) A treasury management system: BigPay operates in MY and SG and you can move money between the two. Currently, we use an external service provider to do this but obviously it would be more efficient to do it ourselves. To do so, we would have to manage reserves of both currencies (MYR and SGD), set an exchange rate, and execute and settle transfers. It takes about a day to physically move money (via our partner banks) between Malaysia and Singapore or between our currency brokers and us. Your job is to design a software system capable of managing and visualising these reserves. It should take a feed of the buy and sell rates available to us from our partners at various distances (1d,7d,30d) and export an API allowing users to give a target currency and amount and receive a price (and then confirm the transfer). As far as possible, the system should achieve optimal revenue. You will need to write a simulator for exchange rates and for customer behaviour.</p> <p>(b) Playing games with money is quite fun. As such, we'd like to introduce a game in which housemates (or larger groups) can exchange transactions. When you spend money, the transaction will be charged to some random member(s) of the group - possibly split. The catch is that you will never be charged more money than you would otherwise have spent in a given period (tunable by either you or the group). Design suitable rules and build a UI and transaction recording system that allows people to play this game.</p>"},{"location":"BioRISC.html","title":"BioRISC","text":"<p>Based in St Catherine's affiliated with the Department of Zoology and Cambridge Conservation Initiative</p> <p>Used as client affiliation for the Conservation Evidence Synthesis project</p>"},{"location":"Bloomberg.html","title":"Bloomberg","text":""},{"location":"Bloomberg.html#project-suggestions-for-2016","title":"Project suggestions for 2016","text":"<p>Pebble Jogging App</p> <p>We would like you to make a hazard warning app on the smartwatch Pebble. When a user takes their Pebble for a jog, he/she can take notes on any potential hazard they come across on the road, such as broken pavement, dog dirt, flooding... After the run, they can pair their Pebble to a computer program or mobile app, and upload the data via an interactive map. This allows other Pebble users to download the data, and receive an alarm when they are near the hazard.</p> <p>1) Safe way home</p> <p>Goal: Build a form of detection for crime in the local area. This would involve crime alerts with the scope to include GeoTagging, mapping the danger of certain routes and the detection of where you are if you experience/see a crime. A Pebble smart watch will be used for detecting the user's location and for quickly reporting a crime, and the watch should be paired with an Android phone for getting alerts.</p> <p>Feedback:</p> <p>Nice. Based on last year, students will be keen to get some experience of wearables. We need to think of a scenario that does rely on the Pebble - if the user is also carrying an Android phone, then couldn't it be used for the whole application? How about a related application for sports/fitness users, for times when someone might be out jogging with your Pebble, but no phone? Do you know if Pebble apps can run standalone for later upload of data? One idea might be a jogging hazard map - collect information on broken pavements, dog dirt, flooding ... and report to other joggers at the end of your run via an interactive map, or even a warning application that will run on another pebble to sound alarm when approaching hazards.</p> <p>2) Scanning and printing of real-life objects</p> <p>Goal: Use cameras/sensors to take a 360 degrees image around an object. Build a 3D model from the image, then send it off to a 3D printer to get a miniature copy of the real-life object. Technical description: Use or a build a SLAM implementation (there are open-source ones, in particular for Kinect) to get a 3D model from a scene, then improve the model for 3D printing (remove holes etc.) export the geometry as the correct file format (probably STL) and finally send it to a 3D printer.</p> <p>Feedback:</p> <p>probably a bit too close to commercial products, meaning that results might be disappointing to students (we have had design briefs along these lines in the past, but at a time when 3D scanning was more of a novelty).</p>"},{"location":"Bloomberg.html#project-suggestions-from-2015","title":"Project suggestions from 2015","text":"<ul> <li>Audio Websites on   Smartphones</li> </ul>"},{"location":"Bloomberg.html#earlier-suggestions","title":"Earlier suggestions","text":"<p>Project 1: An Interactive, Freeform Board</p> <p>When planning and developing projects, it is often necessary to brainstorm and conceptualise ideas across multiple locations. You will create an application to allow us to share free-form content in a whiteboard format, with multiple users able to update the board simultaneously. This should be available on both desktops and mobile devices. The key challenge will be ensuring that updates from multiple users are handled elegantly. Additions and edits may want to be displayed differently. These problems should be carefully considered with attention given to the user experience.</p> <p>Feedback:</p> <p>The Interactive Freeform Board idea is quite similar to projects that we\u2019ve done in the past, but boards like this are now distributed around our building, so it\u2019s no longer quite as interesting as it has been. We did use a large multi-user touchscreen for a project like this last year, but that was with a client that loaned special hardware to make it more interesting.</p> <p>Project 3: I am also thinking about a third project, for those more financially-minded. Bloomberg has created an open-API (http://www.bloomberglabs.com/api), which offers easy access to financial market data, and we have hosted a few hackathons using this api. I'm trying to come up with a cool project involving using this api. From your experience, do you think this may be something the students will enjoy?</p> <p>Feedback:</p> <p>We could certainly consider this, although I see that the documentation is several hundred pages \u2013 we usually try to minimise the amount of time devoted to learning specific development tools, given the short duration of the projects. However, you said that this API has successfully been used in hackathons in the past? Were these one day events? If so, could you give some examples of the kinds of app that resulted from them?</p>"},{"location":"Boeing.html","title":"Boeing","text":"<p>Suggestion for 2021:</p> <p>Proposed client: Luke Baxter (luke.b.baxter@boeing.com)</p> <p>Interested in use of probabilistic programming approaches that allows decision makers to intuitively specify and explore policy models when interacting with autonomous agents.</p>"},{"location":"Boeing.html#2017","title":"2017","text":"<p>I wonder if we should propose something that applies machine vision to existing social media video streams? The Periscope API has now been closed down, but I heard that WeChat has both good API and Video support.</p> <p>Who's at my party?</p>"},{"location":"Boeing.html#2016","title":"2016","text":"<p>Architecture for a Video Facebook</p>"},{"location":"Boeing.html#earlier-suggestions","title":"earlier suggestions","text":"<p>Non-linear Video Synthesis</p> <p>Digital video-editing suites such as Adobe Premiere and Apple iMovie are stuck in a 20th century linear film model: a sequence of clips is joined end-to-end, possibly with overlap transitions. However in today's films, live action and digital graphics are far more integrated, often with animated characters and blue screen footage composed onto a live video scene overlaid with simulated weather. We already have tools for digital music production that blend many overlapping tracks, some live and some synthesised, with many concurrent filters and effects. Your task is to build a system for creating non-linear combinations of video source material, animations and filters. You should model it on the SuperCollider system for sound and music synthesis, which constructs a graph of unit generators passing data streams between them.</p> <p>Another alternative:</p> <p>YouTube meets Facebook</p> <p>Kids love YouTube, but video is currently very one-dimensional - play, rewind, fast-forward. In contrast, the Facebook \"timeline\" is actually a multimedia narrative, weaving in conversations, status updates, links to friends and so on. Your task is to make a non-linear version of YouTube, in which videos can be mixed with each other, and with text and drawings, allowing each user to create their own narrative storyline. The architecture to support arbitrary non-linear combinations of different media will be a technical challenge. You could model it on the SuperCollider system for sound and music synthesis, which constructs a graph of unit generators passing data streams between them, to allow filters, blends and graphic overlays. Start with a locally-hosted version, and think about a cloud service version (probably with lots of local media caching) as an extension.</p> <p>Yet another alternative:</p>"},{"location":"Boeing.html#2015-project","title":"2015 project","text":"<p>Micro-friends video diary</p>"},{"location":"Bohemia_Interactive_Simulations.html","title":"Bohemia Interactive Simulations","text":"<p>Andy Fawkes andy.fawkes@bisimulations.com</p> <p>2018 idea:</p> <p>Perhaps we could use a pretrained object recogniser to populate the OpenGL model, along the lines of this project from last year? Neural Guide</p> <p>The object in the real world is recognised and then perhaps from a library of 3D models the real object is modelled in the virtual world. Feels like there would be a number of challenges to overcome for the students and it's a worthwhile project from our perspective.</p> <p>Virtual World Generator</p> <p>It is possible to make accurate 3D scans of indoor scenes using depth cameras such as Google Tango or expensive LIDAR scanners. Although the overall geometry is accurate, individual objects cannot be distinguished.Your task is to use a simple SLAM algorithm to recover overall room dimensions, but populate a navigable virtual world in OpenGL using standard 3D library models of furniture and other objects that have been recognised as belonging to relevant categories using pre-trained deep neural net models such as NeuralTalk Model Zoo.</p> <p>Original enquiry</p> <p>Very much in the concept phase but the idea would be to use AI to recognise objects in the real world and then place them in a virtual world. One of the use cases would be for planning missions for say blue light services/military. A drone would be sent into an area and scan the scene, not only collecting the visuals but automatic recognition of say doors, windows, fauna and flora etc which could then be used to populate a simulation (eg. in OpenGL). This is a real issue as it's easy enough to visualise a scene through cameras, LIDAR etc. but much more difficult to categorise objects in the scene for use in the simulation were interaction with objects is important.</p> <p>We were funded by Dstl to look at this problem a year or so ago. It's not just for use in simulation, drones need to understand their environment better, so they don't bump into a window thinking it is a gap. We worked with UCL and a few others using LIDAR data but we ran out of time. Not sure if we still have the data but this would be an alternative approach, perhaps using the cloud to do the AI processing. I am thinking keep it simple, a camera senses a scene, the AI recognises a door (for example) and populates/tags the virtual 3D world of the same scene with the door.</p> <p>2017 advertised:</p> <p>Simulation and Warning for Cyclists</p> <p>My suggestion:</p> <p>Too many cyclists in London and Cambridge are injured or killed by collisions with trucks and buses. We have data that could help. All Cambridge buses have real time GPS tracking, and cyclists often wear GPS devices like the Pebble smart watch. We propose an online training simulator, accessed from screens but based on real data, to help drivers and cyclists learn to avoid such accidents. The real time data and decisions can even be fed back to cyclists out on the streets, with coded buzzes on their wrist helping plan routes and avoid danger ahead. With real-time data throughout, it should be possible to coordinate the simulator with real actions.</p> <p>Based on idea:</p> <p>Exploiting Wearables in the Virtual and Real Worlds</p> <p>Our client wishes to explore the utility of using wearables to help train and then guide/warn its employees working in hazardous environments. As the first step your task is to create a testbed of a 3D interactive world linked to a wearable (eg. a Pebble Watch). As the human navigates this virtual world the wearable will vibrate to guide/warn them. This is intended to help train them ahead of completing the same task in the real world. Our client would also like to see this same task carried out in the real world to help capture any training benefits of using wearables in this way. An example of a task might be navigating different complex routes around the Computer Laboratory Campus. Following these demonstrations the client requires a report on the benefits and challenges of using wearables in this way and recommended next steps towards developing a robust fielded system.</p> <p>Suggested, but not proceeding:</p> <p>Bus Buzzer</p> <p>2017 idea:</p> <p>Exploiting Wearables in the Virtual and Real Worlds</p> <p>We would like a wearable (eg. a Pebble Watch) to provide feedback to a human who is tasked with achieving goals within a virtual world to help prepare and then guide the human carrying out the same task in the real world. This might have a number of uses, for example guiding a human when visibility is low in the real world, but we are open to other uses both for training and for entertainment. We are also interested in such a system being able to transmit data from the wearable to the virtual world, eg. pressing a button on the wearable will trigger an activity in the virtual world. This could be part of the task that the human has to achieve in the real world and again will permit them to practice it in the safety of the virtual world.</p> <p>A Wearable-Virtual World Tie Up</p> <p>Current wearable technology such as the Pebble Watch and Android Wear provide feedback to users such as vibration in the real world. But what might the value be linking such technology to the virtual world? The aim of this project is to create a technology demonstrator that links a virtual world/simulation to a wearable such as a Pebble Watch or at least an emulator. Events that take place in the virtual world must trigger physical feedback in the wearable such as vibration. The feasibility of actions in the real world being transmitted into the virtual world should also be investigated and ideally demonstrated (eg. pressing a button on the wearable will trigger an activity in the virtual world). The purpose of this demonstrator will not be prescribed but we envisage that it might be used in training so that the user gets feedback from their training that goes beyond what they would get with a typical games controller, eg. a vibration signals that they have achieved or failed a task and/or their performance is recorded on the wearable.</p> <p>Perhaps not for 2017:</p> <p>Pictorial Turing Test</p> <p>The traditional Turing Test is usually implemented as a text chat session. Some trivial versions such as CAPTCHA test the ability to translate pictures into text. But would it be possible for a machine to pass a Turing Test using pictures alone, with no text at all? \u201cQuestions\u201d might take the form of maps, plans, charts or photographs, and \u201cAnswers\u201d could be interpretive drawings, perhaps in the style of Cohen\u2019s Aaron or Colton's Painting Fool. The only rule is no text or numbers \u2013 imagine giving an iPad to someone who speaks a different language, where you\u2019d like them to believe that they are communicating with a real person as they draw on the screen or capture images.</p> <p>2016 project:</p> <p>Surprise the Singularity</p> <p>earlier drafts ....</p> <p>If a super-intelligent artificial intelligence takes over the world, Cambridge is likely to be the first target. Unfortunately, we have published important strategic information online, where the Singularity can easily find it. For example, the Computer Lab layout is at https://www.cl.cam.ac.uk/research/dtg/openroommap/, and the University map at https://wiki.cam.ac.uk/university-map/. Your task is to confuse the Singularity by creating distractor maps, navigated in way that a disembodied mind might not realise are impossible, for example as Moebius strips or non-Euclidean spaces. Don't show the whole map at once, where the edges will spoil the illusion. But do include a simulation of real activity - public transport synced with real-time information from Cambridge buses, simulated self-driving cars, and of course locative social media messages from the (simulated) people in the panicking crowds.</p> <p>Using the Computer Lab as a target might be good. We do have an open format map of the building:</p> <p>https://www.cl.cam.ac.uk/research/dtg/openroommap/</p> <p>There is also a useful API that can be used for Cambridge-wide applications based on an open map of the University:</p> <p>https://wiki.cam.ac.uk/university-map/Map_Annotation</p> <p>If we were looking at spread of information across Cambridge, it would be possible to use the following system as a source, based on advertised events in a particular location:</p> <p>http://talks.cam.ac.uk/document/XML%20feeds</p> <p>For example, we could model how long it takes for news of a human extinction event to propagate from a seminar in this series, to the various machine rooms that might house an AI:</p> <p>http://talks.cam.ac.uk/show/archive/52792</p>"},{"location":"Bone_Doctor.html","title":"Bone Doctor","text":"<p>Large databases of labelled X-ray images such as the MURA dataset of broken bones can be used to train AI systems that provide medical advice. An intelligent clinical assistant should be able to take a previously unseen X-ray image and link it directly to cases that can guide possible treatment. Your task is to train a neural network that will find a variety of other cases that are clinically similar, but visually distinct, presented in a visual overlay that highlights local differences for a clinician to review.</p>"},{"location":"Boosting_Skills_after_COVID-19.html","title":"Boosting Skills after COVID 19","text":"<p>sherryleighcoutu@gmail.com</p> <p>Digital Boost is an online learning platform to help people who work for small businesses and charities to be mentored in \u2018all things digital\u2019, to enable them to come out of the COVID-19 crisis stronger. A 46-part taxonomy of skills currently covers 12,000 courses from 6 different providers. Your challenge is to create an intelligent navigation and guidance tool that creates a unique journey for each person, using multiple sources of information to build a model of that person's needs and experience, and drawing on opportunities for mentoring, workshops, short courses and other resources as appropriate to their needs.</p>"},{"location":"Braille_Predictive_Text.html","title":"Braille Predictive Text","text":"<p>David MacKay\u2019s Dasher was a radical predictive text system where a machine learning language model helped users with disabilities by guiding them to zoom in to more likely possible texts. That\u2019s no use for people with a vision impairment, who can\u2019t see the guidance or easily operate animated graphical interfaces. This is an opportunity to work with a team who have recently augmented the classic mechanical Braille typewriter with internet connectivity. Your prediction model will help users to learn and master Braille, by offering appropriate spoken suggestions on what word they might be typing and (if needed) remind them which keys they might need to press next. All this will have to be designed in a way that is helpful, motivational and accessible, not an additional obstacle to learning Braille!</p>"},{"location":"British_Antarctic_Survey.html","title":"British Antarctic Survey","text":"<p>2019 project: Groundwater App</p> <p>potential project with BAS using ground-penetrating radar for identification of aquifers.</p> <p>Martin, Carlos cama@bas.ac.uk</p> <p>Mark Muller mmuller.earthsci@gmail.com</p>"},{"location":"British_Antarctic_Survey.html#previous-years","title":"previous years","text":"<p>Initial contacts:</p> <ul> <li>Beatrix Schlarb-Ridley beatrix@bas.ac.uk</li> <li>Dave Connor dacon@bas.ac.uk</li> </ul> <p>Technical contact:</p> <ul> <li>Matt Polaine maine@bas.ac.uk</li> </ul> <p>Design brief: Antarctic Chasm One</p> <p>Extended version - needs to be edited down!</p> <p>Antarctic Chasm One</p> <p>The Brunt Ice Shelf in the Antarctic is growing a massive chasm at the rate of 1.7km a year, that may lead to an area of nearly 1,000sqkm breaking off and taking the Halley VI base with it. To avoid this BAS has decided to move Halley VI \u2013 a considerable undertaking. http://www.bbc.co.uk/news/science-environment-36197657</p> <p>Your task is to work with British Antarctic Survey (BAS) to make a 3D immersive visualisation of this growing chasm, allowing viewers to descend into it in the way that BBC\u2019s Peter Gibbs did on camera, but using machine learning methods to extrapolate the growth of the chasm over time and into the future to the point of eventual separation. This animation of the crack propagation to be compressed in time, with ~5 minutes representing ~50 years, from detection of chasm change to Brunt calving. You will have access to many sources of aerial scans/photographs/video, multispectral satellite imagery, (entire length) ground penetrating radar cross section of the crack and photogrammetric modelling of a ~300m section of the chasm.</p> <p>Key challenges:</p> <p>The crack propagation trajectory is unknown, although Hilmar can advise on likely scenarios. Some image footage is missing; some of it is due to flat light (no shadow) problems, and also because of the scale (4k video, 25fps, 40km, at multiple drone passes limited to 300m at a time due to battery performance at low temperatures \u2013 not currently possible). Extrapolation of known data will be required to model unavailable/unknown aspects of Chasm One.</p> <p>The single point of contact at BAS will be Matt Polaine, Innovation Manager. He will coordinate your data/technical requests to the key science, imaging and audio staff such as Hilmar Gudmundsson, Andrea Cziferszky and Pete Bucktrout.</p> <p>The immersive effect will require spatialized audio. Some of this audio may be available from BAS, some may need \u2018creation\u2019.</p> <p>Depending on the course requirements, BAS may be able to assist with the supply of some hardware, but funds are limited. We might consider for example the use of a console such as the PS4pro and VR headset to provide the VR experience. However given the scale of the landscape, considerable LOD modelling/horizon may be required to reduce CPU loading to meet the require fps of dual screens for VR. If the required fps can\u2019t be met for the VR experience in the time available, then this is understood.</p> <p>A final presentation of the project would be expected at BAS, describing how the project achieved its end result, and what might be possible in the future/with more time.</p> <p>Summarising the resource side:</p> <p>1. Student resource \u2013 team of 6 working for 7 weeks, starting mid January, about 600 person-hours</p> <p>2. BAS resource \u2013 one person (the \u201cclient\u201d) to attend 3 x 1-hour meetings during that period</p> <p>Regarding future data, it is possible that BAS may have more drone footage taken in November, however this won\u2019t be available until February 2017. BAS would also wish to use the UCam model for presentations at BAS, and there might be an opportunity to use the modelling in a future BBC Horizon documentary about the Halley VI move, but this is currently speculative.</p> <p>My previous suggestion:</p> <p>The Brunt Ice Shelf in Antarctic is growing a massive chasm, that may lead to an area the size of Wales breaking off. Your task is to work with British Antarctic Survey to make a 3D immersive visualisation of this growing chasm, allowing viewers to descend into it in the way that BBC\u2019s Peter Gibbs did on camera, but using machine learning methods to extrapolate the growth of the chasm over time and into the future. You will have access to many sources of aerial scans, ground-based and water data collected by BAS. http://www.bbc.co.uk/news/science-environment-36197657</p> <p>Earlier idea:</p> <p>Antartica at Full Resolution</p> <p>Many people would like to visit Antarctica, but satellite imagery for most of the continent is rather disappointing. British Antarctic Survey have laser scan data, video recordings from drones, and lots of other environmental and audio data. Your task is to create a realistic experience, combining different data formats, that allows viewers to pilot a virtual remote drone from altitude right down to close-up flight at ground level, integrating data from different resolutions to provide the best possible experience of being there. You are welcome to build on and enhance standard viewers or game engines, and we hope to arrange loan of high-end graphics cards and VR headsets.</p>"},{"location":"British_Trust_for_Ornithology.html","title":"British Trust for Ornithology","text":"<p>For 2023:</p> <p>Potential client: Adham Ashton-Butt adham.ashton-butt@bto.org</p> <p>As I understand it, you\u2019re looking for an interface that can be used by bioacoustics researchers to enhance semi-supervised labelling of classifier training data, alongside application / evaluation of the resulting classifiers.</p> <p>We might want to give a hint regarding the kinds of algorithms to be applied, the nature of the sample data that would be used in a demonstrator, and the kind of user community this would be aimed at.</p> <p>In 2022: Flyathlon, created in consultation with BTO Director Juliet Vickery juliet.vickery@bto.org</p> <p>This is an updated variant of Flyathlon (2019 version), which did not proceed with a team (previously proposed client: Jennifer Border jennifer.border@bto.org)</p> <p>Originally based on suggestion by Chris Sandbrook: Cuckoo Race</p> <p>See also previous project from 2013: Race the wild</p> <p>Jenni's original request:</p> <p>We've done some investigation of the Strava API to allow us to access the total miles for a group. It doesn't look like this is possible so the application would need to:</p> <ol> <li>Manage groups</li> <li>Allow individuals to join a group</li> <li>Link the app with their Strava account so we can access their data</li> </ol> <p>We've also created some data that we could use as a starting point for the cuckoo path in a demo system.</p> <p>We'd also need a website for people to register groups and see outputs of all groups and a website or (preferably) an App where people could register for a group and see their individual progress.</p>"},{"location":"British_Trust_for_Ornithology.html#response","title":"response","text":"<p>Could you give us some information about \u201cStrava\u201d, and how a student project would have to interact with it?</p> <p>I wasn\u2019t sure from your message how \u201cgroups\u201d are defined (groups of people or groups of birds?)</p> <p>Perhaps there is another document, giving background to your discussion with Chris, that I haven\u2019t seen? Feel free to pass it on.</p>"},{"location":"Broadcom.html","title":"Broadcom","text":"<p>Contact Steve Barlow (ex-Argon Design) steve.barlow@broadcom.com</p> <p>Proposed client for 2021: Graham Rushton graham.rushton@broadcom.com</p> <p>22 October: I'll have a think over the next few days and see if I can come up with a good project idea. The listings of previous years projects have hopefully helped clarify the right sort of scope and content.</p> <p>Earlier Contact - Krysia Ellery kellery@broadcom.com</p>"},{"location":"Building_the_Matrix.html","title":"Building the Matrix","text":"<p>Successful virtual reality systems have to get just the right balance between system performance and human response. The time coordination issues in distributed multi-player VR are even more challenging. This project is a chance to test your skills in all of these. We have two Oculus Rift headsets, and your goal is to use these to demonstrate a time-critical distributed VR game. The scenario is cricket - one player runs up and bowls, the other bats. Both have to get the timing exactly right (you can use keyboard/mouse input or a USB game controller if you prefer). The VR rendering can be in a style of your choice - either realistic players and wicket, sci-fi/alien cricket, or even cyberspace cricket in the style of William Gibson's original Matrix, where batting and bowling are just metaphors to control financial, business or political transactions.</p>"},{"location":"Bus_Buzzer.html","title":"Bus Buzzer","text":"<p>Bohemia Interactive Simulations</p> <p>We have near-realtime data on location of every bus in Cambridge. This could be used to give guidance for cyclists to take alternative routes when there are large numbers of buses ahead. Wrist vibration makes sense as an output mode for cyclists, because they have no dashboard, and would not routinely be looking down at handlebars. It's also hard to hear alerts from a mobile phone while cycling, and dangerous to look at a phone without stopping.</p>"},{"location":"Buying_Pattern_Prediction.html","title":"Buying Pattern Prediction","text":"<p>Online retailers face the interesting challenge of trying to understand a potentially large and unknown customer base. Once a customer has bought a product from a site, we'd like to know what they'll likely buy next and importantly, WHEN. This project is to build a Machine Learning system that can use the historic behaviour of hundreds of thousands of customers (anonymised) to predict how new customers to the site will behave.</p> <p>The dataset will be taken from a collection of popular and diverse websites that belong to The Hut Group. Proposed sites include MyProtein, LookFantastic and IWantOneOfThose.</p>"},{"location":"Buying_Pattern_Prediction.html#feedback","title":"feedback","text":"<p>We do get quite a lot of suggestions for generic applications of machine learning to business (including two or three stock market prediction systems in a typical year). I don't have any objection to using machine learning techniques as a core of the project, but in their second year, students won't have the skills to develop a very sophisticated approach - they may do something like simply applying a standard regression toolkit. This doesn't really provide a great deal of challenge.</p> <p>The students work in teams of six, so while one or two of them are doing this, we'd need to expand the project idea with functionality that the others might be working on. How about this as an idea \u2026</p> <p>There are many online shopping sites where users become frustrated - they can't find what they want, get bored, or simply fail to complete a purchase because of a usability problem. Retailers would be happy to help out such customers, if only they which ones were most likely to benefit. If you could predict which shoppers are about to abandon their shopping basket based on click stream analysis, then it would be possible for an intelligent agent (ideally assisted by a live human operator whose contributions to the conversation are seamlessly interleaved with robot responses about routine matters) to offer the customer real-time hints and assistance via a pop-up window.</p>"},{"location":"CSR.html","title":"CSR","text":"<p>Location-based teaching</p> <p>iBeacons/Bluetooth4 beacons are now being deployed in public, retail, and office spaces and offer the opportunity for micro-location applications (i.e. you are near X so execute Y). The CL has a large deployment of beacons that can provide phones location throughout. Your task is to create a platform that receives beacon sighting information from Android/iPhone devices and exposes it as location information that other can build location-aware applications on. You will then use this platform to create an educational system. It should be possible for anyone to use this platform to create new types of face-to-face interactive content that are advertised as available at particular times and location. Existing content could be imported automatically from sites such as talks.cam.ac.uk, lecture and seminar timetables, supervision management systems and so on, but users should be able to create new location-based content relevant to other learning or event types.</p> <p>Earlier idea ...</p> <p>There are always interesting things happening in meeting rooms and lecture theatres around the Gates Building. These could be advertised to interested students and visitors using Bluetooth Low Energy beacons. Your task is to make an Android app that uses the location beacons already deployed in the Gates Building, matching different rooms to events that are advertised on talks.cam.ac.uk, and in the lecture timetables for the Computer Science Tripos and MPhil in Advanced Computer Science. You\u2019ll need to extract and convert information from these different sources. It would also be useful to collect information on who attends those events, allowing audience members to vote for value or popularity.</p> <p>or ...</p> <p>Location-based teaching</p> <p>Many Universities are starting to experiment with massively online courses (MOOCs) to replace traditional lectures. However, it\u2019s also useful to meet content experts face to face for interactive delivery. Your task is to create an educational platform based on the Bluetooth location beacons that are already distributed in the Gates Building. It should be possible for anyone to use this platform to create new types of face-to-face interactive content that are advertised as available at particular times and location. Existing content could be imported automatically from sites such as talks.cam.ac.uk, lecture and seminar timetables, supervision management systems and so on, but users should be able to create new location-based content relevant to other learning or event types.</p> <p>--</p>"},{"location":"CUDA_Support_for_ClangIR.html","title":"CUDA Support for ClangIR","text":"<p>The Clang C++ compiler is currently getting support for a new SSA-based high-level IR representation, offering extra frontend knowledge to the compiler for better analysis and optimizations. This new ClangIR is implemented on top of MLIR and is currently in heavy development. It is mainly focused on CPU support (ARM64, x86_64) but still lacks GPU code generation support. Recently, OpenCL was added to the set of C/C++ compiler extensions supported by ClangIR, but many extensions (HLSL, CUDA, etc.) are still missing. In this project, you will add CUDA support to ClangIR, enabling GPU support for highly thought-after application workloads such as AI and computational science.</p>"},{"location":"Calendar_Dialogue.html","title":"Calendar Dialogue","text":"<p>Potential contacts at Amazon - kevcrews@amazon.com, gojav@amazon.co.uk</p> <p>The Alexa Skills Kit allows developers to create new functionality for the Amazon Echo. You will use this to implement a natural language meeting-time negotiator. Multiple simultaneous users each speak to their own Echo, which constructs an independent calendar representation of constraints, conflicts and priorities while ignoring time-wasting details so that the users can have a focused productive negotiation rather than rambling natural language discussion.</p>"},{"location":"CambridgeSpark.html","title":"CambridgeSpark","text":"<p>2020 project: Automatic Assessment of R Code</p> <p>Draft:</p> <p>Cambridge Spark is a startup that develops \u200bEDUKATE.AI\u200b, a platform on which students can access a collection of projects and receive immediate automated feedback on their code -- KATE, the engine behind the platform, evaluates functionality and code quality and generates feedback to help students complete increasingly difficult projects, improve their code and learn new skills. We currently support Python (both standard Python and Data Science / Machine Learning applications) and Java. The aim of this project is to develop a new service that we can integrate into the platform in order to support projects in R.</p> <p>Goal:\u200b The service needs to integrate with our system (see below for technical constraints) so that feedback can be generated and help students progress, learn and complete projects. Technical constraints...\u200b We have developed an infrastructure such that evaluation of code is done as follows:</p> <p>1. Students write code either using our webIDE or using git on their own machine</p> <p>2. When they submit code, a docker container starts. This image is pre-built with a set of tests for the specific project they are working on as well as a library that takes the code and the tests and extracts data from them. Data includes a set of errors and failures generated from the tests, relevant diagnosis about what was tested and why it failed, information about code quality, etc...</p> <p>3. The data is then sent to another service that will process it and render on the frontend of the application.</p> <p>For this project, we will need to develop: \u25cf An R library that takes: source code written by students, tests written by a person developing R exercises, runs it together with code quality tools and generate data in a specific format (the format is well defined and will be shared upon starting the project) \u25cf Design a new format in which tests need to be developed by the person developing a new exercise in order to be processed by the service. This includes not only testing but information about each test, such as what does it check for, what should be shown to students in case of failure, etc... All this information will need to be captured automatically by the library. If time allows, we can build an SDK that will be shared with exercise developers allowing them to write new exercises and tests faster and add them to the platform. \u25cf Docker configurations and script in order to build the standalone docker image that has all dependencies required, tests preloaded as well as the the service running with an entrypoint to generate feedback. \u25cf A sample exercise to demonstrate the service. This can be integrated to the platform to test integration. If time allows, the exercise can also be shared with users to run a user testing session.</p>"},{"location":"Cambridge_Architectural_Research.html","title":"Cambridge Architectural Research","text":"<p>StreetPay</p> <p>Complementary to StreetView - but the big question for sustainability is where the roads are going to come from, not just finding out where they go.</p> <p>A platform for public consultation around transport policy, which allows people to compare their own journeys to costs of provision and taxation revenue, and engage in debate regarding different policy regimes.</p> <p>Transport Game</p> <p>It's hard for voters and taxpayers to assess what impact different funding policies will really have on their lives. The goal of this project is to create an online game that will enable users to explore issues of transport funding and, in particular, to measure their personal costs and benefits from road pricing. An underlying model will simulate the key features of the Cambridge transport network, with users plotting a number of their typical journeys to create a baseline. They will then be given the opportunity to \u201cpurchase\u201d benefits in the form of a range of transport infrastructure and service improvements, for example road quality and public transport. According to the choice of benefits made, the user will incur a variable mileage-based road user charge, whose proceeds are available for spending on transport. Making changes in travel behaviour - for example making a journey by bus or bicycle rather than by car - will allow the user to reduce or avoid the charge. The model will also allow users to opt for a reduced rate of charge and/or a compensating reduction in fuel duty, with a personalised benefit-cost ratio compared to other players.</p>"},{"location":"Cambridge_City_Council.html","title":"Cambridge City Council","text":"<p>ijl20@cam.ac.uk</p> <p>Suggestion:</p> <p>\"The Busking Bus-Stop\"</p> <p>Cambridge buses are fitted with GPS tracking equipment. This is used to predict the arrival time for the next bus, as displayed on many bus-stops around the city. It is also collected in an archive of all bus journeys. It would be nice if the display provided more information, and did so in a more entertaining way, customised depending on how long the bus will take to arrive. Information snippets might include confidence intervals (in layman's terms) for actual arrival time based on historic data, and comparisons to other journey options. Entertainment might be automatically generated poems, fictional dialogues etc, that adapt intelligently to local context such as weather information. news stories and so on - but at a length appropriate to the remaining time. With luck, we hope to deploy the resulting system - at least on the stop outside the Gates building!</p>"},{"location":"Cambridge_Conservation_Initiative.html","title":"Cambridge Conservation Initiative","text":"<p>2021 project:</p> <p>Galapagoan Machine Learning, working with Sophia Cooke sophiacooke18@gmail.com</p> <p>Earlier:</p> <p>Previously looking for ideas around Conservation citizen science</p> <p>Discuss with:</p> <p>John Fanshawe John.Fanshawe@birdlife.org</p> <p>tim.wilkinson@unep-wcmc.org</p> <p>Chris Sandbrook cgsandbrook@gmail.com</p>"},{"location":"Cambridge_Consultants.html","title":"Cambridge Consultants","text":"<p>Machine learning group leader Trevor Wood trevor.wood@cambridgeconsultants.com has apparently left.</p> <p>Previously last contact was in 2013: Davina Jaczyk davina.jaczyk@cambridgeconsultants.com</p> <ul> <li>Chris Roberts - Recipe Curator</li> <li>Rodrigo Queiro \u2013 Dance Practice   Assistant</li> <li>Andrew Knights \u2013 Digital Sheet Music   Viewer</li> <li>Alistair Morfey \u2013 Low energy ECC (Elliptic Curve Cryptography)   library</li> <li>Alistair Morfey \u2013 Application for the new 32-bit XAP6   Processor</li> </ul>"},{"location":"Cambridge_Enterprise.html","title":"Cambridge Enterprise","text":"<p>We discussed the following project for 2021, but Mark has agreed to roll it over to 2022. This might involve processing data from CE company accounts, in which case we can consider asking students to sign the confidentiality undertaking.</p> <p>The Automatic Accountant</p>"},{"location":"Cambridge_Humanitarian_Centre.html","title":"Cambridge Humanitarian Centre","text":"<p>Suggestions from Jennifer Wright jennifer.wright@humanitariancentre.org. but she will be leaving at end July. Use info@humanitariancentre.org for followup</p> <p>1.) Aptivate - http://www.aptivate.org. We met with them recently and they're doing lots of really interesting work, which means they're quite stretched at the moment, but may have capacity nearer the time of the project. - Tom Lord - toml@aptivate.org - is our key contact.</p> <p>2.) Engineers Without Borders - there is a Cambs University Student Society (http://ewb-cam.org) branch which is supported by the UK branch of the main EWB organisation. The UK branch would be interesting to collaborate with. - Chloe Underdown (Innovation Engagement Coordinator), chloe.underdown@ewb-uk.org</p> <p>3.) We are also currently working with Harsha Liyanage, from Sarvodaya Fusion (http://fusion.lk). I know we are currently asking quite a lot from them in terms of collaboration, and Sonia suggested they may have more capacity to get involved in planning such a project in the autumn as opposed to at the moment, but I pass on their details just in case. - enovation4d@gmail.com</p> <p>In terms of other NGOs we don't directly have links to but which may be interested in being involved in such a project:</p> <p>1.) Practical Action (http://practicalaction.org/technology-justice) - do some really interesting work on 'technology justice'.</p> <p>2.) Plan - especially with their 'Because I am a girl' campaign which seeks to promote gender equality. In 2011 they conducted a 'fast-talk' consultation with adolescent girls from several countries to get a better idea of what they see as the innovative and empowering potential of ICTs in their lives, and then produced a report analysing the results. Key contacts included on the first page of the report (attached to this email.)</p> <p>3.) UNICEF Innovation (http://unicefinnovation.org/about-us) - it says (here: http://unicefinnovation.org/get-involved) \"We engage in partnerships with academia, private and public industry, and with the design and manufacturing world, with the aim of finding innovative solutions to the challenges faced by children and their families in resource-limited settings. We welcome your input, whether it is leaving a comment in response to a challenge, or getting involved in one of our projects. If you have a solution to a challenge you think we should know about please let us know.\"</p> <p>4.) The Commonwealth Telecommunications Organisation - (http://www.cto.int). Its Strategic Plan for 2012-2015 identifies 6 priority areas on which it is focusing its contribution to the use of ICT4D across the Commonwealth. Tim Unwin, former CEO, wrote an introduction to our 2011 ICT4D report.</p>"},{"location":"Cambridge_Legal_Risk_Analytics.html","title":"Cambridge Legal Risk Analytics","text":"<p>Original contact: Siobhan Sweeney siobhan@clara.ai</p> <p>Technical: Yuki Cheung chyuki@gmail.com</p> <p>Class-y Action</p>"},{"location":"Cambridge_Mathematics.html","title":"Cambridge Mathematics","text":"<p>Potential client: Darren Macey Darren.Macey@Cambridgemaths.org</p> <p>Possible project title: Cascading Galton Boards</p> <p>Children struggle to learn basic ideas of probability distributions and sampling, despite the fact that we see these all around us in very intuitive forms. The Galton Board (see galtonboard.com) is a mechanical simulation that makes the relationship between normal and binomial distributions very clear. But physical Galton Boards are hard to make. Your task is to make a customisable animated simulation - but not just of a single distribution. Users should be able to chain multiple boards together, associating them with descriptive equations, to help teach conditional probability and an intuitive derivation of Bayes theorem.</p>"},{"location":"Cambridge_Museums.html","title":"Cambridge Museums","text":"<p>For 2019, see Fitzwilliam Museum</p> <p>Previous client: Ina Pruegel ip331@cam.ac.uk (now left Cambridge)</p> <p>Suggestion for 2018:</p> <p>Anthropometrics Today</p> <p>In the 1880s every scientist in Cambridge had their head measured to test for correlations between head size and degree class. To celebrate the 200th anniversary of the Cambridge Philosophical Society, a major public exhibition will reconstruct this experience. You will use computer vision to measure visitors' profiles, matching against archive records of thousands of ex-students to identify a (possibly famous) historical twin, and then render a simulation of a new \"handwritten\" record card that can be accessed online to compare your future grades to theirs.</p> <p>https://anthropometryincontext.com/2017/05/01/about-the-archive/</p> <p>Suggestion for 2017:</p> <p>History Phone</p> <p>There are historic objects around the Gates building that have stories to tell - if only they could speak! Imagine walking up to one of the display cases, and using your phone to start a chatbot session as if you were speaking to the object itself. We will provide Bluetooth location beacons so that an Android phone can detect which object it is near. Your application should respond to questions, and maintain a conversation, with style and content that is customised to each object.</p> <p>Ina says:</p> <p>yes, that could work well. We are running a project at the moment which is called 'Why is this here?' which basically looks at weird objects in the collections and tells their stories, so we would have content and information about those objects for the bot.</p> <p>I will find a museum as a testing ground as it would be really good to do something at one of our sites. I will confirm which one it will be, it's there anything else you would need at this point?</p> <p>My response:</p> <p>I suggested using display cases in our building because it is relatively easy to deploy location beacons here, and also because the team could perhaps demonstrate their application live to the demonstration day audience. If we wanted to get the team to take a look at a museum site, that could well be interesting for them, but we'd need to think about how to do the demonstration here.</p>"},{"location":"Cambridge_Overlay.html","title":"Cambridge Overlay","text":"<p>The Cambridge University Map supports a sophisticated annotation API, based on GeoJSON. The resulting map functionality can be neatly embedded in a page using an iframe.</p> <p>Create a mashup that uses the Talks.cam API with some natural language processing to create an itinerary for a visitor with cross-disciplinary interests, for example to all the research groups that host seminars on neuroscience, or infectious diseases. If the academic visitor is feeling a little lazy, the talks might be a little less clearly related, but within a shorter walking distance. The final result should include a programme of events, with an embedded interactive map showing how to get to them.</p> <p>Resources:</p> <p>http://wiki.cam.ac.uk/university-map/Map_Annotation</p> <p>http://talks.cam.ac.uk/</p>"},{"location":"Cambridge_Science_Centre.html","title":"Cambridge Science Centre","text":"<p>Project proceeding this year will be: Science exhibit interaction adviser</p> <p>Suggestions under development:</p> <p>1. Developing the interactive science centre as a learning and research environment</p> <p>In this project you'll be developing an interactive science centre exhibit which allows the user to explore the process of emotional recognition whilst at the same time collecting valuable data for psychometrics researchers. The exhibit will let the visitor test their ability to recognise emotions in photographs of human faces. It will also allow them to upload pictures of their own face. While they are performing that upload into a shared data-base and tagging their own emotion, their concentration will be monitored to assess the validity of the emotional state which they log into the system. To design and build this exhibit you will be working with the University of Cambridge Psychometrics Department, the Oliver Zangwill Centre and the Cambridge Science Centre. The open-source adaptive testing CONCERTO platform will be integrated onto a Raspberry Pi powered science centre exhibit. The Cambridge Science Centre would like to display this exhibit as part of an exhibition on Perception in the second half of 2013. The research data gathered may be used to help test brain injured patients in the recognition of emotions.</p> <p>2. Using games to teach the theory of evolution</p> <p>In this project you will help to broaden the public understanding of the process of evolution by developing a computer game that is based on the real observations of the Peppered Moth. The game will be able to be used in a public interactive science centre exhibit, most likely powered by Raspberry Pi, as well as be played on-line. In the game, players take on the role of a predator and need to \"eat\" a moth by touching them on a screen. Based on genetic algorithms, the moth wing patterns change over time and the moths become harder to spot against the background. User behaviours will be monitored to test the attractiveness and efficacy of using computer games to teach scientific concepts. The game would be developed with input from the University of Cambridge Zoology Department and the Cambridge Science Centre. We would like to display the exhibit in the Cambridge Science Centre and on-line as part of a Perception exhibition in the second half of 2013</p> <p>3. Using sensing and monitoring to improve hands-on science learning experiences</p> <p>Traditional exhibits in interactive science centres are great for introducing concepts but they often suffer from user disengagement too early. To learn, a user really needs to apply a concept to reason out a problem before they gain confidence in that new way of thinking. In contrast to an un-manned exhibit, a professional science explainer will often keep their audience engaged by offering challenges and additional information based on certain behaviours of the participant. In this project we will placing some sensors in a fairly traditional hands-on science exhibit such as [TBD]. These will be connected to a Raspberry Pi powered data gathering and analysis engine which will adapt the user guidance based on activity monitoring of the hands-on activity. We will track the effectiveness of learning outcomes both with an adaptive and non-adaptive interface. The outcome of this work will help to guide future development of exhibits for the Cambridge Science Centre, potentially making higher quality learning experiences accessible to a wider audience in a cost-effective manner.</p> <p>Category:Raspberry Pi</p>"},{"location":"Cambridge_University_Herbarium.html","title":"Cambridge University Herbarium","text":"<p>http://data.plantsci.cam.ac.uk/herbarium/</p>"},{"location":"Cambridge_University_Press.html","title":"Cambridge University Press","text":"<p>First draft:</p> <p>Science for AD2500</p> <p>Everyone knows that peer-reviewed publication is the gold standard for scientific facts. But it is too slow for the Millennial generation, who prefer fresh opinions and data \"verified\" by Facebook likes, GitHub pull requests, up-votes, blog comments or TED talks. We need a new model for science that is agile and open, but also solid enough to last another 500 years. Your task is to prototype the next Royal Society or Cambridge University Press, providing democratic public access for Millenials, rapid quality control that would satisfy the next Isaac Newton, and PDF for permanent paper archives to survive the Apocalypse of 2499. Elegance and attention to detail are critical on both paper and screen - if it looks like Buzzfeed, nobody will believe it was the Transactions of the Royal Society. Don't forget the essential academic attributes of accurate and secure certificates for time, authorship, and reference to prior work.</p>"},{"location":"Campy_Bird.html","title":"Campy Bird","text":"<p>Gerard.Hester@morganstanley.com</p> <p>Flappy bird is possibly the least intelligent video game ever made. But similar game mechanics could perhaps be used to automatically acquire more useful habits, for example if a whole class full of kids learns to take correct actions together, as part of a class activity. Your task is to design a whole-class education app, in which the players can only finish if everyone learns together how to avoid infection from campylobacter - a bacterium commonly found in the food chain that causes 22,000 hospitalisations and 110 deaths in the UK each year. The whole class has to guide a new-born chicken as it travels from farm to fork, taking rapid decisions based on what they have learned. One wrong step by any pupil, and campy bird will educate the whole class further. Think hard about motivation, or else the result may not be as entertaining as we hope!</p> <p>Originally suggested by Andrew Grant, Vet School,</p>"},{"location":"Cantab_Capital.html","title":"Cantab Capital","text":"<p>Financial Battlefield</p> <p>Attempts to make financial graphs or political trends more entertaining are often disappointingly unimaginative. We have seen too many VR mountain ranges and city skylines. Your task is to communicate the excitement of financial trading data by using the latest gaming technology. We'll provide powerful GPUs for you to use with the Unreal game engine and a budget for off the shelf game art and graphics assets. You will render large scale investment data based on thousands of data streams as competing armies of simulated characters whose bodies, weapons and AI behaviour are determined by key market attributes.</p>"},{"location":"Capita.html","title":"Capita","text":"<p>\"Law, Steven (ESS)\" Steven.Law@capita.co.uk</p>"},{"location":"Carbon_Accounting.html","title":"Carbon Accounting","text":"<p>matthew.postgate@infometa.com</p> <p>Today\u2019s personal bank accounts and banking apps all work by counting money, a simple technology that was created centuries ago as a social consensus to support trade. In the future, we are going to need a carbon economy that realistically prices everything in relation to the actual costs for the planet. Your task is to create a prototype of a new banking system, including personal savings and payment apps, where every transaction is based on the verified carbon cost of products and services. Consensus on carbon costs should allow for initial estimated quotes the first time a particular transaction is made, with better calibrated scientific evidence funded by arbitrage to increase eventual accuracy for integrity of the whole system.</p>"},{"location":"Care_Phone.html","title":"Care Phone","text":"<p>Many older people find the full functionality of a system like Android, with its multiple apps, too confusing or difficult to use. Your task is to design a customisable replacement that can be configured remotely by a trusted person such as a child or sibling, and displays only a very small range of options to the user (e.g. \u201ccall Stephen\u201d, \u201cListen to Radio 4\u201d, \u201cWatch Last episode Eastenders\u201d). There will be difficult design decisions as you trade off generality with security.</p>"},{"location":"Care_Quality_Commission.html","title":"Care Quality Commission","text":"<ul> <li>\"Smith, Jessica\" Jessica.Smith@cqc.org.uk</li> <li>\"Williamson, Paul\" Paul.Williamson@cqc.org.uk</li> </ul> <p>I spoke to Paul yesterday. We are both interested in principle however we are currently in the process of procuring a tool that will, in brief, automate aspects of CQC's qualitative analysis. I imagine Paul / Katherine previously mentioned this to you hence your suggested project below.</p> <p>It might be interesting to have the students explore a 'spin-off' project from this (it's unlikely that whatever tool we procure will be a panacea!), but given we don't have the tool yet it might not be the right time for us to explore these options. Perhaps, if it's an annual student project, it's something we could consider next year? By that point, we would hope to have the tool up and running and we might have identified further business needs.</p> <p>So, it is probably a 'no' for now but I'd be keen to discuss the longer term opportunities when we meet on 2nd Nov.</p> <p>Finally, thank you for considering us as a potential client. I have had positive experiences of student projects in previous roles, so it's something I'm always keen to consider.</p>"},{"location":"Careers_from_Here.html","title":"Careers from Here","text":"<p>emy.d.calder@jpmchase.com</p> <p>Future First is a charity closing the career gap for those born in low-income homes, by helping state secondary schools and colleges develop a thriving and engaged alumni community. Their latest idea is to develop tools that can be used by schools to create and maintain a library of videos in which school alumni describe their school experience and subsequent career. The recording app should structure the video recording with interview questions, and constrain recording times relevant to each question with appropriate messages and visual timer countdown, in a way that is encouraging and user friendly. The system should allow current students to find alumni with similar interests and experience to their own. It should also allow school administrators to manage the library of interviews, customize the interview questions for their school, and have a workflow for checking and approving new videos for release.</p>"},{"location":"Cascading_Galton_Boards.html","title":"Cascading Galton Boards","text":"<p>luke.b.baxter@boeing.com</p> <p>Many people struggle to learn basic ideas of probability distributions and sampling, despite the fact that we see these around us all the time. The Galton Board (see galtonboard.com) is an elegant and intuitive mechanical simulation that makes the origin of Gaussian distributions very clear. Unfortunately physical Galton Boards are costly to build. Your task is to make a customisable animated simulation - but not just of a single distribution. Users should be able to chain multiple boards together, associating them with descriptive equations, creating a visual probabilistic programming language that implements composition of Gaussian kernels as a zoomable giant pinball machine that can help teach conditional probability and an intuitive derivation of Bayes theorem.</p>"},{"location":"Centre_for_Gender_Studies.html","title":"Centre for Gender Studies","text":"<p>The Gender and Technology Project is a joint venture between the Cambridge Centre for Gender Studies and the Leverhulme Centre for the Future of Intelligence.</p> <p>2022 project: Personal Ambiguator</p>"},{"location":"Centre_for_Global_Equality.html","title":"Centre for Global Equality","text":"<p>Membership organisation - suggestions would come from individual members</p> <p>SimPrints</p> <p>Possibly Sensors CDT / Cambike</p> <p>Possibly Waterscope</p> <p>Contacts: Sophie Mower sophie.mower@centreforglobalequality.org, Lara Allen lara.allen@centreforglobalequality.org</p>"},{"location":"Centre_for_Policy_Futures.html","title":"Centre for Policy Futures","text":"<p>Lee Wilson is affiliated with the Centre for Policy Futures at the University of Queensland, and uses this as the base for work with WHO</p> <p>2022 project proposal:</p> <p>Empathetic Chatbot</p>"},{"location":"Change_the_world%2C_one_interface_at_a_time.html","title":"Change the world, one interface at a time","text":"<p>Conor Farrington, Department of Public Health cjtf2@medschl.cam.ac.uk</p> <p>Better project title may be The Adaptive Web</p> <p>Newly drafted:</p> <p>Most websites are designed on the basis that \u201cone size fits all\u201d - for any kind of user or context of use. Your task is to create a tool that allows users to author their own policies for customised appearance and behaviour, for example dark-mode viewing, text subsets, or controls suited to elderly users or those with disabilities. It should also be possible to apply data from one user-selected site (e.g. a weather forecast) to customise the appearance of another. The configuration process should be easily accessible to a wide range of users - so rather than vendor-specific browser plug-ins, a more universal solution might be a configurable online translation service that substitutes alternative CSS and JavaScript through recipes that can be shared with others. Such a powerful tool would also require security provision to guard against misuse.</p> <p>Original suggestion:</p> <p>Every time Twitter changes its look or adds new functions there is an outcry amongst users who are dismayed by yet another top-down change. What if users had the power to transform their own digital environments and create personalised interfaces to suit their personality and priorities? Your goal is to design a suite of meta-design tools to give users the capacity to redesign the appearance and functionality of social media sites. The tools should exhibit high liveness and directness affordances, and should also allow users to create their own tools for further meta-design possibilities. Finally, the new meta-design interface should offer data mining capacities to allow for psychometric analysis of users\u2019 redesigning activities, and to enable future machine learning applications to assist users with smart redesign.</p> <p>Feedback:</p> <p>Thanks for this Conor. We could do something along these lines, for sure.</p> <p>Undergrads would probably struggle to get the intentions of meta-design, so I wouldn\u2019t emphasise this. But the basic idea is fine.</p> <p>Technically, this would have to be implemented either as a Chrome extension, or perhaps as a JavaScript preprocessor/translator.</p> <p>I doubt that Twitter itself could be modified (but could consult with some experts in my group). However, the same ideas could be applied to a more straightforward kind of website - anything that uses a static layout of interaction elements would be appropriate.</p> <p>Alan</p>"},{"location":"Chat-twin.html","title":"Chat twin","text":"<p>LLMs struggle to remember their history of interaction with you, and never update their training weights with real knowledge about your life. However recent research shows how it\u2019s possible to get them to act like an intelligent agent, by maintaining your own description of a simple game world (including other human or LLM players). A highly compact version of this world state is fed back with the prompt for each new round of play. You will use the same strategy to turn an LLM into a digital twin, that keeps the most important records of your life, and helps you to prioritise and complete tasks through natural conversation.</p>"},{"location":"CheckMate.html","title":"CheckMate","text":"<p>soldham@illumina.com</p> <p>Personal genome sequencing is now available to the masses! An individual human's genome sequence contains 3 billion bases. It can be represented as either a string of characters or as a graph showing where the sequence deviates from a standard, reference genome. Your task is to (1) write a tool to filter/compress such a file into a representation of the genetic status for a (provided) selection of serious diseases of an individual, such that it can be stored on a Raspberry Pi or smartphone, and (2) write a Raspberry Pi or smartphone app that can securely communicate with another to establish whether the two individuals represented share genetic status of any of the diseases considered.</p> <p>For bonus points: The genetic details of one individual should not be revealed to the other individual - beyond reporting that the two individuals do or do not share genetic status for one or more diseases.</p> <p>Appendix: Illumina stores variant calls resulting from the sequencing of a genome in a standard format (gVCF) file. Most healthy individuals are carriers of one or more mutations that, if present in two copies (i.e. inherited from both mother and father), would result in a serious disorder (eg 1 in 29 Caucasian Americans carries one mutation in the cystic fibrosis gene : http://www.cff.org/AboutCF/Testing/Genetics/GeneticCarrierTest/).</p>"},{"location":"Checkpoint_Alternatives.html","title":"Checkpoint Alternatives","text":"<p>In videogame worlds, checkpoints are a welcome way to avoid hours of button-mashing. But the usual convention in a game is that time simply rewinds to the checkpoint, like the eternal repeats in the movie Groundhog Day. What if a checkpoint worked like a functional programming continuation, where state could be directly manipulated before continuing? With the Verse functional programming language integrated into Epic Games infrastructure, this project will be an opportunity to invent new kinds of gameplay. You'll need to think about what parts of the state can be rendered in the game, and how the player can make the game modify itself at this meta-level.</p>"},{"location":"ChessPuzzy.html","title":"ChessPuzzy","text":"<p>This challenge is to create a tool that generates chess puzzles (e.g., checkmates in 2 or 3 moves) by analysing real game positions from publicly available datasets or coming up with \"fake\" positions - although legal positions in chess! Existing chess engines like Leela and Stockfish provide an evaluation score on any move, helping to identify when someone has missed a check mate, or didn't see the best move from a position. These outputs can then be used as a puzzle. Your objective is to use AI methods to generate puzzles, based on patterns learned from real games. The puzzles should be classified as belonging to recognised categories (e.g. pins/skewer puzzles, queen + knight combination puzzles, rook endgame puzzles, etc). You should also assign ratings or difficulty level to each puzzle.</p>"},{"location":"Cisco.html","title":"Cisco","text":"<p>The contact email for John Bain is jbain@cisco.com</p>"},{"location":"Cisco.html#finalised-brief","title":"Finalised brief","text":"<ul> <li>Measuring glass-to-glass video-conference   latency</li> </ul>"},{"location":"Cisco.html#old-discussions","title":"(old) discussions","text":""},{"location":"Cisco.html#introduction","title":"Introduction","text":"<p>In 2011, Cisco Systems offered an undergraduate group project to design and implementation an on-line testing system, involving the design and implementation of a new programming language.</p> <p>The six students that worked on the project produced a complete and effective system which is now being considered for live use by another company. Hoping to continue the success of last year, Cisco Systems \u2013 represented by John Bain and Edd Inglis \u2013 are happy to put forward the following idea for another project.</p>"},{"location":"Cisco.html#background","title":"Background","text":"<p>The Cisco site in Langley specialises in multipoint video-conferencing systems, designing hardware and associated software to allow many video endpoints to communicate in large-scale conferences. One key consideration in the design of such systems is to minimise the latency added to the video and audio, since this can have a marked effect on the naturalness of communication.</p> <p>Many software solutions exist for measuring various aspects of the system latency, but there is no substitute for end-to-end (often called glass-to-glass, referring to the lens of the camera and display screen) measurements of video and audio latency. This type of measurement has traditionally been subjectively measured by humans, and is hence prone to error and bias.</p>"},{"location":"Cisco.html#proposal","title":"Proposal","text":"<p>We would like a team to create a system for measuring end-to-end latency of video and audio in a point-to-point or multi-point video conferencing call. We envisage such a system will include a light emitter and matching light sensor, and a sound generator and receiver, though any equivalent ingenious solution would be equally applicable.</p> <p>The system would obviously need to be operable on systems closely located in a testing environment, but consideration should be given to testing between geographically separated devices. This is illustrated by the diagram below, where perhaps endpoint A is in London and endpoint B in San Jose.</p>"},{"location":"Cisco.html#equipment","title":"Equipment","text":"<p>We imagine this system could be developed in a number of different ways. Our anticipation is that a small, embedded device would provide the most appropriate starting point for this, but are happy to entertain other suggestions. Assuming an embedded platform is chosen, we are happy to supply the appropriate hardware - for example an Arduino clone or similar development board - or for students to use any other platform they may be familiar with from other parts of their course.</p> <p>It should be possible to do complete testing of such a system using PC-based video endpoints, but we can also supply \u2018real\u2019 endpoints and conferencing infrastructure for testing towards the latter stages of the project if desired. (We anticipate an embedded platform will need the following peripherals at a minimum: ADC/DAC x2, GPIO, Network (Ethernet). ]</p>"},{"location":"Cisco.html#notes-to-supervisors","title":"Notes to supervisors","text":"<p>We feel this project provides a number of different areas of investigation and interest. Some of these include:</p> <ul> <li>Real-time operation; by its nature, this is a time-critical problem. A   successful system could either be implemented at a logic level, by   using an off-the-shelf RTOS, or even with an RTOS developed by the   students</li> <li>Hardware and software; our engineers work with both day-to-day,   meaning the project is realistic as well as more widely scoped. The   system will solve a genuine issue, potentially offering more interest   than a toy problem.</li> <li>Network enabled; interacting with IP networks is challenging and   interesting, and will allow students to use network analysis tools to   examine existing or new protocols for communication between remote   devices.</li> <li>Time synchronisation; there is a need to synchronise remote devices.   This could involve the use of NTP or other measurements of the   round-trip time of the network, to allow accurate measurement of the   true glass-to-glass latency.</li> <li>Robustness; the system needs to be robust in the face of noisy and/or   corrupted audio and video, as well as lossy networks between remote   measuring devices. This offers the opportunity for students to   investigate methods of making the system robust to errors and external   network factors.</li> </ul>"},{"location":"Citizen_Science_for_Cancer.html","title":"Citizen Science for Cancer","text":"<p>mkallberg@illumina.com</p> <p>Many people enjoy helping with research by completing simple but satisfying classification and recognition tasks online. Examples include the classic Galaxy Zoo, and recent initiatives such as the BBC Your Paintings Tagger. This project aims to design a similar approach to recognise cancer mutations from gene sequencing data, comparing sequences that are different between cancer mutations and healthy cells from the same person. It is relatively easy for people to spot the difference between actual cancers and false positive mutations - your job is to design an engaging online game teaching people to do this task well, and an infrastructure for collecting and analysing the results from large numbers of volunteers, with appropriate account management, motivation scoring and other features that result in effective citizen science projects.</p>"},{"location":"Citizen_Speed_Safety.html","title":"Citizen Speed Safety","text":"<p>ian.j.hales@boeing.com</p> <p>Many small communities are endangered by drivers ignoring speed limits and driving at high speed through populated areas. Some \u201cspeed trap\u201d apps are available for mobile phones, but these are inaccurate. It would be possible to increase accuracy by using two phone cameras, one pointed along the road, and the other across it. Computer vision processing is needed to extract speed data from two time-stamped videos, and construct a calibrated 2D model of the road, vehicle speed, and licence plate number, which can be forwarded to local enforcement agencies together with verified witness testimony.</p>"},{"location":"Class-y_Action.html","title":"Class y Action","text":"<p>Analytics](Cambridge_Legal_Risk_Analytics \"wikilink\") chyuki@gmail.com</p> <p>Many companies cause harm and damage to customers in small ways, but it's not worth employing a lawyer unless a large number of customers aggregate their compensation claims. The ability to pursue this kind of class action was introduced to British law in 2015. There is a business opportunity in identifying which companies can be most profitably sued. Thousands of people will thank you for it, and the long term effect would be to improve products and services for everyone. You will need to use social media - Twitter, Facebook, Instagram, and anything else that comes to hand - to work out which companies are most likely to lose a class action suit in relation to their products or services. Your client can provide expertise in data mining of legal cases, in order to optimise training of your statistical models.</p>"},{"location":"Clean_Cycle.html","title":"Clean Cycle","text":"<p>The CamBike Sensor project has been creating augmented sensing capabilities for future bicycles, including GPS, LoRaWAN data communications and air quality sensors. Your task is to create infrastructure that captures and buffers data, transfers it when links become available, and uses that data to profile air quality over time and distance. The user view of this should be a route-planning application that optimises daily and seasonal alternative routes, guiding riders in dirty cities to minimise their pollution exposure either for daily commutes or more intensive courier or delivery work.</p>"},{"location":"ClimateInColour.html","title":"ClimateInColour","text":"<p>Discuss with Joycelyn Longdon jl2182@cam.ac.uk</p> <p>Likely design client: Ana</p>"},{"location":"Climate_Foresight.html","title":"Climate Foresight","text":"<p>Dynamic Causal Modeling is a Bayesian statistical technique for reverse engineering time series data. One of the ongoing challenges in applying such statistical models is how to visualise the multiverse of possible outcomes that the algorithm derives. Your goal is to create an evidence-based visualisation of possible climate futures that allows users to interrogate and compare projections from a complete simplified carbon-climate model within the Dynamic Causal Modeling framework.</p>"},{"location":"Clinical_Nursing_for_Children.html","title":"Clinical Nursing for Children","text":"<p>Health](Royal_College_of_Paediatrics_and_Child_Health \"wikilink\") michaelkmalley@gmail.com</p> <p>In wealthy countries, hospitals use complex clinical information systems to capture and analyse data such as heart rate, respiration, oxygen saturation, temperature etc. In countries like Myanmar, nurses working in child healthcare have no access to computers that could be used to monitor and chart the condition of multiple patients every 1-2 hours over the course of their treatment. Your goal is to design a mobile app that can be used to capture data, generate clinically relevant output and empower nurses to escalate patient care as appropriate. Challenges will include transferring data between shifts, protecting patient confidentiality, and potentially integrating with existing apps.</p>"},{"location":"Cluster_Mail.html","title":"Cluster Mail","text":"<p>Based on conversation with a potential client who has asked for their details to be removed from the wiki.</p> <p>Everybody has a different approach to categorising email, but nobody has time to do it properly. Your task is to create a new kind of email client that uses unsupervised machine learning techniques to infer topic clusters from content. The user interface should allow users to deal with various personalised clusters in different ways according to their mood and level of concentration at the time. Use the IMAP protocol to automatically file clustered messages on the server, or (if feeling brave) automatically reply to them. A useful side effect of this mail client will be that spam and phishing mail gets the priority it deserves.</p>"},{"location":"Code_Explain_AI_Assistant.html","title":"Code Explain AI Assistant","text":"<p>Large-scale software development projects are often developed by multiple contributors. In certain open-source projects, such as compilers, operating systems or many HPC workloads, developers are frequently located in different parts of the world and are affiliated with various institutions. As a result, these developers may have limited opportunities for direct interaction and must understand code written by others without being able to easily discuss or ask questions to the original authors. Your task is to utilize modern AI technology, particularly large language models (LLMs), to develop a Code Explain AI Assistant. This tool should be capable of providing explanations of specific portions of code, generating helpful code comments, and even answering more advanced queries to help developers navigate and understand the codebase. The tool's applicability can be demonstrated with popular open-source weather or climate codes, such as FV3 or CLOUDSC.</p> <p>Links: https://github.com/NOAA-EMC/fv3atm https://github.com/ecmwf-ifs/dwarf-p-cloudsc</p>"},{"location":"Collecting_Farm-sourced_Data_on_Pest_and_Disease_Pressure.html","title":"Collecting Farm sourced Data on Pest and Disease Pressure","text":"<p>Michael.Gifford@niab.com</p> <p>Farmers routinely provide data on crop disease and pests but not in real-time, as they are discovered in the field, due to problems of ease-of-use and concerns around how data will be used after being reported. Accurate, timely reporting could significantly reduce crop losses, use of crop protection chemicals, and produce better understanding of how crop diseases and pests develop and spread, geographically and temporally. Your challenge is to develop a mobile reporting app with an intuitive and rapid user interface, based on an understanding of the incentives and barriers farmers face in reporting issues.</p>"},{"location":"Collecting_farm-sourced_data_on_pest_and_disease_pressure%281%29.html","title":"Collecting farm sourced data on pest and disease pressure(1)","text":"<ol> <li>REDIRECT Collecting Farm-sourced Data on Pest and Disease     Pressure</li> </ol>"},{"location":"Collusion.html","title":"Collusion","text":"<p>Rachel Drury rachel@collusion.org.uk</p> <p>Simon Poulter simon@collusion.org.uk</p> <p>Possibly with involvement of:</p> <p>Daria Jelonek daria.jelonek@network.rca.ac.uk</p> <p>Perry-James Sugden perry-james.sugden@network.rca.ac.uk</p>"},{"location":"Competing_for_Autonomy.html","title":"Competing for Autonomy","text":"<p>Lucy.Mair@gresearch.co.uk</p> <p>As autonomous vehicles become more common, we are likely to see people tweaking algorithms to accelerate their journeys. Your task is to create a competitive 'market' in which users can submit algorithms to see which is the best. You'll need to define a simple scripting language and API suitable for creating the entries. Users should be able to enter their script into an interactive game then see its performance in a real-time car race against other user's scripts. The best entries should be stored and ranked in a leader board, with new players able to see existing code and tweak it for better performance. In future, this kind of algorithm market could be applied to other problem domains such as finance.</p>"},{"location":"Component_Quest.html","title":"Component Quest","text":"<p>The electronics industry faces chip shortages, rising costs, and increasing e-waste. This creates demand for secondhand components, but it can be difficult to identify and value them. Develop a smartphone app that uses AI to identify and value electronic components (usually still mounted on PCBs) using the phone camera. The app should handle a wide range of components, provide current market value, and link users to a marketplace to buy and sell them.</p>"},{"location":"Computer-assisted_hiring.html","title":"Computer assisted hiring","text":"<ol> <li>REDIRECT Employability Coach</li> </ol>"},{"location":"Computer_Lab.html","title":"Computer Lab","text":"<p>The Department of Computer Science &amp; Technology</p> <p>&lt;https://www.cl.cam.ac.uk&gt;</p>"},{"location":"Computing_Physical_Calculus.html","title":"Computing Physical Calculus","text":"<p>In the days when Cambridge innovators like Turing were still inventing the foundations of Computer Science, our department was known as the Mathematical Laboratory, offering a wide range of computation facilities implemented using mechanical devices. One impressive machine, the Differential Analyzer was able to solve calculus problems. The goal of this project is to create a digital working replica of the Differential Analyzer, which can be used both to illustrate the elegant operation of this device, and help students to gain an intuitive understanding of mathematical principles through the visualised behaviour.</p>"},{"location":"Computing_for_Bird_Colonies.html","title":"Computing for Bird Colonies","text":"<p>The RSPB have many hours of acoustic data recorded from bird colonies, which is becoming a valuable resource for conservation work such as monitoring changes in colony size, or the relative composition of different species. Your task will be to create a convenient set of tools for machine learning experiments using these data. You will be free to make your own suggestions, but tools for segmentation and classification will be important starting points. The tools should be packaged in a way that is convenient and easy for RSPB staff without computer science training.</p>"},{"location":"Conservation_Evidence_Group.html","title":"Conservation Evidence Group","text":"<p>Phil Martin pam79@cam.ac.uk</p> <p>Curating Conservation Evidence</p> <p>A core activity of the Cambridge Conservation Science Group is compiling evidence from research literature, to show which management approaches are most effective for biodiversity conservation. However, this evidence is published in many different academic fields. The Group need tools that can use natural language processing methods to constantly monitor publications across many different venues, extracting key attributes such as geography, habitat, threats or interventions and organising these for thematic browsing or targeted queries without being constrained by the peculiar formats or terminology of particular scientific disciplines.</p> <p>Original query:</p> <p>I'm part of the Conservation Evidence team in Zoology, where we work on summarising scientific evidence on the effectiveness of different types of management for biodiversity conservation.</p> <p>As part of this process we systematically trawl through the scientific literature to identify publications that are relevant to us, which can be extremely time-consuming. We're interested in seeing if someone could use a machine-learning approach to identify relevant studies based on their contents. We have a database that contains studies that we have already identified as relevant that could be used to train the algorithm. Ideally the tool that would be produced would also classify the topic of the studies. We estimate that a tool such as this could save us ~5-15% of the time taken to synthesise evidence.</p> <p>Does this sound like a good idea for a group project?</p> <p>Regards,</p> <p>-- Phil Martin</p> <p>Postdoctoral Research Associate</p> <p>Conservation Evidence</p> <p>Conservation Science Group \u2013 University of Cambridge</p> <p>http://www.conservationevidence.com/</p>"},{"location":"Conservation_Evidence_Synthesis.html","title":"Conservation Evidence Synthesis","text":"<p>Many published descriptions of conservation projects contain information about the actions that were taken, what they cost, and how effective the results were. However, it\u2019s impossible for one person to find and digest the corresponding pieces of evidence when the relevant publications can be so varied in format and length. Your task is to use natural language processing methods to assemble the most important quantitative and qualitative data, and generate short and approachable texts communicating the essentials of each publication.</p>"},{"location":"Conservation_citizen_science.html","title":"Conservation citizen science","text":"<p>Discuss with:</p> <p>John Fanshawe John.Fanshawe@birdlife.org</p> <p>tim.wilkinson@unep-wcmc.org</p> <p>Chris Sandbrook cgsandbrook@gmail.com</p>"},{"location":"Consignment_Tetris.html","title":"Consignment Tetris","text":"<p>fciriell@mathworks.com</p> <p>Short-run manufacturers can now supply arbitrary bulk parts for 3D printing and online delivery, but manually packing a wide range of 3D shapes is difficult for robots. Your task is to design a system that will take a random selection of 3D models (e.g. as might be printed from clara.io/library), and use twin robot arms to fit them together into delivery boxes. You will simulate the system's kinematic and dynamic performance using Simulink 3D animation &amp; Simscape Multibody in conjunction with a high-fidelity robotic arm model from MATLAB\u2019s Robotics System Toolbox.</p>"},{"location":"Continental_Health_Explorer.html","title":"Continental Health Explorer","text":"<ol> <li>REDIRECT AfroInsight</li> </ol>"},{"location":"Conversational_Patient_History.html","title":"Conversational Patient History","text":"<p>Conor.Peacock@alderhey.nhs.uk</p> <p>Waiting lists for Autism Spectrum Disorder (ASD) and Attention Deficit Hyperactivity Disorder (ADHD) assessments are growing, partly due to the extensive time specialists spend on developmental history taking-often hours per patient. This project aims to create a conversational AI tool that allows children and their parents to provide comprehensive patient history in a natural, dialogue-based manner. By engaging users in a conversational interface rather than requiring them to fill out lengthy forms, the system can extract necessary clinical information and automatically format it into a report. This innovation seeks to streamline the initial assessment process, saving specialists' time and potentially reducing waiting lists.</p>"},{"location":"Conversational_Patient_History_for_ASD_and_ADHD_Waiting_Lists.html","title":"Conversational Patient History for ASD and ADHD Waiting Lists","text":"<ol> <li>REDIRECT Conversational Patient     History</li> </ol>"},{"location":"Coordinators.html","title":"Coordinators","text":"<p>The group project coordinators use this page to document the annual management cycle for managing the course.</p> <p>All correspondence with the coordinators, including internal discussion, takes place via the service address.</p>"},{"location":"Coordinators.html#timetable","title":"Timetable","text":""},{"location":"Coordinators.html#summer","title":"Summer","text":"<p>The convenor of the Industry Supporters Club (in 2021, Ben Karniely) solicits ideas for projects from Club members</p> <p>Coordinators prompt Wednesday for industry contacts with potential projects</p> <p>Coordinators collect personal contacts, project ideas from press etc</p> <p>Confirm dates for timetable</p>"},{"location":"Coordinators.html#michaelmas-term","title":"Michaelmas term:","text":"<p>Finalise design briefs, and confirm the individual contact point to act as client for each project</p> <p>Confirm availability of resources (datasets, hardware, cloud compute budget, software licenses, technician support). Direct costs associated with project are generally covered by client. If client is a charity, may need sponsorship negotiation. Equipment may be loaned, or donated, as client prefers.</p> <p>Coordinators send briefing message to DoSes, with preview of workload and logistics, and to check whether some students need special support</p> <p>Update the briefing booklet with timetable dates and any policy changes</p> <p>Create Moodle page for preference voting</p> <p>Format and print list of design briefs.</p> <p>Briefing lecture, including pitch of design briefs</p> <p>Put PDF of the design brief list online immediately after lecture.</p> <p>Deadline for students to express project preferences via Moodle</p>"},{"location":"Coordinators.html#after-end-michaelmas-term","title":"After end Michaelmas term:","text":"<p>Run the allocation algorithm as soon as possible after preferences have been collected</p> <p>Notify clients of any cancelled projects, with invitation to attend demo day</p> <p>Book meeting times and rooms with all remaining clients</p> <p>Prepare handout with group allocation and meeting appointment</p> <p>Request archive copy of group filespaces, clear directories, define group CRSIDs for access</p>"},{"location":"Coordinators.html#lent-term","title":"Lent term","text":"<p>Kickoff on first day of term</p> <p>Deal with any immediate queries / complaints</p> <p>Respond throughout the term to requests for excuse from meetings, medical issues etc</p> <p>Respond to resource requests (redirect, usually with advice to be clearer about actual technical requirement)</p> <p>Respond to concerns about design brief (say to negotiate with client)</p> <p>Give how not to give a lecture presentation</p> <p>Review interim progress report, and follow up with DoS and student where there are any concerns.</p> <p>Confirm prize sponsors, and availability of representative for prizegiving ceremony</p> <p>Ask all teams to submit presentation materials</p> <p>Ask teams to specify any special presentation or demo requirements</p> <p>Negotiate with building services / computer officers / technician support for demo arrangements</p> <p>Print the exhibition programme</p> <p>Make up table allocation signs</p> <p>Design and produce voting mechanism (slips + counting template, or possibly an online system with authorisation tokens)</p> <p>Prepare prize envelopes</p> <p>Arrange catering and networking/rest room for clients</p> <p>Collate all presentations into a single PDF, top-and-tailed with intro and thankyou slides.</p>"},{"location":"Coordinators.html#on-the-demo-day","title":"On the demo day:","text":"<p>Confirm doors unlocked. Load PDF on lecture theatre PC. Connect second mouse to advance slides. Get stopwatch and 4-minute sign. At noon, start placing group name signs on demo tables. Warn students working in Intel lab that they will have to leave. Tidy up any crap. Deal with any emergencies / last-minute requests. Hang out a little with clients. Carry programmes to give to guests. Try to visit every group for appreciation of their work. At 4pm, shout for everyone to go downstairs. Meet with prize sponsors to confirm award procedure. Distribute voting slips (or other authorisation) to clients, guests, and members of research / teaching staff. Run the presentations in order. Collect voting slips and count. Manage prize award. Thank everyone. Run through the Intel lab to ensure not too much chaos for cleaners and following morning. Ensure any groups required to pack up equipment have done so. Go to dinner with supporters club members. Collect feedback and project ideas for next year. Collapse.</p>"},{"location":"Coordinators.html#after-end-lent-term","title":"After end Lent term:","text":"<p>Review all student reports, and source repositories as necessary, for allocation of ticks</p> <p>Notify DoS and student to request further information / mitigation where ticks may be withheld</p> <p>Meet to decide tick penalties in relation to expected contribution</p> <p>Notify other students that all other ticks have been awarded</p> <p>Notify examiners and students affected of recommended penalties</p>"},{"location":"Coordinators.html#easter","title":"Easter:","text":"<p>Review meeting of the coordinators with Dinah</p>"},{"location":"Copilot_for_Business.html","title":"Copilot for Business","text":"<p>jason.mash@cambridgekinetics.com</p> <p>We\u2019re all familiar with the code generation capabilities of ChatGPT and GitHub Copilot. That\u2019s fine for experienced programmers, but how could an AI coding tool support people who have never written a line of code? Your goal is to create a user friendly natural language interface that not only generates code for extracting and visualising data from an arbitrary business database, but helps non-programmer users to understand how that code works, recognising and correcting bugs or hallucinations in the generated code.</p>"},{"location":"Countryside_web_server.html","title":"Countryside web server","text":"<p>A ruggedized version of the Raspberry Pi can be used for outdoor applications, like monitoring wildlife activity via USB peripherals (e.g. GPS) analogue and digital inputs (e.g. monitoring the weight of nesting birds, or entries to a burrow). The kinds of hobbyist and researcher who do this need to specify data capture via a rubberised keyboard and LCD display, but also make that data available more widely via popular websites. Your task is to design a system that allows users to configure battery-powered data capture and website structure in the field via the embedded display, but then turn the same device into a fully-functional web server with data visualisations when it is brought inside and plugged back into a network port. If required, you will also be provided with a licence for the ENEA Polyhedra realtime embedded database.</p> <p>Category:Raspberry Pi</p>"},{"location":"Creative_Community.html","title":"Creative Community","text":"<p>mjohnson@frontier.co.uk</p> <p>Children today struggle with mental health challenges, and it seems from research that the social dynamics of platforms like Instagram do not help. There are alternative approaches to building community, for example the way that TikTok encourages users to build on each other\u2019s contributions with memes, challenges and reaction videos rather than just accumulate likes (see https://www.eugenewei.com/blog/2021/2/15/american-idle). Your task is to create a mobile app that develops community through creative quotation and remixing, with feedback mechanisms that emphasise quality rather than quantity. TikTok already exists, so this app will be focused on phone-based drawing, painting and image remixing, rather than video.</p>"},{"location":"Creative_Writing_Coach.html","title":"Creative Writing Coach","text":"<p>Will human authors be replaced by AI? Language models can convincingly generate human-sounding text and automate many writing tasks, even contributing to novels! Instead, could they be harnessed to make us all more creative? The goal of this project is to create an app in the style of Duolingo. This app will use bite-sized, gamified lessons to help students write more creatively, with poetic imagery, dramatic tension, and vivid characterisation. Experiments show that a standard LLM (with carefully designed prompts) can provide useful feedback. Your app needs to engage and motivate students to become more fluent and confident creative writers.</p>"},{"location":"Croptimisation.html","title":"Croptimisation","text":"<ol> <li>REDIRECT Ramping Up Sustainable     Crops</li> </ol>"},{"location":"Crossing_the_Bubbles.html","title":"Crossing the Bubbles","text":"<p>Software](Ab_Initio_Software \"wikilink\") arley@abinitio.com</p> <p>We are all learning a lot about the dynamics of virus transmission, but often in ways that leaves us having to trust experts who don\u2019t themselves understand why some social settings result in \u201csuper-spreading,\u201d others are benign \u201cbubbles\u201d, and how these very different situations interact when people in a city move between them. Your task is to create an intuitive environment that models and visualises the dynamics of infection and transmission both within and between diverse settings such as schools, private homes, and workplaces. The key challenge is presenting controls that allow people without mathematical training to experiment with causal parameters and understand the often non-linear consequences over time. The visualisations should be delivered via a web browser, intuitively readable by primary school children, but based on real evidence and mathematical models of transmission and infection dynamics.</p>"},{"location":"Cuckoo_Race.html","title":"Cuckoo Race","text":"<p>Chris Sandbrook cgsandbrook@gmail.com aims to make an introduction to someone from British Trust for Ornithology</p> <p>They want a bit more time to think, so may return to this in 2019</p> <p>The British Trust for Ornithology wants to improve public engagement with bird conservation. One very successful approach is to help those interested in wild birds to learn more about their daily activities, and to imagine the environments that the birds have to survive in. The goal of this project is to create a game that runs on a mobile phone platform, allowing players to compare their own movements to those of cuckoos, as tracked by BTO. You are free to design a game scenario in any genre that makes use of player location data and cuckoo tracking data.</p>"},{"location":"Culture_Glasses.html","title":"Culture Glasses","text":"<p>Networks](Metaswitch_Networks \"wikilink\") Lancelot.Robson@metaswitch.com</p> <p>Google Glass is an amazing product, but can make the wearer seem a little geeky. The goal of this project is to compensate for that, by using the Google Glass camera to identify a barcode on a non-geeky cultural product you are given in a social situation (say a book or vinyl LP), and then provide a private display with cues of clever things to say about it. This will probably come from online reviews, but your software will need to spot the barcode, find the reviews, and distil them into a few words that make the wearer seem as smart as possible.</p>"},{"location":"Curriculum_for_Life.html","title":"Curriculum for Life","text":"<p>2022 project: Youth-led Future</p>"},{"location":"Cycle_path_mapping_with_a_custom_hardware_platform.html","title":"Cycle path mapping with a custom hardware platform","text":"<p>The aim of this project is to produce a highly accurate map of the Cambridge cycle network including information about inclines, one way roads, restricted access. Since this will require more data than can be gathered using a simple GPS device or smartphone this project will have a custom hardware element based around the .NET Gadgeteer platform. The first part of the project will build a device to capture data such as GPS, accelerometer, compass, cadence, wheel rotation, heart rate etc, to produce a sample dataset representative of the Cambridge cycle network, as well as providing the cyclist with relevant data.</p> <p>The second part of the project will process and visualise the sample dataset. This will include removing erroneous data, fusing data streams and maps to improve accuracy and inferring cycle features from the data whilst keeping an emphasis on data accuracy. This information could be used to recommend cycle routes or diversions in real time, assist with finding a bike rack, or perhaps the addition of new cycle lanes. The resulting dataset should be open and accessible.</p> <p>Note that Gadgeteer development requires .NET tools, so the development language for this project will either be C# or VB.</p>"},{"location":"Cydar.html","title":"Cydar","text":"<p>The client is rob.hague@cydar.co.uk</p> <p>Surgery in the Cloud</p> <p>Original proposal:</p> <p>Visualizing Clouds</p> <p>At Cydar, we make extensive use of Amazon Web Services. In particular, we use their Virtual Private Cloud (VPC) features to set up many separate virtual networks, each containing a number of virtual machine running different software for different purposes. The connections both within and between these networks quickly become complicated. Moreover, as we\u2019re dealing with highly confidential patient data, we need to be sure we have a good understanding of how the network is configured and where the data is going at all times.</p> <p>The brief is to create a tool for visualizing VPCs in some kind of automated block diagram. It should show, at a minimum: - Connections between machines within a VPC - Routes in and out of each VPC (as governed by AWS Security Groups)</p> <p>The visualization should update automatically as the network changes. Once the basics are in place, there\u2019s plenty of scope for additional information such as: - Real time network traffic display - Server health monitoring - Interaction, for example to focus on more details of a particular VPC</p> <p>Cydar will be able to provide technical help in integrating with AWS, as well as example networks to visualize.</p>"},{"location":"DAMTP_Image_Analysis_Group.html","title":"DAMTP Image Analysis Group","text":"<p>Talking to</p> <p>Kasia Targonska-Hadzibabic kt441@cam.ac.uk about work with Hamilton Kerr Institute</p> <p>Julian Gilbey jdg18@cam.ac.uk about image labelling / annotation tools building on work by Ariel</p> <p>Intelligent Tools for Coeliac Disease Diagnosis</p> <p>In principle, computer vision and machine learning methods can be used to recognise coeliac disease. Currently, images of biopsies of gut tissue are examined by pathologists to diagnose the presence or absence of coeliac disease. This project involves automating part or all of this process to allow for much faster and more accurate diagnosis, making use of machine learning methods with other tools (for example image editors).</p>"},{"location":"DX_Analytics.html","title":"DX Analytics","text":"<p>Original contact Vladimir Vilde vlmv2@cam.ac.uk</p> <p>Client: vladimir.vilde@dxan.co.uk</p> <p>Suggestion: Zoom into Books</p> <p>Art and travel books often have beautiful images, but it\u2019s frustrating that you can\u2019t pinch to zoom as you would with a phone, to see arbitrarily high resolution details. The purpose of this project is to identify those times when a picture in a book or magazine corresponds to an existing high resolution image that is available online. Your Android app should work in augmented reality style, starting with a view of the book through the phone camera, but then seamlessly zooming by substituting high-resolution online data.</p>"},{"location":"Dance_Practice_Assistant.html","title":"Dance Practice Assistant","text":"<p>Contact: Rodrigo Queiro rodrigo.queiro@cambridgeconsultants.com</p> <p>For learning swing dance routines such as the Shim Sham, dancers are often taught individual stages of the routine without music, starting from the teacher's count of \"5, 6, 5 6 7 8!\". This tends to lead to unnecessary confusion later, when trying to match up the moves they've learned to the music. Trying to practice to excerpts of the music is currently tough, requiring teachers to hunt back and forth for the right section.</p> <p>I propose a system which takes a track and analyses it, perhaps with the Echo Nest API, to identify the times of individual beats and split the track into musical bars and phrases. This greatly aids the teacher in splitting the track into distinct stages of the routine. Then, in the class, the teacher can very easily request playback of a given stage, allowing it to be practised individually to music. The application would also allow the teacher to control the playback speed of the music, to start of easy and build to full speed on later attempts - perhaps by voice or a linked mobile phone app for convenience. At home, the student can use the application to scrape a video off youtube and practise the steps in a similar fashion. For added work, a Kinect-based or similar system to track the dancer and work out what they were doing might be interesting.</p> <p>To follow up on what I said at the meeting, based on the success of things like Swingify: http://musicmachinery.com/2010/05/21/the-swinger/ http://haveyouheard.it/a-swinging-hack-swingify/</p> <p>It seems that individual beat detection works very well, at least for a subset of songs. The same API used for the underlying code: https://github.com/echonest/remix/blob/master/examples/swinger/swinger.py 95 sloc!!! would probably be useful.</p>"},{"location":"Dance_Practice_Assistant.html#feedback","title":"feedback","text":"<p>Beat matching from audio is still a reasonably hard problem, but will probably give acceptable results with relatively strict tempo dance music of the kind used in lessons. Echo Nest seems like a good starting point.</p> <p>Andrew Knights also suggested a project that would require audio tracking of music (his was more complex, potentially requiring polyphonic pitch tracking as well). From past experience, although we usually have a few musicians on the course, Computer Science seems to attract slightly fewer musicians than most Cambridge degrees, so we may not get enough interest to support two projects of this kind. Yours seems more technically achievable, and may also benefit from the Strictly Come Dancing audience (though this may not be large among computer scientists either).</p> <p>Tracking from Kinect seems a bit too challenging - it's not going to work if dancing with a partner, and if there is no partner, we might end up with just a version of Dance Dance Revolution.</p> <p>I liked the idea of voice prompts to the dancer - an earpiece could issue a sequence of instructions, for example a series of Ceroc moves - sufficiently ahead of the music to guide someone (like me) who relies on a teacher shouting what to do next.</p>"},{"location":"Daniel_Hall.html","title":"Daniel Hall","text":"<p>Daniel Hall, CamCyan Ltd danielahall@gmail.com</p> <p>General area of cloud computing for graphics rendering/printing services.</p>"},{"location":"David_Rubin%2C_Bloomberg.html","title":"David Rubin, Bloomberg","text":"<p>\"David Rubin (Lo) (BLOOMBERG/ LONDON)\" drubin19@bloomberg.net</p> <p>Finalised as Hashtag-FollowTheMarket</p> <ol> <li>FollowMyFund\u2013 Twitter-Based Visualisations and Alerts for Investors</li> </ol> <p>Twitter has famously been first to break many major news stories, so why is its data not often considered valuable by people in finance? Perhaps the data is not deemed reliable or presented in a familiar way? Surely, coupling improved analysis and filtering of Tweets with market data could provide a novel and useful tool for financial decision-makers. You will create a dashboard for Investors to monitor their portfolios, overlaying sentiment gathered from Twitter data. Is a particular company in a fund trending positively or perhaps not being tweeted about at all? To make the tool more sophisticated you will also create a system for configuring alerts about these companies based on the information you derive from Tweets as well as Market Data such as stock prices or volumes traded, helping spot the next market mover.</p>"},{"location":"David_Rubin%2C_Bloomberg.html#alternative-proposal","title":"Alternative proposal","text":"<p>Were you around when a group built the TweetGuv system? Perhaps we could do something similar with financial commentators who have Twitter feeds, looking for evidence that they are using the same (or different) sources?</p>"},{"location":"De-biasing_the_Employment_Process.html","title":"De biasing the Employment Process","text":"<p>Analytics](Umbrella_Analytics \"wikilink\") johnp@umbrellaanalytics.net</p> <p>The past year has seen a significant rise in awareness of misogyny, racism and other discrimination in society and, in particular, in workplaces. In addition, there is growing awareness of how \u2018algorithms\u2019 can reinforce bias rather than remove it. Your task is to produce a system that can help businesses recruit more fairly, by removing biased language from their job adverts that would put off many candidates. Your system should allow users to upload the text for a job ad, to identify problems using natural-language processing and statistics, and to recommend changes to the user so that they can make iterative improvements. Ideally, your system would give each text an overall score as well as word-level feedback.</p>"},{"location":"Degrees_x_NFTs.html","title":"Degrees x NFTs","text":"<ol> <li>REDIRECT NFTs for Digital CVs</li> </ol>"},{"location":"Deliberative_Social_Media.html","title":"Deliberative Social Media","text":"<p>Anna McKeon, Traverse Anna.Mckeon@Traverse.Ltd</p> <p>EngagementHQ is a software platform designed for public engagement and debate, which was used alongside Zoom for recent research during the #LockdownDebate project. But in recent times, governments are having to move faster and faster, while the large audiences on social media struggle to engage in relevant ways. Your goal is to create a media platform that is as engaging as TikTok, but also allows thoughtful deliberation when different generations and communities have to share their perspectives and make compromises on difficult questions, even while government policy might be changing on a daily basis.</p>"},{"location":"Delivery_Radar.html","title":"Delivery Radar","text":"<p>david@thefusionworks.com</p> <p>Are you ever curious just how fast delivery riders and hacked e-scooters travel down cycle paths? GPS-enabled apps like Strava can tell you how fast you are going yourself, but not how fast somebody else is. In principle, you could automate that. First record some precise reference points on a cycle path of your choice. If planning an official complaint, you might think how to secure that data for later confirmation. Then you'll need some video with accurate timestamps to verify the velocity as the rider's front wheel passes each point. Finally, what is the most effective way to use the aggregated data to campaign for better regulation, as an alternative to motorist campaigns against cycle lanes?</p>"},{"location":"Department_of_Zoology.html","title":"Department of Zoology","text":"<p>Phil Martin pam79@cam.ac.uk</p> <p>Postdoctoral Research Associate, Conservation Evidence</p> <p>Conservation Science Group \u2013 University of Cambridge</p> <p>http://www.conservationevidence.com/</p> <p>2021 project: Speeding Up Evidence Synthesis for Conservation</p>"},{"location":"Digital_Boost.html","title":"Digital Boost","text":"<p>Contact from Nicky Blake nicola.blake@coutu.org.uk</p> <p>On behalf of Sherry Coutu</p> <p>Proposed design brief:</p> <p>Boosting Skills after COVID-19</p> <p>Explanation of requirement:</p> <p>Digital Boost is an online learning platform to help people who work for small businesses &amp; charities to be mentored in \u2018all things digital\u2019, to enable them to come out of the COVID-19 crisis stronger.</p> <p>Many small businesses have been forced to shut their physical locations due to COVID-19 and many struggle to move online to build up new revenue streams. Digital Boost offers free interactive Boost Workshops and free 1:1 Boost mentoring Calls for the staff of small businesses &amp; charities on topics related to digitalisation to help them build up sustainable organisations through online channels. This will not only help bring businesses &amp; charities through this crisis, but will also ensure they are able to stay competitive in the long run in today\u2019s highly digital world.</p> <p>As a learning platform, each person should have a unique journey through the digital boost taxonomy depending on choices they make as they onboard and what their level of digital literacy is prior to reaching out to us. Your task would be to create an algorithm that guides each person on a unique journey sometimes recommending a mentor, sometimes recommending a workshop and sometimes recommending short stackable courses. Each user should progress through the entire taxonomy, which is comprised of 46 sub-categories divided into two tiers. There is no \u2018right place\u2019 to start, but they should not be \u2018guided\u2019 to do things that they have already done.</p> <p>At the moment, the \u2018nudges\u2019 take them through the first 3 subjects they indicated that they needed tuition in, however, after their first three, we would like to take them the rest of the way through the subjects in the curriculum so they complete the course.</p> <p>Currently, there is 1 taxonomy comprised of 46 parts (divided into 2 tiers), 12,000 courses from 6 different providers and you can assume infinite mentors skilled in the 46 skills in the taxonomy</p>"},{"location":"Digital_Currency_for_Public_Good.html","title":"Digital Currency for Public Good","text":"<p>The digital currency Bitcoin uses a block chain distributed database to guarantee that any transaction can be traced to a unique original coin. The same technique could be used for anonymous authentication of a chain of custody for other kinds of data. Your task in this project is to create a secure end-to-end system for authenticated reporting and verification of organised criminal activity, corporate safety violations, governmental human rights abuses etc. You need to think about how reports can get into the system safely, and how those receiving a report can use the block chain to prove that the evidence has not been tampered with, all without endangering the whistleblower.</p>"},{"location":"Digital_Sheet_Music_Viewer.html","title":"Digital Sheet Music Viewer","text":"<p>Consultants](Cambridge_Consultants \"wikilink\") andrew.knights@cambridgeconsultants.com</p> <p>A musical score is in effect a single line of n bars. Lines, pages, and to some extent repeat markers appear due to the score being printed on a page. Your task is to design software that allows a user to have complete freedom to arrange a musical score on their chosen display (be it a laptop, tablet, mobile-phone, or projector) in a format that best suits that display and their needs. Starting with a free digital format of the score, the software should allow users to manipulate on-screen scaling, rearrange the score layout using drag &amp; drop of bars, automatically advance in a way that doesn't interrupt play, and supports annotation by one or more users. Ideally, it should be possible to capture the score using OCR from a scan of a paper copy. And of course, when playing in a group, it would be preferable to synchronise all of these functions across the screens used by multiple players.</p>"},{"location":"Dignified_Distributed_Work.html","title":"Dignified Distributed Work","text":"<p>Na\u2019amal provides refugees and other underrepresented communities training in marketable skills, with a focus on the human/soft skills that are required in the global labour market and links them to dignified digital remote work. The final piece of Na\u2019amal\u2019s work is the link to employment. However, different partners all have different requirements for digital employment profiles, involving scarce skills and labour. Your task is to provide an automated integration platform that streamlines the connection of Na\u2019amal alumni to opportunities, amplifying their chances of securing meaningful and sustainable jobs.</p>"},{"location":"Directors_of_Studies.html","title":"Directors of Studies","text":"<p>The Director of Studies in Computer Science at each Cambridge college is recorded here: http://www.cl.cam.ac.uk/teaching/dos-list/</p>"},{"location":"Directors_of_Studies.html#advice-for-directors-of-studies","title":"Advice for Directors of Studies","text":"<p>We recommend that during Lent term, Directors of Studies regularly discuss with Part 1B students the contributions that each student is making to the work of their project teams. Occasionally, we find that a student has not made any contribution to the project, but has not informed either their DoS or the group project convenors of the problem that led to this. If we do not learn of this situation until after the end of the project, this places us in the unfortunate situation that the student may not have earned his or her individual ticks, but since the project has ended, there is no opportunity to rectify the situation and earn the ticks.</p> <p>Students are able to make a request that they be excused from some aspect of the project. We ask that this request be communicated to us in the form of a letter from the student's personal Tutor. These requests may result from illness, from family circumstances, from sporting commitments or other causes. If the policy at your College means that this standard approach is not appropriate, we may be able to accommodate local practices. Otherwise, we assume that the student will keep you informed, rather than relying on us to deliver individual status reports to college DoSes.</p> <p>If a student does experience a problem with the group project, we strongly encourage them to inform us at the earliest opportunity in order to make alternative plans. If students are experiencing problems, but do not inform us, there is little we can do. Please do encourage them to let us know of any problems via the group-project email address. This address is received by the group project convenors, and by the staff of the student administration office.</p> <p>We also invite DoSes to contact us in confidence, if they are aware of any reason why a student might struggle with the project (for example, related to disability or illness, or a track record of problems in group work). We send a reminder to DoSes each year, before the teams are allocated, so that we can take any issues into account. We are also happy to receive any information from DoSes at this time, or at any other stage during the project.</p> <p>Our published intention is that we expect all students to gain all four ticks for the group projects. The most common cause of failure is serious illness or bereavement, and in these cases the DoS is usually well aware that the student is having trouble. Less commonly, students who were otherwise doing well in the Tripos have unexpectedly failed to earn group project ticks. Some potential failure modes that DoSes should be alert to include:</p> <p>1. A student spends a lot of time proposing, researching or \"evaluating\" possible technical approaches, or else criticising the technical approaches taken by other members of the team, but does not implement any actual code themselves.</p> <p>2. A student does not communicate with the rest of the group, instead choosing to work by themselves, often with the result that they deliver code different from what was required (perhaps because they did not participate in discussions that would have alerted them to changing requirements).</p> <p>3. A student does contribute to the code base, but only in the form of documentation, for example adding comments, writing README files, importing open source content, or making commit log entries that focus on descriptions of bugs and their possible causes rather than source code.</p> <p>4. A student delivers an initial version of the code that was assigned to them, but leaves it to other members of the team to resolve faults, rather than taking responsibility for design iteration, debugging and maintenance of their own work.</p> <p>Note that working in groups does involve substantial coordination and managerial overhead. We are aware that some members of each team will accept a disproportionate burden in such work, especially if elected as the official group contact or project manager. We do not penalise students for such work (on the contrary, the responsibilities they take often lead to the most valuable professional development and learning outcomes). However, we do require every student to make a substantive technical contribution to the project. The main reason for this is to ensure that students who are lacking in technical confidence do not \"opt out\" of the computer science aspects of the course by volunteering to take responsibility for documentation or management. We are very clear in our course briefings that every student must make a technical contribution in order to earn their ticks.</p> <p>Ticks are assessed at the end of the course, after final presentation and submission of personal reports. If there is any sign that a student may not have made a contribution to justify award of the ticks, we will contact the DoS directly at that stage, in order to check whether the student has some personal problem that we were not previously aware of. If the student's personal report was incomplete, or possibly evasive in relation to their technical contributions, we may invite the student to provide a more detailed report of their personal contribution and interaction with the group. A DoS might usefully advise the student with regard to the preparation of this more detailed report.</p>"},{"location":"Disability_Bias_Explorer.html","title":"Disability Bias Explorer","text":"<p>cecilym@microsoft.com</p> <p>Recent work led by a team at ethical AI initiative Hugging Face (arXiv:2303.11408) demonstrated a tool that could be used to interactively investigate some of the race and gender biases that have become encoded in major text to image generation systems. Your task is to create a similar tool that could be used to demonstrate image generation biases relevant to visual disabilities. You may also need to consider how this tool can be made accessible to users who have visual disabilities themselves.</p>"},{"location":"Distributed_Microcontracts.html","title":"Distributed Microcontracts","text":"<p>Kampala](Infectious_Diseases_Institute_Kampala \"wikilink\") poyat@idi.co.ug</p> <p>Personal and small business finance innovations increasingly come from low-income countries, as with the hugely successful M-Pesa mobile payment system. The goal of this project is to create a distributed payment and ledger system for organisations that commission many small pieces of work in remote locations. These contracts can often be passed on or subcontracted, making them hard to trace. Your system should use the sensor capabilities of smartphones (e.g. camera, accelerometer, GPS) to authenticate contracts, payment and verification of commissioned work in an intuitive, secure and traceable way.</p>"},{"location":"DoS_D-Stress.html","title":"DoS D Stress","text":"<p>The very first AI chatbot was the psychotherapist Eliza. For young people today, mental health is more challenging than ever, but we aren\u2019t using LLM technology in ways that reduce stress. Your goal is to create a de-stressing experience, potentially including responsive sound and imagery alongside short generated text exchanges that respond to what is stressing you. A fully automated chain should direct stressful content (e.g. an email from your DoS) directly into the system so that you can be properly de-stressed before you even read it.</p>"},{"location":"Don%E2%80%99t_Stop_the_Music.html","title":"Don\u2019t Stop the Music","text":"<p>Audio mixing desks are a mystery to many, as you might know if you\u2019ve ever had to diagnose the silence when your friend\u2019s band goes onstage. Desks have only got more complicated as they integrate USB soundcards for capture and streaming. There\u2019s an opportunity to make life a lot easier for the amateur stagehand, with a phone app to communicate over Bluetooth with a standalone computer (say a Raspberry Pi) that can be connected to the USB port of any low-end mixing desk like the Yamaha MW/12CX. The app should listen to the sound output, analyse the signal, and send either audio test data or user instructions to optimise all the settings.</p>"},{"location":"Dovetailed.html","title":"Dovetailed","text":"<p>vaiva@dovetailed.io</p>"},{"location":"Dovetailed.html#2021","title":"2021","text":"<p>suggestion from Victoria Doerfer victoria@dovetailed.io \"Barometer of Public Emotions\"</p> <p>Feedback:</p> <p>Your suggestion is definitely an area where we are happy to have projects. Two examples from previous years are:</p> <p>2010#Delta:_Party_Line_Detection</p> <p>2016: The Politics of Wikipedia</p>"},{"location":"Dovetailed.html#2020","title":"2020","text":"<p>project: Ethical Surgery Assistant</p> <p>Additional contact in 2019 - Francine Ganter Restrepo francine@dovetailed.io</p> <p>Idea for 2020:</p> <p>Auntie Iris (AI)</p> <p>Client: Vaiva Kalnikait\u0117, Dovetailed</p> <p>Morality and ethics are concepts created by people. However, people are not always inclined to behave in ethical ways. Much of the debate around the fast development of AIs has focussed on ensuring that machine learning systems are designed ethically and make decisions that do not result in harm to any. These debates assume that people are the authority on ethics and morality. In an ironic twist, your task is to build an AI that functions as an ethical consultant or agony aunt to its end users. Much like an interaction with an agony aunt, the system should take on a conversational dynamic, with the user asking a question for which the AI has a witty and philosophical response to.</p> <p>AI agony aunt</p>"},{"location":"Dovetailed.html#2016","title":"2016","text":"<p>Reducing food waste with IoT</p> <p>Edible Lego</p>"},{"location":"Dovetailed.html#earlier","title":"earlier","text":"<p>Something related to touch/tangible interaction?</p> <p>Or location-specific, related to the recent chalking project in Mill Road?</p>"},{"location":"Drawing_Machines.html","title":"Drawing Machines","text":"<p>The ancestors of computer graphics, in the 18th and 19th centuries, used sophisticated mechanisms to render realistic perspective views, transform complex geometry, visualize mathematical and real-world data, and act as human prosthetics. Pablo Garcia\u2019s drawingmachines.org documents many of these remarkable devices, but we have lost much of the information on how they really work. The goal of this project is to build an interactive assembly kit that simulates mechanical drawing machines, bringing them back to life, and even providing a creative resource for today\u2019s art students.</p>"},{"location":"Drive_by_Age.html","title":"Drive by Age","text":"<p>Dana.Ma@jpmorgan.com</p> <p>It is often difficult for young people on the roads to remember that older people (such as the Group Project Coordinators) see the world very differently - sensitivity to light decreases dramatically, while reaction times, awareness of peripheral movement, distance vision, hearing and fine motor control can also change a great deal. Your task is to make a driving simulator that allows a user to drop through from Google Maps into an alternative interactive Street View as experienced by an older person driving a car. You should simulate particularly challenging situations such as night-time with cyclists having dark clothes and no lights. It should be possible to see any neighbourhood in the UK, from the perspective of a wide range of different ages, and with the experience as realistic as possible. You could even control the simulation on the basis of local demographic data, so that popular retirement destinations can be seen from the point of view of their residents.</p>"},{"location":"Driverless_Humans.html","title":"Driverless Humans","text":"<p>Daniel.Clarke@cambridgeshire.gov.uk</p> <p>Cambridge is at the leading edge of many tech developments, including imminent trials of driverless buses, as well as the data infrastructure driving large status displays like the one by the WGB front door. Your task is to use the data infrastructure to solve one of the biggest problems with driverless buses - who will help wheelchair users, visually and cognitively impaired, or those with other mobility problems to get on and off the bus? Your design solution should integrate location services with realtime data from every bus in Cambridge, to help connect those who need assistance to those able to provide it.</p>"},{"location":"Drone_Safety.html","title":"Drone Safety","text":"<p>lawrence@altitudeangel.com</p> <p>When drones fly beyond direct human control, they must plan routes that meet operating and safety criteria. For example, a delivery drone needs to make a number of visits within time constraints, while public safety and policing may require repeated surveys of a specific area. Different drones have different capabilities; some can hover, others cannot, while others require more regular charging. Routing drone traffic safely is also challenging: avoiding airspace restrictions, manned aviation and ground hazards, like crowded roads and pedestrian areas. Your goal is to create a cloud-based air traffic control system that registers flight plans, modifies them in response to hazards based on safety data maintained by Altitude Angel, and makes route alterations in real-time to avoid other drones, as well as gatherings of people identified automatically from real-time Cambridge ground data including WiFi network registrations and public transport locations.</p>"},{"location":"Dry_Cycle.html","title":"Dry Cycle","text":"<p>The Barbican Rain Room was an artificial shower, digitally controlled so you could walk around in it while never getting wet. Imagine if every bicycle ride in Cambridge was programmed to be dry! Your goal is to use advanced Dynamic Causal Modelling (DCM) to extrapolate from open rain radar data, finding precise windows when a specific bicycle journey can be completed through dry corridors, even if it\u2019s raining all around. Some high-end computation will be needed in the back-end, but the user interface should be an intuitive rendering in a web browser.</p>"},{"location":"Dynamic_Narrative.html","title":"Dynamic Narrative","text":"<p>mark.ogilvie@jagex.com</p> <p>Narrative-led games like Telltale\u2019s The Walking Dead and The Wolf Amongst Us present the player with a multilinear narrative driven by a decision-based game engine. Your goal is to take this to the next level, where the player can play several characters that have all experienced the same event, and do this in any sequence. Each decision will have an impact on the game\u2019s visuals, positioning of props and dialogue options. The focus should be on delivering a system architecture and tools that allow developers to track the logic of player decisions and alter the state of the game based on those decisions, including any knock-on effects that each decision may or may not have on the rest of the game. Rendering and player controls can use a standard game engine, but content should be driven by your original narrative architecture.</p>"},{"location":"Eco-Location.html","title":"Eco Location","text":"<p>Centre](UNEP_World_Conservation_Monitoring_Centre \"wikilink\") tim.wilkinson@unep-wcmc.org</p> <p>Wildlife and critical ecosystems around the world include over 230,000 legal \"protected areas\", ranging in size from Coldham's Common in Cambridge https://protectedplanet.net/555561770 to the Serengeti https://protectedplanet.net/555570276. Many people from tourists to researchers and conservationists need to know about these, but there is no quick way to find out whether you are near one. If one is nearby, what can be found there? Barren scrubland or dense forest? Could a park manager see evidence of agriculture where there shouldn\u2019t be, or a visiting scientist learn that the area has been flooded? Your task is to build a mobile application that enables the user to quickly orientate themselves with nearby protected areas, and deliver contextual data by accessing other services. You should specifically include data from the European Space Agencies Global Land Cover Layer to show the percentage of cover types within the protected area (e.g. 40% Mosaic vegetation, 60% Mosaic grassland), and you may include other information such as geolocated photos from Flickr, or species from the IUCN red list of threatened species.</p>"},{"location":"Ecosystem_Game.html","title":"Ecosystem Game","text":"<p>Mike.Harfoot@unep-wcmc.org</p> <p>UNEP-WCMC have been pioneering the development of an agent based model of whole ecosystems, the Madingley model. This process based formulation provides an engine that can be used in many ways. One of the key ways we would like to use the model is to engage with the public and/or decision makers. Your challenge is to consider options for improving the way the model can be used, either through a game interface or a visualisation interface for the model engine. The principal aim is to make the model more engaging and exciting.</p>"},{"location":"Edible_Lego.html","title":"Edible Lego","text":"<p>vaiva@dovetailed.io</p> <p>It\u2019s great fun to make elaborate decorations out of chocolate, but hard to make anything really impressive, because big complex moulds are impractical to commission. Your task is to make a 3D chocolate sculpture tool that takes a (somewhat) arbitrary 3D shape, and decomposes it into pieces that can be assembled from standard shaped blocks such as chocolate bars. However, any unusual local details will need to be queued offline to order a 3D-printed mould for that specific part. You will have access to a basic 3D printer for testing purposes. Unfortunately the Lab cannot supply chocolate, but this project could be a good starting point for a revenue-making business model.</p>"},{"location":"Electric_Motor_Optimisation.html","title":"Electric Motor Optimisation","text":"<p>daniel.bates@monumo.com</p> <p>Electric motors are all around us and together consume about half of the world's electricity. Even small improvements can therefore have large global impacts. Your task is to streamline the early experimental process of motor design, allowing a domain expert to prototype a good design more quickly and/or produce a better design before they reach their deadline. This will involve building an intuitive interface for designing motors, learning about the underlying computational models, and analysing and displaying the results in a way that highlights important features.</p>"},{"location":"Electronically_Cataloguing_Butterflies.html","title":"Electronically Cataloguing Butterflies","text":"<p>The University's Museum of Zoology (UMZC) stores over two million specimens, were collected over 200 years by naturalists including Charles Darwin. Their age means most could not be electronically catalogued at the time of their collection so many had their details transcribed by hand into physical log books, inaccessible to most audiences. Your task is to use optical character recognition and machine learning to transcribe the notebook of one individual into an electronic database or spreadsheet. This may involve going behind the scenes and viewing collections usually inaccessible to the public.</p>"},{"location":"Electronically_Cataloguing_Butterflys.html","title":"Electronically Cataloguing Butterflys","text":"<ol> <li>REDIRECT Electronically Cataloguing     Butterflies</li> </ol>"},{"location":"Elm_Partners.html","title":"Elm Partners","text":"<p>Victor Haghani victor@elmfunds.com</p> <p>Dear Alan, Ian and Megan,</p> <p>Vince Darley kindly told us about your Computer Lab Group Design Projects program, and suggested that a project we\u2019ve been working on may be a good fit with your program. My company, Elm Partners, would like to submit a brief for this project, which we think should have a very significant educational value. Looking forward to discussing this with you, and hoping it merits a place in your project list.</p> <p>With kind regards, Victor Haghani CEO and Founder, Elm Partners Victor@Elmfunds.com</p> <p>Title: Flipping to a Fruitful Future</p> <p>We\u2019re facing a savings crisis. Too many in our society won\u2019t have adequate savings for their retirement, despite favourable long-term expected returns available in the stock market and government policy encouraging savings by granting tax-free status to qualified retirement accounts. People don\u2019t save enough, but more inexcusable is that they manage their investments poorly. Research we\u2019ve done (please see our recent paper on ssrn and this Bloomberg article) on how people bet on a biased coin highlights the need for more effective training in practical investment skills. We believe that playing a simple coin flipping game in combination with appropriately linked instruction can effectively teach people to do a better job managing their savings. This approach to teaching decision making under uncertainty is novel, and differs with the most common gamified versions of investing which teach participants all the wrong lessons about investing-- no one ever won an investing tournament by buying a market portfolio index fund. A rough prototype of the game which was used for our experiment is: coinflipbet.herokuapp.com. The project is to develop an engaging interactive game around coin flip betting that will more closely simulate lifetime investing. Users should get feedback on how they\u2019re doing compared to optimal strategies, such a fractional Kelly betting, and to the pool of other participants to date. They should be able to see what their betting behaviour implies about their utility function, and what in turn that says they would do in other circumstances. They should get a feel for randomness and learn to be on guard against a number of powerful and damaging cognitive biases that stand in the way of sound investing, such as gambler\u2019s fallacy and loss aversion.</p> <p>-- Victor Haghani Founder www.elmfunds.com US: (307) 222-4725 UK: +44 20 3290 4725</p>"},{"location":"Email_Diplomacy.html","title":"Email Diplomacy","text":"<p>angus.allen@volemic.com</p> <p>It is easy to make a mistake when sending an email and the consequences range from personal embarrassment to professional misconduct. In order to prevent these errors, it is likely to be helpful to understand the relations between different people associated with an email. At its simplest, this could involve identifying and classifying the sender, each recipient and any other people mentioned in the body of an email. It might also be useful to provide a confidence score for each relation, to recognise where a recipient is a member of a group of people such as an organisation, or classify the tone of the language used to ensure it is appropriate.</p>"},{"location":"Embecosm.html","title":"Embecosm","text":"<p>Potential client: Will Jones william.jones@embecosm.com</p>"},{"location":"Emma_Salgard_Cunha%281%29.html","title":"Emma Salgard Cunha(1)","text":"<p>Emma is based at Cambridge Enterprise, responsible for commercialisation of research from Cambridge Arts, Humanities and Social Science departments. Researchers in those departments often have interesting digital projects, without ready access to technical resource for prototyping. It's worth contacting her each year, to see whether she might be aware of potential opportunities</p> <p>In 2021:</p> <p>Introduction to Vladimir Vilde, regarding technology for linking from image watermarks.</p> <p>In 2020:</p> <p>I\u2019m working with a conservation and behaviour researcher based in zoology, Doug Macfarlane, on a proto-social enterprise based around assessing and directing funding into evidence-based and evaluated conservation projects.</p> <p>At the moment the idea is to deliver this as a sort of consultancy to corporate or other large donors to match them up with small-scale projects in need of funding. The team have access to data and a formula which allows them to rank the projects by urgency, efficacy, etc. But there is also the thought of producing a platform, in the style of a crowdfunding site, to display and rank projects and to gamify the process in order to encourage donors to achieve the greatest impact and possibly even to rank their philanthropic efforts against others in their sector.</p> <p>This is Doug\u2019s academic profile. He has built an interesting team of social scientist and conservation practitioners: https://www.zoo.cam.ac.uk/directory/douglas-macfarlane</p> <p>Although its less of a design-led project than the digital humanities projects, I wonder if this could be of interest to your students. If so I\u2019d be glad to put Doug in touch with you (or whoever is holding the fort while you are away).</p>"},{"location":"Emo_Face.html","title":"Emo Face","text":"<p>Has been offered to Collusion</p> <p>Some people find it easier to express emotion with emojis than with facial expressions. Your task is to prototype a personal projector that will use camera input to track a person wearing a blank face mask, and project onto the mask a version of their face with a relevant expression selected using emoji input.</p>"},{"location":"Empathetic_Chatbot.html","title":"Empathetic Chatbot","text":"<p>Futures](Centre_for_Policy_Futures \"wikilink\") l.wilson7@uq.edu.au</p> <p>Chatbot dialog builders can be used to create systems that are very good at dispensing accurate information such as medical advice, following a configurable decision tree, but the output text needs to be standardised and impersonal. Language model-based text generators on the other hand, produce text that is grammatical and possibly entertaining but often factually wrong. Your task is to integrate the two into a demonstrator for the World Health Organisation that can be configured by public health clinicians to give accurate advice when needed on problems like Covid infection, and can also stimulate mental health with original creative responses - but only when the question from the patient makes it safe to do so!</p>"},{"location":"Employability_Coach.html","title":"Employability Coach","text":"<p>Client Entrepreneur First</p> <p>Contact: Matt Clifford matt@entrepreneurfirst.org.uk</p> <p>Many tech companies collect data about potential employees via online application forms. But it's hard to know whether your own answers to each question are going to look competitive. Wouldn't it be great if you got feedback as you were typing, like the password strength guidance often provided when you choose a new password? The goal of this project is to use the large database of applications to Entrepreneur First to train a live interactive form processor that gives feedback as you type on how employable you seem to be. Once the form is complete, it should return a visualised \"employability map\" that pinpoints how you stand in relation to all the other potential applicants - for example, using data gained from a business networking site like LinkedIn. This map should take account of various aspects of employability (qualifications, technical experience, social life) and also the trade-offs between them.</p>"},{"location":"Energy_Budget.html","title":"Energy Budget","text":"<p>Yuichi Abe, Informetis yuichi.abe@informetis.com</p> <p>Shops don\u2019t take your money without asking, so why should your home appliances use scarce electricity resources without consulting you? Current \u201csmart meters\u201d are pretty useless, because house occupants have to guess where the power is going. Local company Informetis has an Internet of Things device that sends a WiFi stream of power consumption from any appliance. Your task is to make an app that will aggregate and visualise this data to help households budget for a future where energy costs 10 times what it does today. When energy is rationed, what will work best? Neighbourhood contests, household policies, online games or financial incentives? Your system design needs to address motivation, not just monitoring.</p>"},{"location":"Energy_with_Social_Conscience.html","title":"Energy with Social Conscience","text":"<p>yuichi.abe@informetis.com</p> <p>Although electricity generation in the UK relies increasingly on renewables, these only provide low baseline capacity. To meet demand spikes, electricity companies must burn gas and oil. In principle, smart meters would allow a social consensus to save the planet \u2013 we just can\u2019t afford 10 million people getting out of bed to switch on their kettles at the same time! Your client has smart technology already detecting household current consumption. Your task is to create machine-learning appliance detection, real-time data infrastructure and front-end services that could minimise fossil fuel consumption across the whole country, while keeping everyone happy through consensus pricing markets and social media.</p>"},{"location":"Engaging_Everyone.html","title":"Engaging Everyone","text":"<p>Many public events and services aim to include young people, with meaningful attention to their specific views and needs. Our own outreach activities, such as the huge Cambridge Festival (next taking place on 16th March 2024) want to ensure that feedback from visiting families includes all visitors, especially where \u201cfamily\u201d feedback might otherwise only engage adults through traditional surveys. Your task is to create a fun and engaging online tool that encourages people of all ages to share their views, and is inclusive and motivational for the young. If successful, we can deploy this at the Cambridge Festival as soon as it is finished.</p>"},{"location":"Engineering_Design_Centre.html","title":"Engineering Design Centre","text":"<ol> <li>REDIRECT Touch screen prototyping at     school</li> </ol>"},{"location":"Entrepreneur_First.html","title":"Entrepreneur First","text":"<p>Matt Clifford at Entrepreneur First.</p> <p>matt@entrepreneurfirst.org.uk</p> <p>Employability Coach</p> <p>Initial discussions:</p> <p>to make better and/or quicker selection decisions - has long been a goal for many employers. Advances in Natural Language Processing and other AI/ML techniques present an opportunity to make this a reality.</p> <p>We invite you to explore whether hiring and selection can be improved using automated evaluation of written applications. You will explore different potential approaches to this problem and create prototype software that assesses and scores completed application forms. Interesting extensions might include exploring visualisation techniques to make the software's output transparent to non-technical users.</p> <p>We see the software created having wide applicability and would encourage and support you to open source your work where appropriate.</p> <p>From Alan, 5 September:</p> <p>One thing that occurs to me is a privacy and data protection issue. Do you have permission from the people whose application data you are holding to use it in this way? Even if it has been submitted to you with consent for this kind of use, it might not be appropriate for personally identifiable data to be distributed to undergraduate students. We do have some provision for confidentiality of data in the group projects, but it might be necessary to either anonymise in some way, or for members of your organisation to be responsible for actual dataset handling.</p> <p>The \"spicing\" ideas that I had were:</p> <p>1. Make a comparison between the discriminatory power of application data and publicly available (Facebook) data. This in light of today's Dilbert! (link to follow)</p> <p>2. If you're evaluating applicants primarily for entrepreneurship, then rather than simple yes/no, we could suggest that an enhanced algorithm offer a score for investment potential. (Of course, they'd have to notice that the judgement ground truth data they have is not necessarily well correlated with the value they need to derive)</p> <p>3. Students might like to see something in it for them, rather than simply a sausage-selector for future recruiters. How about using the same scoring judgements to provide a CV-grooming service for job applicants?</p>"},{"location":"Environmental_Value_Added.html","title":"Environmental Value Added","text":"<p>Direct action can be an effective contribution to our preparations for the future. However, with limited resources in volunteer organisations, it is important to target action toward the problems that have greatest benefit for the environment. The goal of this project is to use public information such as traffic monitoring and air quality data to help activists deliver most value to public thinking and government policy. A useful direct action coordination app could take account of public opinion, availability of activist volunteers, and measurement of environmental data to maximise the benefit to society of such organisations.</p>"},{"location":"Envisioning_Nairobi.html","title":"Envisioning Nairobi","text":"<p>lindankatha@gmail.com</p> <p>Large cities around the world are grappling with plans to accommodate environmental, social and climate change. But there is a huge gulf between the technical software of geographical information systems and infrastructure planning on one hand, and the retail and entertainment data that is promoted in consumer products like Google Maps. The city of Nairobi is thinking ahead through visionary planned cities as Nairobi Railway City, Tatu City, and the Konza Technopolis, that aim to present models of how an environmentally sustainable and climate-resilient urban area developments in a carbon-constrained environment can be delivered. Your role is to prototype a new social mapping tool that could engage members of the local population in these discussions, visualising data, plans, priorities, and their personal implications.</p>"},{"location":"Epistora.html","title":"Epistora","text":"<ol> <li>REDIRECT Sparrho</li> </ol>"},{"location":"Equity_Exchange.html","title":"Equity Exchange","text":"<p>(mjohnson@frontier.co.uk).</p> <p>The crowd-funding proposition (e.g. Kickstarter) is simple - give us your money, we\u2019ll make a product. So is Mechanical Turk - do our menial task, we\u2019ll give you money. What about situations where everyone is adding value, and the rewards should be shared (or negotiated) in proportion? Many startups, indie video games, and social enterprises work this way. Because there are no suitable online platforms for negotiating and setting them up, at the moment everyone involved has to live in the same place, whether Silicon Valley or Cambridge, to work it out over endless macchiatos. Your task is to create an online service that uses artificial intelligence approaches to help potential co-founders form a team, and create a fair legal framework, financial structure and investor/market engagement mechanisms. Software startups would expect all of this to sit on top of a Github-style repository for content and code, customised to their individual needs. If there is a market here, you\u2019re free to use the result to bootstrap your own business!</p>"},{"location":"Ethical_Surgery_Assistant.html","title":"Ethical Surgery Assistant","text":"<p>vaiva@dovetailed.io</p> <p>More than 15 million GP appointments are missed annually, costing the NHS hundreds of millions of pounds. Your task is to build a proactive, ethical appointments assistant for a GP surgery that will call or email patients prior to their appointments to confirm date and time, and increase the likelihood the patient will attend. There should be a good conversational flow, with the assistant leading the conversation, and learning over time how to handle conversations more effectively and even become personalised based on patients\u2019 input. Extra features include handling prescription renewal, and appointment booking by phone or email.</p>"},{"location":"Every_Car_in_Cambridge.html","title":"Every Car in Cambridge","text":"<p>ijl20@cam.ac.uk</p> <p>Earlier this year, for a period of one week, we deployed around Cambridge 90 Automatic Number Plate Recognition cameras. This has provided anonymized timestamped journey segment data for about 4,000,000 vehicle movements between pairs of cameras. Your task is to provide a tool that supports flexible end-user analysis and visualisation of this data. For the same time period we also have car park occupancy information as well as major road journey time information derived from the real-time position of buses and it may be of interest to relate the ANPR data to these sources.</p>"},{"location":"Evolve_a_Pet.html","title":"Evolve a Pet","text":"<p>KCheetham@illumina.com</p> <p>The goal of this project is to create a game that teaches GCSE or A level science students about genomes and genomic sequencing. The idea is for a number of users to run evolutionary optimisations (perhaps using genetic algorithms) that optimally combine the favourite features of their pets - or perhaps even alien species! As with dog breeding, there may be some genetic trade-offs between functional and aesthetic attributes. Local optimisation to meet a particular user's preferences can take place on individual users' computers - perhaps mobile phones, or even Raspberry Pis. Once a desirable local optimum has been reached, users should be able to select which part of the genome to exchange with their friend's pets. Exchanges could simply take place online, but it might be more interesting to require a physical meeting - exchanging genetic material via bluetooth, with a network cable that directly connects one Raspberry Pi to another, or some other form of ad hoc networking.</p>"},{"location":"Exhibition_Inference.html","title":"Exhibition Inference","text":"<p>Music](Royal_College_of_Music \"wikilink\") neta.spiro@rcm.ac.uk</p> <p>The Royal College of Music Museum has one of the richest collections of music-related objects in the UK and Europe, spanning over 500 years of musical activity. A new layout has just been created, and the museum needs to learn how visitors respond to it in order to refine the design in future. We suggest tracking (with permission) visitors who may use QR codes to access media or links from a specific exhibition case. Your task is to combine time-stamp records of QR access with dead reckoning from a phone's step counter, glimpses of GPS signal through the museum windows, prior knowledge of valid walking paths around the museum display, and any other sources of data you can find, to get the best estimate of how visitors travel around the museum, as well as which exhibits they pause at and in which order.</p>"},{"location":"Extrusion_finder.html","title":"Extrusion finder","text":"<p>Client: Emma Gordon, Metaswitch Networks emma.gordon@metaswitch.com</p> <p>Many offices, houses, furnishings and machines are made from lengths of metal or plastic that have a constant cross-section, but come in different lengths of extrusion. When one of these breaks, it ought to be possible to fix it by ordering a replacement length and simply snapping it into place. However, it's not necessarily easy to find the extrusion you want. The result of this project would be a great new market opportunity. A user can simply take a picture of the required cross-section (using their phone, or perhaps a flatbed scanner), and the system should automatically find the closest match from online catalogues or sales sites such as seagateplastics.com. As a last resort, an obsolete product could even be resurrected with 3D printing - but there is far more profit to be made by making online referrals and have someone else worry about the manufacturing!</p>"},{"location":"Eye-Tests_on_Demand.html","title":"Eye Tests on Demand","text":"<p>peter.thomas@addenbrookes.nhs.uk</p> <p>Everyone is familiar with visual acuity tests, where you read an eye chart on the wall, while a nurse or optometrist asks which letters you can see. These are expensive and time-consuming to run, but there may be alternatives. Imagine a display screen on the wall of a chemist, a doctor's waiting room, or a driving test centre, running the eye test as a full-screen page in a standard browser. You take out your phone, connect to a shared web server using an on-screen QR code, then stand in the spot marked on the floor at a calibrated 4m distance. All remaining instructions are delivered over audio from your phone headset, with any necessary interaction eyes-free (e.g. 'touch the left of your phone if you can see a \"b\", touch the right if you see a \"d\"'). You should ensure that the result is private and secure, including a mechanism to send you the results by email without bystanders seeing who you are (remember that the people being tested may be elderly, with poor eyesight).</p>"},{"location":"Eyes_in_the_Sky.html","title":"Eyes in the Sky","text":"<p>Package delivery by drone might become a reality. Until it does, postal and delivery services are considering the immediate potential in remotely driven vehicles. Your task: figure out how to monitor those vehicles from the sky! The goal is to build a service that tracks a vehicle with a drone (using a visual, wifi or bluetooth beacon) and broadcasts the drone\u2019s video output to a web-based interface.</p>"},{"location":"Eyes_on_the_Road.html","title":"Eyes on the Road","text":"<p>Are VR-controlled vehicles the answer to postal woes? With e-commerce pushing package-delivery services to the brink and self-driving cars not yet available, we want to explore a new generation of remotely driven vehicles. Your exciting task: build a service that controls a smart vehicle (Lego Mindstorms EV3 Car with camera) using a VR headset (Oculus). Optionally, you could broadcast the video output of the smart vehicle to a web service.</p>"},{"location":"Fair_Finance.html","title":"Fair Finance","text":"<p>Potential client: 'Faisel Rahman' faisel@fairfinance.org.uk</p> <p>Original contact: matthew.jones@jbs.cam.ac.uk (Matthew is an affiliate of JBS, but also Chairman of the Board for Fair Finance)</p> <p>Project could look at development of a mobile platform for community-based risk management of loans to people who do not have access to low-cost financial services.</p> <p>Some similarity to the Distributed Microcontracts project from last year</p> <p>Issues to consider: lenders need something that replaces face-to-face risk assessment; costs must be low to serve low-income market; a mutual society might be able to establish new social trust mechanisms employing mobile phone features.</p> <p>https://www.fairfinance.org.uk/</p> <p>Initial idea:</p> <p>Community risk sharing</p> <p>Building a relationship with the customer is an essential part of loan financing, often face to face in situations where risk is higher. Fair Finance offers community-based loans to people on low incomes, and need to expand their operations beyond London. Your task is to build a mobile app that supports quantified management of financial risk by sharing data (including location, photos, call records etc) among local members of a supportive community. Privacy and security will be paramount, as will sensitivity to the dignity and rights of those living on low incomes.</p>"},{"location":"Faraday_Predictive.html","title":"Faraday Predictive","text":"<p>Boulton will.boulton@artesis.co.uk</p>"},{"location":"Faraday_Predictive.html#ongoing-discussion","title":"ongoing discussion","text":"<p>Actually for our purposes we're not wholly focused on how good their data analysis is (though obviously if they manage to do a really great job, that would be excellent) - our thoughts were that as long as they've managed to design the system as a whole well, we could then spend some time refining or rebuilding the predictive fault diagnosis part, but what's really valuable for us would be a 'nice looking' user interface (maybe as a web app, if they felt that was most appropriate?) with capability to automatically provide reports, and a function to schedule maintenance in the future, and update a log to keep track of when known faults have happened; and the data stored logically in a database that they could design (depending on if we only gave them CSVs of the raw data). Perhaps one way to extend this into a more ambitious plan would be to ask for them to additionally have a reasonable looking phone app so that an engineer about to go to the site could get some idea about what was wrong with the compressor they were looking at (or make notes if they noticed something funny), whereas a manager on their PC could have an overview of what was happening across the whole plant?</p> <p>A different option, though of a similar nature, could be to ask for the students to design a system such that their analysis of the data could be easily extended (by us) e.g. by uploading Python scripts to a repository and then getting results back in close to real time, with graphical results displayed in a friendly format - that would also be very valuable to us since and hopefully turn their task from just a data analysis task into one of overall design of the entire system.</p> <p>One other thing we had in mind (though I'd need to discuss first with Geoff first) would be to provide a small bank of about 10 little DC motors (in a suitcase-sized box and with power supply etc already set up), and some sensors to go with them; if interfacing with that could provide a similar level of technical challenge compared to interfacing with the bike (in addition to using the sensor data to detect which motors are showing anomalies and display the results), then that could be very useful to us, and we'd be happy if the students wanted to test these motors to destruction, in which case there would be far less need for much insight into the mechanical systems as the problems introduced should be completely obvious.</p> <p>Predictive Maintenance of Industrial Equipment</p> <p>Faraday Predictive is a small local technology company which uses sensor data from electric motors to diagnose faults in rotating equipment (e.g. fans, pumps, compressors), and provide advice to clients about maintenance of their equipment. Useful advice contributes to the smooth running of this industrial equipment, potentially saving customers millions of pounds in some cases.</p> <p>One of our customers operates in the gas industry. We have an expanding dataset (still in use) of thousands of records from 72 identical gas compressors, some of which have shown problems, that could be used to train machine learning models, rather than relying on expert analysis of each compressor. Your task is to deliver a system that can easily be used both by site engineers to alert them to problems, and allow them to provide feedback (alerting your system to when and where maintenance has occurred), and site managers, to schedule maintenance based on your models of machine health.</p> <p>Potentially a project related to the company's work in condition monitoring of rotating machinery, for example using machine learning for failure prediction. However, this would have to be integrated into a larger product concept.</p> <p>Alternatively, perhaps adapt The Headless Bicycle?</p>"},{"location":"Fauna_and_Flora_International.html","title":"Fauna and Flora International","text":"<p>Contact Gavin Shelton Gavin.Shelton@fauna-flora.org</p> <p>Head of Conservation Labs</p>"},{"location":"Feeding_Body_and_Mind.html","title":"Feeding Body and Mind","text":"<p>david.sharp@ocado.com</p> <p>As reported in the media, lack of proper nutrition is a particular problem for schoolchildren, as it affects their learning and educational progress. Your task is to produce a system that enables schools to spend financial gifts from donors at an online supermarket on food, crockery, etc. to supply clubs that give children a good meal and teach commercially valuable skills such as programming. The system should gamify both nutritional and educational needs to encourage the children to engage, and might consider multiple factors such as cost of items, and timeliness of delivery. If successful, your project will be released as open-source for Ocado to deploy.</p>"},{"location":"FetoLife.html","title":"FetoLife","text":"<p>Contact Nora J\u00f6chlinger nora.joechlinger@fetolife.com</p>"},{"location":"Fever_Finder.html","title":"Fever Finder","text":"<p>dan@simprints.com</p> <p>Google Flu Trends was a famous (but unsuccessful) attempt to predict flu outbreaks on the basis of anxious people searching for symptoms. A more pressing need is to work out whether people in remote villages might be harbouring an outbreak of Lassa, Zika or Ebola. Your goal is to design a smartphone-based field station that geolocates fever symptoms for members of a family or village, using technology from Cambridge startup SimPrints to identify individual cases. With advice from an infectious disease specialist, you can use machine learning to model potential outbreaks as they occur.</p>"},{"location":"Financial_Battlefield.html","title":"Financial Battlefield","text":"<p>ewan.kirk@cantabcapital.com</p> <p>Attempts to make financial graphs or political trends more entertaining are often disappointingly unimaginative. We have seen too many VR mountain ranges and city skylines. Your task is to communicate the excitement of financial trading data by using the latest gaming technology. We'll provide powerful GPUs for you to use with the Unreal game engine and a budget for off the shelf game art and graphics assets. You will render large scale investment data based on thousands of data streams as competing armies of simulated characters whose bodies, weapons and AI behaviour are determined by key market attributes.</p>"},{"location":"Financial_Trading_Trends.html","title":"Financial Trading Trends","text":"<p>piers.thompson@baml.com</p> <p>Over-the-counter (OTC) trading of financial products is less regulated than exchange trading, but also less transparent. To improve market fairness and efficiency, near-realtime details of OTC trades must therefore be placed in a public repository (rtdata.dtcc.com/gtr/dashboard.do). However, since this data is not easy to view and analyse, the aim of increased transparency has not been achieved. The aim of this project is to provide a convenient means of accessing, viewing and analysing OTC trade data. This should provide realtime data on current prices and trading volumes, historic trends, and automated identification of pricing anomalies and trend alerts.</p>"},{"location":"Finding_Nature.html","title":"Finding Nature","text":"<p>Suggestion from UNEP-WCMC</p>"},{"location":"Fitzwilliam_Museum.html","title":"Fitzwilliam Museum","text":"<p>Potential client: Daniel Pett dejp3@cam.ac.uk says I\u2019m interested in quite a few things based around collections and data:</p> <p>1) Machine learning and computer vision - the work my former colleague, Harrison Pim is doing at the Wellcome is along the lines of where I want to go eg https://twitter.com/hmpim/status/1052961056727990272 Very python driven research or R.</p> <p>Feedback: Harrison Pim's work is probably more the kind of thing that we might get a Master's student to do. Undergraduates could probably have a good hack at it, but computer resources are higher than they usually have, it can often take longer to negotiate access to labelled data than the span of the project, and it's hard to divide this kind of work among a team - as you say, usually just one person at a Python console (followed by waiting three days for the network to be trained).</p> <p>2) Predictive modelling of exhibition attendance</p> <p>Feedback: Predictive modelling of exhibition attendance would have results largely driven by the quality of your dataset. What kind of real-time data do you have access to, and is there a substantial amount of historical data for building the predictive model?</p> <p>3) Data science stuff around social media and reviews data from sources like Tripadvisor</p> <p>Feedback: It's an interesting idea to work with Tripadvisor. Do Cambridge museums pick up a lot of reviews there? Do you happen to know anything about their APIs and terms of service for data mining research?</p> <p>4) 3D modelling approaches</p> <p>Feedback: I presume you mean 3D models of collection objects. Do you have a laser scanner that could be used for the digitisation stage? We don't have one in the Computer Lab, but have collaborated with other museums in the past who used their own scanners, for example in NHM.</p> <p>5) Visualisation of any sort</p> <p>Feedback: Past experience is that CS undergraduates are not that good at inventing novel visualisations. My research group does a lot of visualisation research, but for undergrads, we would probably have to specify exactly what we want their system to look like.</p> <p>6) expansion of my crowdsourcing project https://crowdsourced.micropasts.org</p> <p>Feedback: That's a nice project. Which of the datasets have attracted most labelling input? Is this in a form that validation and reliability analysis might be useful?</p> <p>Original introduction:</p> <p>After meeting with Andrea Kells, \"... feels that there might be scope for the Museum to offer one or more projects \u2013 for example around digital curation, monitoring visitor interaction with exhibits/visitor flow, using social media and other sources to collate and analyse visitor feedback etc.\"</p> <p>Previous projects (see also Hamilton Kerr Institute, Cambridge Museums):</p> <ul> <li>Next-Generation Museum   Guide - in   2008 and 2006</li> </ul> <ul> <li>Smart Poster Picker - in   2008</li> </ul> <ul> <li>Pigment Analysis with Hamilton Kerr   Institute</li> </ul> <ul> <li>History Phone</li> </ul> <ul> <li>Anthropometrics Today</li> </ul> <ul> <li>The Poet Laureate's web   thresholds</li> </ul>"},{"location":"Fix_the_past_with_Raspberry_Pi.html","title":"Fix the past with Raspberry Pi","text":"<p>Suggestion by Peter Robinson / Simon Moore</p> <p>Current status: it seems unlikely that the EDSAC reconstruction project will have a working chassis ready in time for group project public demonstrations in March 2013. It may be necessary to defer this project until 2014.</p> <p>The pioneering Cambridge EDSAC computer is now being reconstructed at the national computing museum(??). However, the radio valves, mercury delay lines, and other components of EDSAC are all far less reliable than modern technology. This means it will be a real challenge keeping the thing running! Your task is to build an embedded diagnostic monitor device, using Raspberry Pi, that can continuously monitor the health of the reconstructed EDSAC, warning operators when something needs to be fixed, or perhaps that it is about to fail. We expect there will be multiple Raspberry Pi's in each chassis or frame of the EDSAC. They might even be able to compensate for temporary failures, imitating the behaviour of that chassis to keep the rest of the system working until a failed component is replaced.</p> <p>Category:Raspberry Pi</p>"},{"location":"Flash_Mob_Learning.html","title":"Flash Mob Learning","text":"<p>School students increasingly use tablet or mobile devices to access online content or submit work, but these depend on network infrastructure. The goal of this project is to create a local content hub that allows students and teachers to collaborate, but without needing an internet connection (for example, in developing countries, in rural locations, or just to avoid the bureaucracy of school internet permissions). You will use a Raspberry Pi as the basis for a WiFi hotspot that also has a built-in educational content platform, allowing students themselves to collaborate in building the content. This could support in-browser creation of shared executable scripts as provided by skulpt.org, or even shared composition of a piece of digital music (see sonic-pi.net) that would be played from a speaker on the central device.</p>"},{"location":"Fly-past_Finance.html","title":"Fly past Finance","text":"<p>Radmilo Racic radmilo.racic@imc.nl, cc: Taylan.Toygarlar@imc.nl</p> <p>We think the Oculus Rift can be used to navigate complex and correlated financial data using virtual reality. Your goal is to integrate time series data on global futures, stocks, bonds and currencies with trader sentiment and pin point market moving trades. The team will be provided with time series data from Eurostoxx, DAX, CAC, KOSPI, Nikkei, ES, EUR/USD, T-Note, GBL, etc. The VR interaction module should allow users to look and left and right to see the past and future, nod forward and back to zoom in and out for more detail. Other movements, such as leaning to the left or right, could be used to select data sets or analyses.</p>"},{"location":"Flyathlon.html","title":"Flyathlon","text":"<p>Ornithology](British_Trust_for_Ornithology \"wikilink\") adham.ashton-butt@bto.org</p> <p>Major sporting events such as marathons and triathlons often raise funds and awareness for good causes including conservation. This project is an opportunity to design a new global sport where human challenges are measured against the challenges faced by wildlife such as migrating wild birds. You will use the Strava API to capture records of human performance, and monitoring data from bird migration (available from your client) to represent wildlife. You will need to define the rules for this new hybrid sport, including secure and fair algorithms to determine the competition results that might combine running, cycling and flying stages. Will humans compete against birds, or be combined in hybrid teams? Your technical platform should also include social media and live stream support to that can be scaled to global public participation such as refereeing, commentary, fan clubs or cash sponsorship.</p>"},{"location":"Flyathlon_%282019_version%29.html","title":"Flyathlon (2019 version)","text":"<p>Ornithology](British_Trust_for_Ornithology \"wikilink\") jennifer.border@bto.org</p> <p>Major sporting events such as marathons and triathlons often raise funds and awareness for good causes including conservation. This is an opportunity to design a new global sport where humans compete digitally in relay teams alongside wildlife. Using the Strava API, and records of bird migration from the British Trust for Ornithology, create secure and fair infrastructure for a competition that includes joint teams of cyclists and wild birds, attracting large audiences through public engagement for refereeing, commentary, fan clubs and sponsorship.</p>"},{"location":"Fossil_or_Future.html","title":"Fossil or Future","text":"<p>During the COP26 conference, it became clear that many politicians around the world do not necessarily follow the party lines of the 20th century left versus right, but are dividing themselves between those who mainly plan for the future, and those that focus on protecting the past. It should be possible to use natural language processing to help the electorate decide between these alternatives, by identifying the real allegiance of public officials to classify them as either fossil or future. Simple bag-of-words classifiers won\u2019t be enough, because anybody could mislead readers by dropping in random words. It\u2019s likely that you\u2019ll need to use some kind of deep learning, and also plan for the possibility of inadvertent bias or even malicious sabotage when collecting the training set.</p>"},{"location":"Fossil_or_Future%3F.html","title":"Fossil or Future?","text":"<p>Version for 2023:</p> <p>Client: Matthew Postgate, Informeta Ltd matthew.postgate@infometa.com</p> <p>Humanity needs to respond to climate change, but there is a lack of science-based policy for sustainable action. Legislation is not consistent, and corporate actors continue to lobby against climate legislation even while promoting environmental strategy in other areas. These factors make it hard for politicians to make essential choices between fossil fuel strategies that worked in the past, and the unavoidable future. The goal of this project is to develop a science-based decision tool, for use when drafting and reviewing policy proposals, that both analyses the language used and calculates realistic projects along the lines of David MacKay\u2019s classic book Sustainable Energy Without the Hot Air.</p> <p>Older version discussed for 2022:</p> <p>During the COP26 conference, it became clear that many politicians around the world do not necessarily follow the party lines of the 20th century left versus right, but are dividing themselves between those who mainly plan for the future, and those that focus on protecting the past. It should be possible to use natural language processing to help the electorate decide between these alternatives, by identifying the real allegiance of public officials to classify them as either fossil or future. Simple bag-of-words classifiers won\u2019t be enough, because anybody could mislead readers by dropping in random words. It\u2019s likely that you\u2019ll need to use some kind of deep learning, and also plan for the possibility of inadvertent bias or even malicious sabotage when collecting the training set.</p>"},{"location":"From_Hogwarts_to_hackers.html","title":"From Hogwarts to hackers","text":"<p>Many children are more interested in imaginative stories than tinkering with circuit boards. But they need not be excluded from Raspberry Pi. The goal of this project is to create a multiplayer online game, where each room of a castle runs on a different Raspberry Pi. The owner of that Pi should be able to define surroundings, objects, characters and scripted interactions (e.g. to learn spells or solve challenges) as well as visiting other player's rooms. Players get to learn about network topologies, scripting languages and command lines - but all while having sociable fun. A text adventure game might be the best choice - for example, of the kind that can be created with plot scripting language Inform7, or LambdaMOO, but you are free to attempt simple graphics or other presentation styles.</p> <p>Category:Raspberry Pi</p>"},{"location":"From_PDF_to_Practice.html","title":"From PDF to Practice","text":"<p>biko.jj.agozino@jpmorgan.com</p> <p>Many hospitals and trusts in the UK produce their own local guidance, regarding what medicines should be given to patients before and after operations (perioperative medication). Policy is buried in PDF documents and academic papers, which combine descriptions of drug properties with factors that might result in different advice to different patients. Your task is to create a system that can automatically extract and compare a wide range of such advice, presenting it in a form such that clinicians can draw on both best practice and individual factors when advising a specific patient.</p>"},{"location":"Frontier.html","title":"Frontier","text":"<p>New Contact for 2025 is Head of Design Laurence Oldham, who plans to raise with Oscar Cooper, Senior Director of Development</p>"},{"location":"Frontier.html#2021","title":"2021","text":""},{"location":"Frontier.html#confirmed-augmented-room-dressing-for-zoom","title":"Confirmed: Augmented Room Dressing for Zoom","text":"<p>Second project that was considered: Social Distance Modelling</p> <p>Businesses would like to open up commercial spaces adapted for social distancing measures. But what's the best way to guide people through these spaces so they have the best chance of maintaining distance? Design a simulation that can model customers as particles that freely move around these public spaces keeping to an avoidance radius with each other. Include directional markup (one way systems) that control the flow of customers around the space. Track congestion metrics to evaluate the safety of the building. With a complete simulation implement machine learning techniques to generate the best directional markup for a given space. Perhaps there are some good common techniques that any business can learn from!</p> <p>I wonder if the Feng Shui idea could be modified to provide some Covid relief? Perhaps something that generates a dynamic Zoom background that is based on a captured model of student\u2019s actual room, but with augmentations?</p> <p>My Logitech webcam has an app with controls to pre-process camera input before it goes to Zoom/Teams etc. However, perhaps it does this on-camera, since it seems to be OS-independent.</p>"},{"location":"Frontier.html#2020","title":"2020","text":""},{"location":"Frontier.html#confirmed-robotic-warehouse-design-suite","title":"Confirmed: Robotic Warehouse Design Suite","text":"<p>Online shopping is taking over the world! A growth area in robotics at the moment is the use of robots and AI in the efficient running of warehouses and retail storage facilities. The team should produce a virtual warehouse simulation and demonstrate how AI may be applied on this training suite to control bots in their storage and retrieval of randomised streams of orders for items to allow the suite to find efficient methods of organising and driving a robotic warehouse area. How AI is applied to the system, whether in terms of organisational control, or manipulation, or both is up to the teams to decide.</p>"},{"location":"Frontier.html#locomotion-system-api-middleware-for-games","title":"Locomotion System API middleware for games","text":"<p>In today\u2019s game development world there are middleware solutions for many of the problems facing games and simulation developers. One of the areas currently dominated by bespoke programming is the area of character locomotion through an environment. Focusing on 3d applications, we would be asking a project team to create a general library allowing developers to specify and create instances of controllable objects, taking navigation directives, and within the specified movement parameters of the object, navigating the world in which it exists to reach its objective. This may involve traversing uneven or barricaded terrain, and possibly even climbing walls or traversing ceilings where necessary. The solution must have a means of connecting with animation assets to control the movements of the object. The system must support bipedal and other forms of controllable objects.</p>"},{"location":"Frontier.html#accessibility-assessor","title":"Accessibility Assessor","text":"<p>Today, with smart phones being such powerful computational devices equipped with cameras the opportunity to capture data from the world around us has greatly increased. This project aims to produce a piece of software which can be used on a smartphone to capture the 3d shape of an interior environment in order to produce a simplified computer model. This model may then be processed, perhaps by another device in order to produce a node graphed plan of the floorspace. This plan could provide useful views of the space in terms of accessibility and aiding planning usage of existing space.</p>"},{"location":"Frontier.html#tidy-rescue-bot","title":"Tidy Rescue Bot","text":"<p>We are seeing an ever increasing use of AI in real world applications over time. One of the most useful potential applications is to enable robots to do work in environments which could be hazardous to humans. Such examples could be earthquakes, or the aftermath of tsunamis, or even the problematic resolution of the Chernobyl nuclear disaster. We would like the team to create a simplified 3d simulation of such hazardous environments and produce a prototype software system to show the possibilities of using AI to attempt to safely clear or access areas following disasters. This may involve clearing rubble, or identifying possible locations of victims. The bot should be demonstrable of working in virtual environment showing it\u2019s decisions and processes to make a rescue attempt feasible.</p>"},{"location":"Frontier.html#feng-shui-online","title":"Feng Shui Online","text":"<p>Human\u2019s are always going to be useful when tasked with subjective problems. In Feng Shui Online you create a fun gamified physics sandbox of your room and present it to other players online to tidy. You then divide a quota of points to the players that made the best versions of your newly organised room. Does it spark joy? Keep the experience engaging so that players enjoy the process. With the data generated from the players train an AI to see if it can generalise and produce satisfying results.</p>"},{"location":"Frontier.html#project-proposals-for-2019","title":"Project proposals for 2019:","text":"<p>with Olly Powell</p> <p>VR Avatar</p>"},{"location":"Frontier.html#other-suggestions-not-used-this-year","title":"Other suggestions not used this year","text":"<p>Character Locomotion Middleware</p> <p>In today\u2019s game development world there are middleware solutions for many of the problems facing games and simulation developers. One of the areas currently dominated by bespoke programming is the area of character locomotion through an environment. Focusing on 3d applications, we would be asking a project team to create a general library allowing developers to specify and create instances of controllable objects, taking navigation directives, and within the specified movement parameters of the object, navigating the world in which it exists to reach its objective. This may involve traversing uneven or barricaded terrain, and possibly even climbing walls or traversing ceilings where necessary. The solution must have a means of connecting with animation assets to control the movements of the object. The system must support bipedal and other forms of controllable objects.</p> <p>Automatic accessibility assessor</p> <p>Today, with smart phones being such powerful computational devices equipped with cameras the opportunity to capture data from the world around us has greatly increased. This project aims to produce a piece of software which can be used on a smartphone to capture the 3d shape of an interior environment in order to produce a simplified computer model. This model may then be processed, perhaps by another device in order to produce a node graphed plan of the floorspace. This plan could provide useful views of the space in terms of accessibility and aiding planning usage of existing space.</p> <p>City generation</p> <p>Create a program that can procedurally generate a city complete with a road network and basic infrastructure. The goal is to describe methods of generation that evaluate as well networked and functional cities whether exotic or traditional. The system should be able to highlight an estimated flow of people and traffic at various times of day depending on the function of buildings, such as consumer or business locations, and positioning of public services. Heat maps for access times for ambulance and fire services for example should be available derived from the road network.</p>"},{"location":"Frontier.html#project-proposals-for-2018","title":"Project proposals for 2018:","text":"<p>Preferred? Opposing Views</p> <p>VR AI Ping Pong Trainer</p> <p>Also with Eddy Aston in 2017 eashton@frontier.co.uk</p> <p>-Simulation LOD-ing</p> <p>Level-of-detail (LOD) optimisations have a long history in rendering. 3D meshes and textures are simplified as objects move away from the camera, avoiding wasteful computation where a user can no longer distinguish finer details. There is increasing use of LOD-ing in other areas such as animation and AI routines, allowong us to simulate large, active crowds with high frequency details in the foreground. Can we use similar techniques to simulate other systems which are otherwise too complex or large to be fully computed? Perhaps a global weather simulation interacting with person-sized physics objects, or a densely populated world with interactions ranging from person-to-person up to empire-to-empire. The challenge is in finding a generalised representation of the simulation at small scales which has a stable, consistent approximation at larger scales, allowing a user to zoom to any point and see deterministic results. Can you include user input to alter the simulation, and simulate that change at different scales and over time? You may wish to do this on constrained hardware such as a Raspberry Pi, where an otherwise simple simulation may be too complex and so the gains of LOD-ing are necessary.</p>"},{"location":"Frontier.html#project-proposals-for-2017","title":"Project proposals for 2017:","text":"<p>Creature Dash</p> <p>In some video games over the years, and most notably of recent in No Man's Sky, attempts have been made to make procedural alien life forms, to give a sense of diversity and variety, yet avoiding the production difficulties of manually creating and animating such a vast range of potential life forms. A common thread in these products solutions has been to come up with a malleable connected graph that can represent a creature out of a small and finite number of given parameterised nodes.</p> <p>The challenge is to build a platform which provides a number of parameterised 'primitive parts' which may be connected together by users in building block fashion to create automotive creatures with some kind of walk, or propellant movement cycle. The users may also use other provided simple building blocks to construct 'obstacle' courses to commit their creatures to, to explore their success in navigating them, and to see which creature finishes first. Innovations involving sensors, planning, navigation and movement are welcome, but must extend the modular parameterised system, rather than being specific to an individual creature. The only rule is there must be no user interaction with individual creatures during its progress on the course.</p> <p>My version:</p> <p>VR Algorave DJ</p> <p>Why can't a DJ be more like an orchestra conductor, remixing instrumental sections and adding new expressive content, instead of simply selecting from a library of prerecorded tracks? In the future this will be possible, using a gesture controllers in virtual reality. We can provide a Myo gesture control armband. Your task is to create a VR space in which the DJs of the future will edit and configure algorave-style music synthesis programs. You can use APIs for the Sonic Pi music language from Cambridge's Sam Aaron as a back end to produce professional-standard musical results.</p> <p>VR DJ</p> <p>Virtual Reality is becoming an increasingly popular medium for computing applications, particularly in entertainment. There is currently a lot of undiscovered potential in VR, especially related to it's use in creativity and manipulation, rather than just in terms of 'experience'. This project aims to explore the more tactile and immediate possible uses for VR, to use a headset and application to create live, responsive audio/visual entertainment, through the use of virtual controls presented to the user, to allow them to mix audio, video and potentially other media presented to an audience in real-time.</p> <p>VR Minigame BuildSpace</p> <p>VR has become a serious contender in the field of video games and entertainment in the last few years. There is still limited applications for it in the this area which allow users to build and share their own games in a common virtual environment. Your task in this project will be to build on the backs of some existing technologies to develop such a space, allowing users to build operational games out of primitives, assets and rules, and potentially even collaborating to do so.</p> <p>and slightly more high level</p> <p>Plan -&gt; VR</p> <p>This project is about interpreting 2d building plans given in a commonly accepted format, and using this to produce a decorated and lit 3d environment from the plan, allowing walls and faces to be set with various materials, and so rendered as such from a palette of textures and models. The environments should be navigable via a convincing VR interface, potentially with the ability to manipulate and decorate them, from within</p>"},{"location":"Frontier.html#projects-in-2016","title":"Projects in 2016:","text":"<p>Equity Exchange</p>"},{"location":"Frontier.html#projects-in-2015","title":"Projects in 2015:","text":"<ul> <li>Planet Builder</li> </ul>"},{"location":"Frontier.html#projects-2014","title":"Projects 2014:","text":"<ul> <li>Rent-A-Mob</li> </ul> <ul> <li>Set Builder</li> </ul> <ul> <li>Multi Chat</li> </ul>"},{"location":"Frontier.html#projects-in-2013","title":"Projects in 2013:","text":"<p>Contact: Ben Nicholson bnicholson@frontier.co.uk</p> <ul> <li>A platform for live online   modding</li> </ul>"},{"location":"Fusepump.html","title":"Fusepump","text":"<p>(lauren.dawe@fusepump.com)</p>"},{"location":"Fusepump.html#2015-project","title":"2015 project","text":"<p>Retail Category Mapper</p>"},{"location":"Future_Health_and_Fitness.html","title":"Future Health and Fitness","text":"<p>The Terra API unlocks health and fitness data from diverse sources, including popular wearables and fitness apps like Fitbit, Apple Watch, Oura, and 70+ others. Your challenge is to leverage the Terra API to develop an innovative and creative product that enhances the way people engage with health and fitness data. We're looking for an application that does more than track metrics. Your project needs to inspire, motivate, and transform users' health and fitness journey.</p>"},{"location":"G-Research.html","title":"G Research","text":""},{"location":"G-Research.html#2019","title":"2019","text":"<p>Lucy.Mair@gresearch.co.uk</p> <p>Define a simple scripting language and API suitable for creating algorithms. Can enter scripts directly into an interactive game then see its performance in an actual real-time car race created with the Unity graphics engine and physics model Store &amp; rank best algorithms in a leader board, with new players able to build onto existing well performing algorithms Think how the algorithm market would extend to other problem domains.</p>"},{"location":"G-Research.html#feedback","title":"feedback","text":"<p>We had a very similar project with the same title for which your colleague Dominic Nancekievill acted as client in 2015 AI racing market. I think this is a good topic, and happy to repeat it. The proposal that came to me has a few differences from the one we agreed with Dominic. Are these things that you were specifically wanting to change, or just trying to be more concise? A bit more motivating background may be helpful, but we can certainly modify the previous description</p> <p>I think the reason that we specified Unity originally is that it might have seemed intimidating to implement a full physics engine and we hoped that giving students explicit permission to use a standard platform would help them to concentrate on novel areas. But since you are well aware of the background, I\u2019m sure that you could review the team\u2019s proposal, and give them a gentle hint if they seem to be going in an unproductive direction.</p> <p>The other change in the past 4 years is that autonomous vehicles are now an everyday topic of discussion, so there is no need to explain the concept by reference to a particular research project like the Google one. So perhaps we could modify it a little further like this:</p>"},{"location":"G-Research.html#earlier","title":"earlier","text":"<p>Contact was Dominic.Nancekievill@gresearch.co.uk</p>"},{"location":"G-Research.html#2016","title":"2016","text":"<p>Put your phone to work</p> <p>Original suggestion:</p> <p>There are around 40 million smartphones in the UK alone. That's a huge computing resource which lies unused much of the time as even today's teenagers rarely check Facebook while they sleep. Design a distributed compute framework with a central server which can split up large compute tasks into small jobs and distribute them to mobile clients. Your solution should be cross platform so using JavaScript and either running in-browser or via Ionic may be a good choice. Once you have a basic setup running with a server, client and demo distributed application there are lots of extensions to consider: How can you secure the platform so that it can't easily be stolen for use as a giant ready-made botnet? Can you come up with a business model where clients can pay for compute time and mobile phone owners are incentivised to provide it? Malicious phone owners might try to provide bad data either to deliberately attack a paying client or to increase their processing speed and therefore get paid more - can you stop them?</p>"},{"location":"G-Research.html#2015-project","title":"2015 project","text":"<p>AI racing market</p> <p>Project suggestion:</p> <p>Today's high tech financial markets provide a competitive environment in which having access to the smartest software can make the difference between success and failure.</p> <p>We would like you to create a similarly competitive environment where programs can be designed and then pitted against each other, only with rather better graphics. The software in this case will be driving cars in a racing simulation rather than placing orders on an exchange.</p> <p>Using Unity as a starting point to provide a graphics engine and physics model, your completed project should allow a competitor to sit down at an easy-to-understand interface and write a simple controller for a racing car, then at the touch of a button see that how that controller fares in a race against those of other competitors (and at least one which you've created yourselves).</p> <p>The API should be simple enough that I can knock something up in a few minutes on the demonstration day which will at least make it around the track, even if just by sticking to 10 mph and aiming for the middle of the road. At the same time there should be enough detail in the AI's view of the world to make it possible to write a truly smart driver which takes the racing line, responds to other cars and understands as much of driving as your physics model allows.</p> <p>We're always looking for ways to identify smart graduates at recruitment fairs, so if your solution works well we may ask to take it to universities around the country as a way of identifying high calibre students.</p> <p>Modified:</p> <p>AI racing market</p> <p>Projects from previous years:</p> <ul> <li>Resilient and Rapid   Raspberries</li> </ul>"},{"location":"Galapagoan_Machine_Learning.html","title":"Galapagoan Machine Learning","text":"<p>Sophia Cooke, Cambridge Conservation Initiative sophiacooke18@gmail.com</p> <p>The residents of the Galapagos Islands could be more involved in conservation research, leading to educational and business opportunities, through using their mobile phone to interact with research data. Your client has field recordings of birdsong collected from the Islands, and your task is to use this to train machine learning tools that can identify species and bootstrap locally distinctive citizen science activities. You will need to provide cloud facilities for data management and analysis, as well as phone-based client software that allows the users to contribute to research activities in ways that bring them positive educational and economic benefits.</p>"},{"location":"Game_trading_engine.html","title":"Has become Algo-Trading Game","text":"<p>Client: Radmilo Racic, IMC (Netherlands) (Radmilo.racic@imc.nl)</p> <p>Data mining and statistical modeling is an essential part of generating successful models. There are various approaches to generate a statistical model, but verification of ideas are usually standardized to a couple of criteria. In this project, the aim is to create a back-testing engine that is capable of evaluating different models according to well-known success metrics such as P&amp;L, and risk metrics like returns, alpha, beta, max drawdown and sharp ratio. The project involves efficient parallelization of experiments with parameter sweeps and visualization of the success of the models. Succinctly put, the input to this engine is a strategy and the output is a vector of success metrics mentioned above.</p>"},{"location":"Game_trading_engine.html#feedback","title":"feedback","text":"<p>I've been trying to think of a way to incorporate this into a product design problem of a kind that would allow a team to work together on different aspects of the problem, but I'm afraid I've been struggling with it. It seems like quite an interesting research problem for a single student to work on, or perhaps a pair working together, but we try to find ideas where students with a range of interests and abilities can make different kinds of contribution to a team project. We also need to keep in mind that these are only second year undergraduates, so asking them to create a novel machine learning engine that has a chance of outperforming existing algorithms may be a little ambitious.</p> <p>At present, I'm wondering whether we might be able to take elements of several of the proposals that have been coming from your colleagues at IMC, and combine these to make a single project that would be better suited to having a design team work on it.</p>"},{"location":"Gardin.html","title":"Gardin","text":"<p>Member of the Barn4 incubator</p> <p>Contact: Julian Godding j.godding@gardin.co.uk</p> <p>2022 project: Reading the Leaves</p>"},{"location":"Gearset.html","title":"Gearset","text":"<p>Introduction to Sara Turkentine sara@gearset.com</p> <p>Proposed contact for 2020, no response to email for 2021</p>"},{"location":"Genomes_are_fun%21.html","title":"Genomes are fun!","text":"<p>IlluminaKCheetham@illumina.com</p> <p>Contact: \"Oldham, Scott\" soldham@illumina.com</p> <p>Design and implement a game (on iOs and/or Android) to teach the user about genomes or genomic sequencing, targeted to a GCSE or A level science student. The game should have a strong social element to it.</p> <p>One suggested game could be bacterial genetics, where each user has a 'pet bacterium' with certain continuous characteristics, eg shape, size, ability to survive on a wide range of foodstuffs, resistance to antibiotics. Bacteria can exchange parts of their sequence (the social aspect) and the challenge is to evolve the overall fitness of your pet bacterium by interaction and exchange with others. The user can select which small part of the bacterial genome to exchange with a friend. Eventually users will be able to work out which parts of the bacterial genome define which of the characteristics and move up the leaderboard of 'fit bacteria'. (mobile apps, graphics, social networks, no background in biology required)</p>"},{"location":"Genomes_are_fun%21.html#feedback","title":"feedback","text":"<p>I was thinking about ways to add a little more technical challenge to this project. One thing I considered is that we might exploit the potential of the Raspberry Pi as a very low cost compute server to do far more extensive genetic algorithm optimisation. Each \"player\" could leave their Raspberry Pi running for a week or two, then (the social aspect) carry them to a shared location and connect them together with a network cable to exchange genetic material. I think that negotiation of an ad-hoc local network will involve a bit of low-level technical challenge (though must check this with a networks specialist), and I like the symbolism of using a physical connection to transfer the genetic material.</p> <p>Rather than bacteria, do you think we could use something more Internet-friendly? Hamster-kitten-panda hybrids or something? We could use a lot of compute power to optimise the fur :-) However, the fitness function might be a little more complex than for a bacterium.</p>"},{"location":"Genomes_are_fun%21.html#response","title":"response","text":"<p>The bacterial model fits well with the physical exchange of 'DNA'. To liven it up, users could try to make the most pathogenic/contagious/antibiotic resistant bug that can live on as many substances as possible (soil, empty coke cans, fingernails), has the most rapid growth etc. If you feel that soft and fluffy has a wider audience appeal then I'm happy for the project to be a hybrid pet or alien creature (or anything else)! Presumably the genetic algorithm can be as complex as we/you/the students choose it to be.</p>"},{"location":"Genomes_are_fun%21.html#more","title":"more","text":"<p>I had two things in mind here - one is broadening appeal, which I've been discussing with the Vet School in Cambridge lately, and the other is that I'm reluctant, in educational contexts, to suggest that genetic algorithms work in very much the same way as actual biological processes. Use of more playful examples (or as you suggest, \"aliens\"), may help to avoid this - whereas using bacteria may give the impression that we're building an actual biological model.</p>"},{"location":"Genomics_for_the_COVID_Endemic.html","title":"Genomics for the COVID Endemic","text":"<p>dan@geromics.co.uk</p> <p>Open genomics provides an opportunity for members of the public to engage directly with genomic health research including Genome-Wide Association Studies (GWAS). Now that the emergency response phase of the COVID pandemic is settling into management of endemic infections and their consequences, there are many opportunities for members of the public to contribute to such studies. The goal of this project is to develop an interactive genome report that keeps members of the public informed, and even allows them to participate as citizen scientists in ongoing investigations of the many consequences of COVID.</p>"},{"location":"Giving_Voice_to_Digital_Democracies.html","title":"Giving Voice to Digital Democracies","text":"<p>GVDD is a project team based at CRASSH</p> <p>Brief written, waiting to confirm client: Deliberative Social Media</p> <p>Potential second project: Marcus Tomalin mt126@cam.ac.uk suggested:</p> <p>How about one of the following?</p> <ul> <li>Developing NLP-based Visualisation Tools for Data Statements -- i.e.,   taking the notion of data statements (e.g., Bender and Friedman 2018)   as a starting point, develop a suite of NLP-based tools that would   enable biases in language-based corpora to be displayed visually</li> </ul> <ul> <li>Developing Interactive Data Statements -- -- i.e., taking the notion   of data statements (e.g., Bender and Friedman 2018) as a starting   point, develop an interactive version of a data statement that enables   the person using the data to ask and receive answers to (a constrained   set of) questions about the data</li> </ul> <p>These are both ideas that we have discussed within the GVDD group, but we haven't focused on thse specific tasks yet (mainly because we were unable to hire a coder over the summer).</p> <p>Both these projects could be constrained in ways that made them approachable for students, but they could also become as complex as the students wished.</p> <p>Feedback:</p> <p>I have already been discussing the broad area of dataset bias with a research fellow at Microsoft Research Cambridge, who is looking at global cultural and economic bias in training of machine vision systems. Are you familiar with \u201cmodel cards\u201d, which appear similar in their intention to \"data statements\u201d as advocated in the Bender and Friedman paper? A recent application of model card approach in response to the recent \u201cwhite Obama\u201d scandal is described here:</p> <p>https://thegradient.pub/pulse-lessons/</p> <p>I think there are a number of potential approaches to anticipating, illustrating and correcting data set bias, but this is a fairly active research area, and I suspect that the specific domain of application for the data set may produced considerable differences in the most appropriate design responses. Is there a particular area (with publicly available datasets) that you think might be appropriate for computer science undergraduates to work on?</p>"},{"location":"Global_Ground_Truth.html","title":"Global Ground Truth","text":"<p>Local people in rural areas have valuable knowledge about climate change effects and adaptation, but it is not straightforward to integrate their observations into scientific evidence and policy frameworks. Your task is to create a trusted infrastructure that integrates reports from local people (including photos and voice recordings to be translated as necessary) into a secure evidence blockchain. The client tools must run on low-end android phones, and be accessible to people with low literacy. Processes for authentication and standardisation should respect traditional authority, cultures and rights of indigenous people, and expert advice will be available from the International Centre for Climate Change and Development (ICCCAD) in Dhaka.</p>"},{"location":"Google.html","title":"Google","text":"<p>Contact is Robert Harle</p>"},{"location":"Google_UK.html","title":"Google UK","text":"<p>Google UK</p> <p>&lt;https://google.com&gt;</p> <p>Client: Alex Wilson</p> <p>2020 project: Workout Help with Android and WearOS</p>"},{"location":"Grakn.html","title":"Grakn","text":"<ol> <li>REDIRECT Grakn Labs</li> </ol>"},{"location":"Grakn_Labs.html","title":"Grakn Labs","text":"<p>https://grakn.ai</p> <p>2020 project: Testing a Logical Query Language</p>"},{"location":"Grand_Remote.html","title":"Grand Remote","text":"<p>rob.sinclair@nhs.net</p> <p>Grandparents and children both enjoy a quick chat, but often live too far apart for regular opportunities. Older people also have challenges with remote technology such as IoT, security devices, or media systems. You can solve both problems in one, with a new universal remote that establishes a voice channel to an available grandchild who can help complete a control function through network redirection, automation or scripting of commands while also providing regularly scheduled social contact. Your remote app should be highly usable by people with visual, motion control and memory impairments, while also being compatible with a wide range of IoT and media devices.</p>"},{"location":"Graphical_Programming_for_Budding_Engineers_on_Raspberry_Pi.html","title":"Graphical Programming for Budding Engineers on Raspberry Pi","text":"<p>Contact: Milos Puzovic Milos.Puzovic@mathworks.co.uk</p> <p>Model-Based Design (MBD) is a prevalent methodology that is used in complex control, signal processing and communication systems to address problems that arise during their design. Engineers in, for example, aerospace and automotive industries use MBD to define models that have advanced functional capabilities by pictorially combining well-defined building blocks and describing communication between them. Unfortunately school children are not exposed to MBD at an early age and as a result do not grasp how engineering is made enjoyable and rewarding by tinkering with combinations and communications between building blocks. Your task is to design a light-weight interface that can run directly on Raspberry Pi that will enable school children to write applications that can seamlessly use the underlying hardware and peripherals connected to the Raspberry Pi. You will need to identify basic building blocks that will make school children interested in your interface and are powerful enough to create applications that a child's mind may envision. Finally, you should be able to demonstrate how easy it is to create an application using your interface that is eye catching, such as tracking the movement of a yellow duck toy.</p>"},{"location":"Grasping_Concept_Spaces.html","title":"Grasping Concept Spaces","text":"<p>Today's most powerful machine learning models, including generative AI LLMs like ChatGPT, encode their knowledge as higher dimensional latent spaces. Vector-based concepts in that space can be clustered as regions on a 2D screen, for example using the t-SNE visualisation algorithm. Your task is to create a 3D version of t-SNE that is interactive, so users with VR headsets can literally \u201cgrasp\u201d a concept, and manipulate it to explore, fine-tune, or adjust the machine learning model.</p>"},{"location":"Green_Eyes.html","title":"Green Eyes","text":"<p>laurens.vandam@imc.com</p> <p>We live in a consumer society, often buying more things than we really need. Everything we buy has some environmental impact. For example, it takes 2700 litres of water to make one cotton T-shirt. If your garment is made out of polyester, it will take it 20 \u2013 200 years to decompose. We could all benefit by reducing our environmental impact by buying fewer things or by buying things that are more environmentally friendly. Your task is to develop a HoloLens application that evaluates the impact of an item on the environment given a picture of the item.</p>"},{"location":"Green_Maps.html","title":"Green Maps","text":"<p>pasquale.giovenale@imc.com</p> <p>In an effort to tackle climate change, we would like to reduce our carbon footprint. Therefore, we want to offer people insights into the carbon footprints of various transit options. Your task is to develop a system which finds routes using various transport types (cycling, car, train, plane) and computes the costs, travel time and carbon footprints of them. In the end, the user can then make an informed decision on what mode of transport to take.</p>"},{"location":"Groundwater_App.html","title":"Groundwater App","text":"<p>Survey](British_Antarctic_Survey \"wikilink\") mmuller.earthsci@gmail.com</p> <p>British Antarctic Survey has developed a compact ground-penetrating radar for measuring melt rates at the base of ice-sheets. In principle, the same device can be used to locate groundwater in arid regions, guiding borehole drilling and supporting groundwater management. Your task is to create an app that runs on a smartphone, able to take data from the radar equipment and estimate groundwater depth. You will have access to a variety of signal processing research algorithms (in Matlab) that process the radar data at present, and your code may involve translations, adaptations or refinements of these. Your software should provide simple visualisations to help nontechnical users control the system and interpret its output, and also make use of the phone storage for \u201csneakernet\u201d transfer of data to servers for more intensive cloud-based analysis by technical specialists.</p>"},{"location":"Guitar_tab2hand.html","title":"Guitar tab2hand","text":"<p>Guitar tabs are a simple and popular alternative to music notation for guitar students, as well as guitarists and bassists in cover bands. The tab tells you where each string needs to be held, but not how to get enough fingers into the right places. That requires a clever algorithm, perhaps AI-assisted. Your task is to build an app that automatically converts tabs, from sites like ultimate-guitar.com, into a 3D animated hand that shows a student how to hold their hand on the fretboard.</p>"},{"location":"Hamilton_Kerr_Institute.html","title":"Hamilton Kerr Institute","text":"<p>Spike Bucklow sb10029@cam.ac.uk</p> <p>2021</p> <p>Spike says: \"Digital stuff is now a very small part of my work - I have a Leverhulme project doing machine learning with DAMTP - but I'm not sure what I could come up with for your students. And we don't have any interns like Camille this year because of covid so I can't ask anyone else to come up with a project either. Sorry.\"</p> <p>2019</p> <p>Could follow up exchange with Kasia Targonska-Hadzibabic kt441@cam.ac.uk, who suggested doing some content analysis of paintings. This could apply methods from recent PhD or Leonardo Impett.</p> <p>2018</p> <p>Project with Camille Polkownik cp574@cam.ac.uk (now left Cambridge)</p> <p>Pigment Analysis</p> <p>2017</p> <p>Proposal for a student project Build an Interactive and Intuitive Tool to Assist Art Conservators in Pigment Analysis</p> <p>The Project</p> <p>Build an interactive tool (website or app) that would enable conservators to identify pigments through their microscopic characteristics. The reason why we would like to make this a student project is that this educational tool would be in online and in free-access . It would benefit students and recent graduates in conservation as well as older conservators who use polarised light microscopy every now and then and need the support. It also offers the IT student a collaboration with professionals and most of all, a multidisciplinary experience .</p> <p>How are pigments analysed?</p> <p>As of 2017, various methods are available to analyse pigments. To cite a few, there is: x-ray fluorescence (XRF), Macro X-ray fluorescence (MA-XRF), SEM-EDX (Scanning Electron Microscopy with Energy Dispersive X-Ray analysis), FTIR (Fourier transform infrared spectroscopy). The major drawback with all these methods is the price: they are expensive to acquire and need specific knowledge of the machine and its limitations. Another method to analyse pigment exist: polarised light microscopy (PLM). It has the potential of solving problems confidently and quickly , as the sample set-up and analysis can be done under 15-20 minutes. Plus, the investment is minimal , one needs a hot plate and glass slides for the mounting of samples and a good microscope.</p> <p>What is currently available to support pigment analysis? - Flowcharts (paper): very rigid . If one characteristic is missed then it is impossible to go on. - McCrone Atlas ( www.mccroneatlas.com ): not adapted for historical pigments. - Pigment Compendium: dictionary, not an analytical tool . (Eastaugh, N., Walsh, V., Chaplin, T., and Siddall, R., 2004. The Pigment Compendium: Dictionary of Historical Pigments , Oxford: Elsevier Butterworth-Heinemann)</p> <p>Who would use the interactive tool?</p> <p>The survey done in July 2017 received 226 responses, mostly from conservators interested in the project and sharing they would like to have access to such a tool. A few even offered to test it for us before the launch. Interviews with conservation students and emerging and settled conservators alike showed that such a tool would be welcome and would provide support which would itself bring more confidence.</p> <p>How is the tool different and useful? The tool would work as a deconstructed flowchart : the conservator can start with whichever characteristic he/she wants. The more characteristics you enter, the few options are presented, narrowing the search. This is more intuitive and allows more freedom as the analysis is not always straightforward.</p> <p>Additional information - The content is being written up by myself, based on available information in the Pigment Compendium and information from flowcharts. - The website/app would be supported by the IT staff from the Fitzwilliam Museum and would be hosted at the Hamilton Kerr Institute in Whittlesford. - The design, amongst other things, would be up to the student and every aspect would be discussed to produce the most accurate project.</p>"},{"location":"Hashtag-FollowTheMarket.html","title":"Hashtag FollowTheMarket","text":"<p>Sentiment analysis of social media is now fairly routine, but it's still relatively new in the world of finance. Coupling popular sentiment with market data could provide a very useful tool for financial decision makers. Your task is to derive sentiment data from Twitter and present its relationship to market data in a tool for traders to test their knowledge of the market. The user selects a date range and a stock, and is then asked to sketch a graph of how they believe popular sentiment and stock price trends behaved over that time. The system gives visual feedback, and awards a competition score based on comparison to the actual data. This system might be used simply for practice and training, or as a game for would-be traders. But in the long term, statistical data showing the ways in which the judgments of real traders predict (or lag) Twitter trends might provide an extremely valuable product!</p>"},{"location":"Heroes_in_Conference.html","title":"Heroes in Conference","text":"<p>mark.ogilvie@jagex.com</p> <p>Even the best conferences and conventions experience a slump where engagement declines. Your job is to design and prototype a mobile AR experience to keep conference attendees interested - using gamification and social techniques to bring attendees together, predict and counter the slump, as well as providing a novel way to deliver key information about the event. This should be offered as a downloadable app that supports the 2019 public show for the group projects, and also shows the potential to support RuneFest 2019, the JAGEX convention that\u2019s all about RuneScape.</p>"},{"location":"Heterodox_Economic_Modeller.html","title":"Heterodox Economic Modeller","text":"<p>Christopher Newfield, Independent Social Research Foundation chris.newfield@isrf.org</p> <p>There is a long history of financial simulators that can be used to model national economies, dating back to the water-powered \u201cPhillips machine\u201d (we have one in Cambridge). Today\u2019s economy is stuck in a rut, because alternative economic theories are proposed by people whose mathematical models are simply less well embedded than the legacy implementations. Your task is to create a quick and dirty financial simulator that could be used by heterodox economists to propose and debate serious alternatives to outdated government and corporate policies.</p>"},{"location":"High_speed_password_bypass.html","title":"High speed password bypass","text":"<p>Many companies ask users to create a unique user account and password for systems whose security the user couldn't care less about. Sometimes it can be faster to just click \"forgot my password\", and use the emailed reset link rather than the login page. Your task is to make a super-fast login bypass procedure by automating this process, with a custom web/email client that will automatically trigger the forgotten password facility in any URL it receives, then take care of the reset process (using the user's securely stored email account credentials) to navigate the login process without having to bother with inventing a real password.</p>"},{"location":"History_Phone.html","title":"History Phone","text":"<p>ip331@cam.ac.uk</p> <p>There are historic objects around the Gates building that have stories to tell - if only they could speak! Imagine walking up to one of the display cases (like the one to the right of the front door), and using your phone to start a chatbot session as if you were speaking to the object itself. We will provide Bluetooth location beacons so that an Android phone can detect which object it is near. Your application should respond to questions, and maintain a conversation, with style and content that is customised to each object. The project team will have a chance to visit some of the famous museums elsewhere in Cambridge, to learn how curators design interactive content.</p>"},{"location":"History_Scraper.html","title":"History Scraper","text":"<p>david.russell@altfusion.co.uk</p> <p>The Cambridge University Map supports a sophisticated annotation API, based on GeoJSON. Your task is to create an interactive application that allows users to relate the research and technology of locations in contemporary Cambridge to the things that happened in those places in earlier historical times. The Talks.cam system has an API that can be used to gather information about what is being discussed in a particular location right now. You'll need to find some alternative sources of information for the events of 100 or 1000 years ago. To engage users, your goal is to give a seamless interaction - overlaying with swipe, pan and zoom to peel down the past, or scrape off the present, in a kind of virtual archaeology.</p>"},{"location":"Hololens_Escape_Room.html","title":"Hololens Escape Room","text":"<p>Escape Room facilities are popular for student social outings and professional team building, but the props and decorations needed to create an engaging theme are difficult to move from place to place. Your task is to create an authoring tool for Hololens that can be used to turn any physical space into an escape room, using only simple portable apparatus. Using holographic projections, clues and puzzles should be provided that the player must navigate in order to unlock the exit. The Hololens can be connected to a screen to share the vision of the wearer to the other players. IMC will provide one Microsoft Hololens.</p>"},{"location":"Home.html","title":"Home","text":"<p>Go to [[index]] to get to the root file of this wiki.</p>"},{"location":"Household_Payment_Pool.html","title":"Household Payment Pool","text":"<p>richard@bigpayme.com or James Hinshelwood</p> <p>Routine financial responsibilities can be more pleasant if a small amount of chance is involved, for example UK Premium Bonds, which distribute interest as monthly prizes with an average rate of return comparable to other government-backed investments. This project aims to create a personal finance game in which housemates (or larger groups) can exchange transactions. When you spend money, the transaction will be charged to some random member(s) of the group - possibly split. An important constraint is that you should never be charged more money than you would otherwise have spent in a given period (tunable by either you or the group). Design suitable rules and build a UI and transaction recording system that allows people to play this game.</p>"},{"location":"IBM.html","title":"IBM","text":"<p>Kevin Males Kevin.Males@uk.ibm.com Phil Rodgers Phil.Rodgers@uk.ibm.com</p> <p>May be Raspberry Pi related?</p> <p>Client nominated: Luke Morgan MORGANLU@uk.ibm.com</p> <p>Proposal: Password and privacy protection with Pi</p> <p>Few children (or even adults) really understand what makes a password secure, or how to keep their online information safe. Your task is to create a simple set of password cracking and message encryption/decryption tools that children can run on the Raspberry Pi, together with a scripting language or GUI for them to run simple statistical experiments to understand what factors make their messages more secure. Children love code-breaking, so it should be easy to make this into an entertaining Raspberry Pi game, not just boring school work.</p>"},{"location":"ICCCAD.html","title":"ICCCAD","text":"<p>International Centre for Climate Change and Development</p> <p>https://www.icccad.net</p> <p>Contact: Ali Mohammed Rezaie, local contact in Cambridge Alec Christie</p>"},{"location":"IMC.html","title":"IMC","text":"<p>Careers Europe CareersEurope@imc.com</p>"},{"location":"IMC.html#2023-projects","title":"2023 projects","text":"<ul> <li>ModularSynth.io</li> </ul>"},{"location":"IMC.html#2022-projects","title":"2022 projects","text":"<p>Plan to propose three, for selection of two</p> <p>Admin contact for 2022 will be Sanne Cuperus Sanne.Cuperus@imc.com</p>"},{"location":"IMC.html#2021-projects","title":"2021 projects","text":"<p>Confirmed:</p> <ul> <li>Aerial Video Selfies</li> </ul> <ul> <li>Remote Reading</li> </ul> <p>Original suggestions from Ben Catterall ben.catterall@imc.com:</p> <p>Drone assisted filming Drones have become an essential tool for many filmmakers, but they require manual control usually from additional staff as the subject cannot operate the drone themselves. This constraint also limits the number of perspectives that can be captured in a scene to the number of pilots available. There is great value in reducing the required number of staff as well as capturing multiple views on a single scene without hassle. A swarm of drones that are aware of their surroundings, including each other, and basic cinematography setups could achieve such results. Develop a solution for capturing video recordings of moving subjects such as a cyclist or rower from multiple drones. The drones should be aware of their surroundings, make sure to avoid filming each other and to deliver tasteful and usable footage. A minimum viable product would consist of a drone filming and following an object, perhaps using a Bluetooth tracker. Support for more drones, each providing footage with a specific perspective, could then be added as an extension. You will be provided with a drone.</p> <p>Smart Fridge Food waste is a major part of the impact of agriculture on climate change, amounting to between one-third and one-half of all food produced. This problem can be tackled at home, by reducing the amount of out-of-date food that is thrown away. Your task is to design a device that helps users manage the food in their fridge. It should notify users when food is about to go out of date, assist them with finding tasteful recipes for using their food, and consequently help them reduce their food waste. You will be provided with a tablet.</p> <p>Remote reading The ability to read is the foundation of a person's education, transforming children into life-long independent learners. Especially in the early stages of learning, human-to-human interaction is critical to the teaching process.</p> <p>The focus of this project is to design an interactive remote reading app. It should enable children to connect with their teachers and/or family members by allowing them to read a story together. This project will likely involve designing an interactive reading interface, as well as building the back-end video/audio streaming service. Possible extensions can include support for multiple languages with live translation to better connect non-native speakers and/or facilitate language learning. You will be provided with a tablet.</p>"},{"location":"IMC.html#2020-projects","title":"2020 projects","text":"<p>Confirmed:</p> <ul> <li>Green Eyes</li> <li>Trading Assistant</li> </ul> <p>Three possibles in discussion:</p>"},{"location":"IMC.html#develop-a-voice-assistant-for-trading","title":"Develop a voice assistant for trading","text":"<p>Not all the trading happens on exchange, sometimes counterparties trade directly, with human-to-human communication. For such trading humans use their most natural interface - voice. What is our purpose? We want to automate one side of the process using modern technologies (voice recognition, natural language processing and voice production). What will be my task? Create a service which holds market data and shares the data on demand in a human-like manner.</p>"},{"location":"IMC.html#green-eyes-develop-environmentally-aware-goggles","title":"Green eyes: Develop environmentally aware goggles","text":"<p>We live in a consumer society, often buying more things than we really need. Everything we buy has some environmental cost. For example, it takes 2700 liters of water to make one cotton T-shirt. If your garment is made out of polyester, it will take it 20 \u2013 200 years to decompose. What is our purpose? It would be great if we were all a bit more aware of the impact we can have on the environment by buying less things or buying things that are more environmentally friendly. What will be my task? Develop a HoloLens application that given a picture of an item calculates the impact of that item on the environment.</p>"},{"location":"IMC.html#the-ocean-cleanup","title":"The Ocean Cleanup","text":"<p>Over 5 trillion pieces of plastic currently litter the ocean. The largest collection is in the Great Pacific Garbage Patch. Unfortunately, such statistics are rather intangible. What is our purpose? We want to bring home to people how devastating the impact on our actually oceans is by letting them experience it themselves. What will be my task? Design a virtual reality experience of the collection process allowing users to interact with the rubbish collected by System 001.</p>"},{"location":"IMC.html#2019-projects","title":"2019 projects","text":"<p>Two projects confirmed:</p> <ul> <li>Eyes on the Road</li> </ul> <ul> <li>Eyes in the Sky</li> </ul>"},{"location":"IMC.html#previous-discussion","title":"(previous discussion)","text":"<p>If the program allows for it, we would like to be the client for two groups again this year as we would like to give this an extra dimension by soft-linking the two projects together:</p> <ul> <li>Group 1 would design a project where the output is a driving   mindstorms car (we are contemplating a project driving a car with VR   experience - storyline remote driving a car).</li> </ul> <ul> <li>Group 2 would design a project where the input is a driving mindstorms   car (we are contemplating a project with a drone following a car with   wifi/bluetooth/visual beacon - storyline safety monitoring of high   value transport).</li> </ul> <p>The success of the groups does not depend on each other (we have multiple mindstorms sets). Both projects can be developed, presented and demonstrated independently but a combined demonstration (probably not during the public demonstrations sessions) would be awesome!</p>"},{"location":"IMC.html#2018-projects","title":"2018 projects","text":"<p>Wearable house control</p> <p>Autonomous highway system</p>"},{"location":"IMC.html#earlier-discussion-for-2018","title":"Earlier discussion for 2018","text":"<p>\u2022 Automated Highway System</p> <p>Highway congestion is a never ending problem. One way to increase the throughput of the highway is to group vehicles into platoons to shorten the distance between two consecutive cars. Further advantages of vehicle platooning are decreased fuel consumption and emissions and increased safety and comfort. Design an automated platooning system in which multiple vehicles autonomously follow the leader. Safety is of paramount importance, each vehicle should do its best to avoid collisions.</p> <p>Tools: 3 - 4 sets of Lego Windstorms Responsible: Jan Kis jan.kis@imc.com</p> <p>Feedback: It looks like fun, and autonomous vehicles are a timely area of interest. It\u2019s nice for both students and the demo day audience to have something concrete to see, so I\u2019m certainly happy to base something on Mindstorms. However, we had a swarm robot project last year, in which relatively trivial issues (mechanical reliability, sensor accuracy, battery charge cycles) dominated the computing questions. I wonder if we might consider a hybrid system design, in which the students simulate larger platoons in software, and build a mechanical testbed (still using Lego) to evaluate or calibrate the inter-vehicle dynamics?</p> <p>\u2022 Autorad</p> <p>A recent article in New Yorker magazine has explored the triumphs of algorithms in the diagnostic arena. Teleradiology is generally regarded as being the forerunner in employing technology to automate and streamline workflows to better quality of care, more accurate diagnosis and better treatment outcomes. Design a service that would receive DICOM studies and identify Subdural hematomas in CT scans and return its findings. This service would serve as a diagnostic assistant to a radiologist and provide a second level of confidence on the findings. All relevant DICOM data should be extracted and used to create studies and associated reports. Bonus: Ascertain the technical accuracy of the scan (position, dosage etc)</p> <p>Tools: An extensive medical image source is required for this project. Responsible: Arindam Paul arindam.paul@imc.com</p> <p>Feedback: If I understand correctly, the core of this appears to be a relatively straightforward computer vision application, which would require training with a substantial dataset of segmented and labelled images. Did you have access to a suitable dataset, or would we need to find a source?</p> <p>\u2022 GreenPi</p> <p>Large-scale agriculture has the unenviable task of feeding the world\u2019s ever-expanding population which is gradually headed towards unimaginable numbers. Food as we know it today will become a scarcer and far more expensive commodity. Sustainable home gardens can make a difference like all small measures do but not all of us have the privilege of the space required. With solar panels, raspberry pi\u2019s, fans and other sensors create a small greehouse that could be packaged and sold for an affordable amount. The kit should be easy to setup and mostly automated in its operation besides the initial setup effort. There should be an accompanying app/web page to guide the user through setting up the greenhouse and monitoring all its operations and health of the plants inside. Given the time challenges of this project I propose growing radishes, green beans and peas</p> <p>Tools: All required sensors, solar panels and raspberry pi kits will be supplied Responsible: Arindam Paul arindam.paul@imc.com</p> <p>Feedback: Are you a keen gardener? As you note, timescale is a problem - what kinds of plants grow indoors in February? I suspect that the control regime for successful plant growing is fairly simple - the more light the better, and water delivery to maintain optimum water content. Could we perhaps use one or two larger plants, and do more intrusive condition monitoring (tissue conductivity, internal water content, mechanical properties of the plant fibres)?</p> <p>\u2022 Smart House</p> <p>Over the last years smart IOT hardware has become main stream and affordable to consumers. Commonly seen smart electronics in average households may consist of smart lights, smart solar panels, smart curtains or smart thermostats. Together with a smart hub a consumer can control all smart devices. However, the smart devices only perform their own tasks and are unaware of other devices. A smart house should combine multiple smart devices. Create a service that controls all smart devices together. For example, download sun rise and sun set times and automatically switch on lights and close curtains. There should also be a UI that can be loaded on a web browser or as app for mainstream OS'es.</p> <p>Tools: IOT hardware / smartwatch Responsible: William Bakker william.bakker@imc.com</p> <p>Feedback: This is a rapidly growing area, with products such as IoTool and IFTTT delivering this kind of generic functionality. We might want to think of a slightly more specific use case, or interaction approach, selected for convenient demonstration to the audience we will get at our public event in March. From experience, this means avoiding room thermostat functionality (because it\u2019s hard to vary the temperature of our room) and other functionality with time constants greater than a few minutes (so not relying on sunset time etc). I noticed with interest your idea to integrate smartwatch functionality - I wonder whether we might shift this toward some kind of body-based (single user) or collaborative (multi-device) policy specification language. Did you have a particular smartwatch model in mind?</p> <p>\u2022 Geographical Pattern Recognition</p> <p>Within the next few years, 5G will be the successor of 4G. This introduces the need for new placement of transmission towers. The United Kingdom has been fully covered by high quality satellite images. This opens the opportunity to optimize this placement problem. Analyze the geographical properties from the satellite images where to find suitable locations. Then, cross reference with average property prices to determine the optimal location. The user interface should show a graphical overlay of signal coverage and cost.</p> <p>Tools: (license for) high quality satellite data. Responsible: William Bakker william.bakker@imc.com</p> <p>Feedback: I\u2019ve had an intern this summer using UK government open data from Ordnance Survey, which might be more appropriate than satellite imagery. However, they have struggled with licensing terms. Data is available for free, but via interfaces built to resist large-scale scraping. I like the idea of optimising by property price - perhaps you were thinking of cost of acquiring land for tower placement (though my experience is that planning permission, rather than land acquisition, is the main constraint). Perhaps even more interesting would be to optimise coverage according to the income of the people who live there, and charge higher rates for the service? A geographical auction optimisation algorithm seems pretty interesting.</p> <p>\u2022 Proof-of-work for crypto currencies</p> <p>A proof of work is a piece of data which is difficult (costly, time-consuming) to produce but easy for others to verify, and is used to define the requirement for the generation of a new set of transactions (\"block\") to be added to a distributed transaction database (\"block chain\"). In the case of Bitcoin this is a hash algorithm (\u201chashcash\u201d) which requires a minimum level of computing power to solve. This is referred to as the process of \u2018mining\u2019 which ultimately controls the rate of deflation/inflation of the crypto currency. The Bitcoin mining concept is not completely without risk, eg what happens if the cost of mining would increase significantly due to fossil power shortage, or mining has become extremely easy with the use of quantum computers? As proof of work can be anything, we\u2019d like the students to come up with a new, original and difficult to solve problem which can be used to add new blocks to the block chain. It should require effort to do, protected from exploitation and sustainable over time.</p> <p>\u2022 Block chain for OTC trading</p> <p>Another idea we discussed was to use the Etheruem platform, and set up a private net, which can be used for OTC (Over The Counter) trading. OTC, or off-exchange, trading is directly between two parties and often non-electronic. Therefore likely to result in discrepancies between buyer and seller of what was really agreed as part of the trade. A platform based on an immutable block chain mechanism completely reduces this risk including the need to reconcile after the fact between buyer, seller and the clearing bank.</p> <p>Design your own crypto currency Alternatively we could ask students to define a new crypto currency from scratch, although that might be a lot.</p> <p>Responsible: Renier Eijkelestam \u2013 renier.Eijkelestam@imc.com</p> <p>Feedback: Your proposals to work with block chain technologies seem a good idea to me, and likely to inspire students. We did include a block-chain based design brief two years ago, with your colleague Jan Kis (copied here) as the client, but perhaps a little ahead of the curve at that time, and students struggled to come up with an innovative concept. You might be interested to compare the design brief that we used then: https://wiki.cam.ac.uk/cl-design-projects/Digital_Currency_for_Public_Good</p> <p>I still like the idea that proof-of-work can be something that delivers public good, as opposed to the Bitcoin proof-of-work, which seems designed expressly to waste natural resources on as large a scale as possible. Do you think that we might be able to come up with a concept along these lines? If you see Jan, you might ask his opinion. I agree with your specification of requirements as the need for a \"new, original and difficult to solve problem\u201d. It\u2019s a great research challenge, but experience is that these undergraduate teams need a little more guidance (or constraint) toward a particular direction.</p>"},{"location":"IMC.html#2017-proposals","title":"2017 proposals","text":"<p>Confirmed:</p> <p>Hololens Escape Room</p> <p>More ideas:</p> <p>Neural Guide</p>"},{"location":"IMC.html#24000-words-per-second","title":"24000 words per second","text":"<p>Ben Catterall : ben.catterall@imc.com</p> <p>Many fields in machine learning, from image recognition to machine translation have recently received a tremendous boost using deep learning. Deep architectures have sparked a renewed interest in artificial intelligence, and resulted in a lot of cool applications. It has also arrived together with a new wave of peer-reviewed research, where people share and publish all of their code online. Most big companies race to provide their pre-trained models online for free. In this project we will focus on automatic video captioning, and the aim is to build a prototype system for a real-time captioning system, using already published research. The resulting product could be used by visually impaired people, or to create automatic tags on instagram.</p> <p>Feedback:</p> <p>Quite a lot of our students enjoy playing around with pre-trained deep neural nets, so this is certainly feasible. However, it seems at present like a one-person project, and would have to be expanded to suit work from a team. We already have some projects planned for this year that involve training a deep net, but this involves some ingenuity in identifying suitably labelled training data, as well as getting hold of a machine suitable for running the GPU-intensive deep learning frameworks that are currently popular.</p> <p>Do you want to provide a reference to the specific piece of published research that you thought might be applied, and we can see where we might go from there?</p> <p>Response:</p> <p>The image captioning is from Andrej Karpathy:</p> <p>http://cs.stanford.edu/people/karpathy/deepimagesent/</p> <p>I think in order to create an interesting application from this research, we can extend the problem to include audio captions through a mobile application. The students will have to:</p> <p>- Write a server application that accepts images, and produces captions - Convert captions into audio files - Write a mobile application which shoots images and uploads to server - Replays the audio that comes back from the server</p> <p>I believe this is already not a one person project.</p> <p>If you want we can further extend the project to include training of custom captions as well. This can be used to train an 'audio guide' for a particular location for example. We can even think about creating a meta-trainer which receives images and captions for a particular building(museum, or even the computer lab), and automatically forms an audio guide. But personally, I think we are entering a dangerous area, where the project becomes prone to failure.</p> <p>More:</p> <p>My understanding is that it\u2019s relatively straightforward to run the Karpathy libraries on novel images using one of their trained models. I agree that it would be much more of a challenge to collect a sufficiently large dataset (and computational resources) to train your own model.</p> <p>As you say, there is far more chance of failure if doing something other than image labelling, which is already a research topic rather than a design project. Nevertheless, we are taking a chance on this with the project brief I sent you - and I\u2019m hoping that looking at text rather than image encoding will make that one feasible. I got one of our machine learning profs to check it out for sanity.</p> <p>I would have thought that converting the captions into audio is also an API-calling job, rather than involving any substantial software engineering. I\u2019ve used Festival for this: http://www.cstr.ed.ac.uk/projects/festival/</p> <p>I think the issue with both deep learning image recognition techniques and speech synthesis is that in both cases, there are fairly good libraries and APIs that allow you to create acceptable results with a few lines of Python, while any improvement over the off-the-shelf libraries is way beyond the capability of undergrads.</p>"},{"location":"IMC.html#neural-networks-in-fpga","title":"Neural Networks in FPGA","text":"<p>Taylan.Toygarlar@imc.com</p> <p>We are entering a new era in computing, where the services provided are becoming more and more dependent on machine learning and artificial intelligence, with deep learning at the forefront of this new gold-rush. The introduction of deep learning architectures were only possible due to the use of GPUs, and they have done a great job training more and more complex models. However, FPGAs offer huge benefits over GPUs in terms of power savings, which is crucial when web-scale applications are considered. There are many exciting developments in this field, but unfortunately, contrary to GPUs, there are close to no public tooling available for FPGAs. We would like to develop a code generator, which takes as input a commonly used neural-network definition file, and spits out fpga code. This project could potentially help fuel the next generation systems for which all of us interact with daily.</p> <p>Feedback:</p> <p>I've discussed with a couple of the staff who teach our hardware course, and they confirm that the dev boards the students use do have FPGA that might be used here.</p> <p>I wasn't suggesting online learning - rather that they might see how fast they can train a simple image classifier.</p> <p>Our research team have recently implemented something along these lines. Here are some relevant papers:</p> <p>Neural nets in custom hardware: http://www.cl.cam.ac.uk/~atm26/papers/fccm2012-bluehive.pdf</p> <p>Custom hardware v vector processing http://www.cl.cam.ac.uk/~atm26/pubs/FPL2013-BlueVec.pdf</p> <p>Video and background http://www.cl.cam.ac.uk/research/comparch/research/bimpa.html</p> <p>An undergrad group could perhaps work with their code, rather than build something from scratch?</p>"},{"location":"IMC.html#shelved-for-2017-tamagotchi-brief","title":"Shelved for 2017: Tamagotchi Brief","text":"<p>Jan Kis : jan.kis@imc.com</p> <p>(\u2018Creative\u2019) Pokemon Go took the world by storm. Now it\u2019s your turn! Remember those cute, egg-shaped devices with the dancing critters you all played with when you were younger? Well, this task will involve the exciting opportunity of creating an interactive online Tamagotchi world! Your aim is to entice users to explore the fascinating concept of optimal parameter selection, critical to many real world problems such as Machine Learning and automated trading, through their Tamagotchi\u2019s. Develop a mobile application allowing users to view their Tamagotchi and exchange limited resources with each other by agreeing a fair value for their exchange. Once acquired, users should be able to modify the appearance of their Tamagotchi using these resources. Users will thus need to carefully optimize their basket of resources to build their ultimate Tamagotchi. They want to recreate that incredible wig they saw at last night\u2019s bop but only have two bundles of cloth? Well, they trade six spindles of thread for two bundles of cloth, apply some suspect sowing skills and ta dah!</p> <p>(Formal) Optimal selection of parameters is an important aspect of many exciting real world problems from Machine Learning to automated trading in world markets. This project aims to get users to explore this concept. The task is to build an interactive online mobile application to enable users to view and build their ultimate Tamagotchi. Users will need to exchange limited resources with each other by coming to an agreement about a fair value. These resources can then be used to alter the appearance of their Tamagotchi. Consequently, users will need to carefully select their optimal basket of resources.</p> <p>Feedback:</p> <p>Thanks for your \u201cTamagotchi\u201d suggestion for the Cambridge design project course. Sorry that I\u2019ve left yours to last \u2013 I have been discussing other projects with your colleagues that were either more obvious or more problematic.</p> <p>My initial reaction was that current undergraduates might be unlikely to remember Tamagotchi, so an alternative creature focus might have been necessary. Pokemon would be the obvious choice.</p> <p>We do already have a design brief for next year that shares some similarities with your proposal, so if we did do something in this area, I\u2019d like to reduce surface resemblance: https://wiki.cam.ac.uk/cl-design-projects/Learn_to_be_an_Alien</p> <p>I noted the market-making aspect of your more formal version. I found this reminiscent of other market-making projects we have done in the past, such as these two:</p> <p>https://wiki.cam.ac.uk/cl-design-projects/Scrobble_Exchange:_A_massively_multiplayer_game</p> <p>https://wiki.cam.ac.uk/cl-design-projects/AI_racing_market</p> <p>We don\u2019t yet have a \u201cmarket\u201d proposal for this year, so could perhaps think of a Pokemon Go variant that included this aspect?</p>"},{"location":"IMC.html#2016-projects","title":"2016 projects","text":"<ul> <li>Fly-past Finance</li> </ul> <ul> <li>Digital Currency for Public   Good</li> </ul>"},{"location":"IMC.html#earlier-ideas","title":"earlier ideas","text":"<p>Maksym Korotkiy Maksym Korotkiy Maksym.Korotkiy@imc.nl</p> <p>Prototype a 2D visualization for an execution of a genetic algorithm (GA) applied to a multi-dimensional search problem. The visualization should provide insights into all stages of GA (selection, crossover, mutation) as well as into evolution of candidate solutions. We can assume that number of dimensions is between 10 and 50, number of candidate solutions (population size) is 500 and number of generations is around 100. The visualization should make it easy to understand internal workings of GA and to show an impact of different selection and crossover strategies or mutation rates. Students can use any general GA implementation and can apply it to any multi-dimensional search problem.</p> <p>Taylan Toygarlar Taylan.Toygarlar@imc.nl</p> <p>Radmilo Racic radmilo.racic@imc.nl</p> <p>Visualization techniques for large set of financial markets data This project develops techniques for visualizing multiple data sets of financial data, including ticker states of global futures and significant stocks, bonds and currencies. The end goal is not only to unearth hidden relationships and correlations between global markets but also to convey trader sentiment and pin point market moving trades. As global market landscape is quite complex and correlated, we will be using Oculus Rift as the principal display tool. Students will be provided with data from Eurostoxx, DAX, CAC, KOSPI, Nikkei, ES, EUR/USD, T-Note, GBL, etc.</p>"},{"location":"IMC.html#2015-project","title":"2015 project:","text":"<ul> <li>Building the Matrix</li> </ul>"},{"location":"IMC.html#2014-as-imc-netherlands","title":"2014 (as IMC (Netherlands))","text":"<ul> <li>Virtual Reality Trading   Desk</li> </ul> <ul> <li>Algo-Trading Game</li> </ul>"},{"location":"IMC_%28Netherlands%29.html","title":"IMC (Netherlands)","text":"<p>contact Elisa van der Linden (Elisa.vanderLinden@imc.nl).</p> <p>Note that clients would be traveling from the Netherlands for project meetings - they would proceed with two of these at most.</p>"},{"location":"IMC_%28Netherlands%29.html#initial-proposals","title":"Initial proposals","text":"<p>News Analysis: Owner: Julien Mattei (Julien.mattei@imc.nl)</p> <p>Game trading engine: Owner: Radmilo Racic (Radmilo.racic@imc.nl)</p> <p>Trading input visualization: Owner: Taylan Toygarlar (Taylan.toygarlar@imc.nl)</p> <p>Network queuing analysis: Owner: Pedro Estrela (Pedro.estrela@imc.nl)</p>"},{"location":"IMoji.html","title":"IMoji","text":"<p>It is useful to include emojis in your messages as a quick indicator of emotional state, but why should you have to call up a special keyboard, or scroll through many alternatives, when your emotional state could be read off your face? The goal of this project is to augment the on-screen keyboard by using the front facing camera (and/or depth data provided by the device) to just read off the emotional state and put the \"right\" emoji in. It could also be useful to use other sensors of the device to better assess the emotional and physical state of the user in selecting the fitting emoji.</p>"},{"location":"Ideaspace.html","title":"Ideaspace","text":"<p>Membership organisation - suggestions would come from individual members</p> <p>Contact: Ben Hartley bpih2@cam.ac.uk (Previously Stewart McTavish)</p> <p>The following invitation was passed on to Ben for 2021 and 2022</p> <p>The Cambridge Computer Science Department runs an annual design project course for its students, where teams of 6 develop a prototype for an external client. No payment is required, but clients are expected to meet with the team (by Zoom) four times between January and March. This is a great opportunity to explore new product or application ideas, meet skilled students who are interested in your business, or experiment with new software technologies at minimal cost. If you would like to be involved in the course next year, please contact the organisers on group-project@cl.cam.ac.uk</p>"},{"location":"Illumina.html","title":"Illumina","text":""},{"location":"Illumina.html#2016-proposal","title":"2016 proposal","text":"<p>Citizen Science for Cancer</p>"},{"location":"Illumina.html#earlier-suggestions","title":"earlier suggestions","text":"<p>Proposed client: Lisa Murray Staff Scientist, Bioinformatics lmurray@illumina.com</p> <p>long-term contact Scott Oldham -(soldham@illumina.com)</p> <p>Suggestion:</p> <p>Genomics Mechanical Turk</p> <p>Analysis of genetic data (genomics) is full of classification tasks that are difficult to solve algorithmically, but which a human expert can often figure out from a quick glance at the data. Even novices have lots of insight to offer into these tasks by bringing novel perspectives and fresh ideas to these complex problems. Getting lots of people to solve thousands of instances of a problem for you lets you learn general principles from their proposed solutions, which can then be implemented algorithmically to improve. The trouble with getting people to try to solve a difficult genomics problem is that it\u2019s often a bit complicated, and for most people, not very fun. But we can change that! There are several successful games created that help scientists solve tough computational problems, such as Genes in Space (Cancer Research UK) and Foldit (University of Washington). These programs help researchers identify broken genes in cancers and figure out properties of potential drug targets, both crucial problems that need solving to improve human health.</p> <p>Let\u2019s make genomics fun! Create a Facebook or mobile game to solve a difficult genomics challenge\u2014identifying tumor-causing cancer mutations. Fundamentally, identifying these mutations is a signal processing problem where the signals are sometimes weak and the noise is variable. One way to conceive the game would be to imagine a comparison of three pictures: a \u201creference\u201d picture and two \u201ctest\u201d pictures. A player would have to figure out which, if any, of the test pictures look like the reference picture. All the pictures would be abstract representations of DNA sequencing data. The key will be providing an engaging way of representing this data from raw sequencing input and creating an engaging game from this core concept that people will want to keep playing. We will provide the \u201cproblem data\u201d and suggestions for potential translations into a game setting.</p>"},{"location":"Illumina.html#2014-project-prize-winner","title":"2014 project (prize winner)","text":"<ul> <li>Evolve a Pet</li> </ul>"},{"location":"Illumina.html#earlier-suggestions_1","title":"earlier suggestions","text":"<ul> <li>CheckMate</li> </ul> <ul> <li>Genomes are fun!</li> </ul>"},{"location":"Infect_your_friends.html","title":"Infect your friends","text":"<p>Educational project suggestion on Raspberry Pi from Cecily Morrison cpm38@cam.ac.uk</p> <p>Step 1: Groups of students can model the spread of influenza and then visualise it graphically on one screen or with sound/light across each students RPi as they get infected.</p> <p>Step 2: This model can be made more complicated by making the rules relative to contact and therefore requiring sensing about where people are moving in the room.</p> <p>Step 3: Add interventions and see how it changes</p> <p>Step 4: Get students to think of solutions (e.g. hand washing) and use the RPi to monitor the amount of handwashing in a school through the use of various sensing attachments. This could also be applied to any other social networking problem if it is not winter.</p> <p>Category:Raspberry Pi</p>"},{"location":"Infectious_Diseases_Institute_Kampala.html","title":"Infectious Diseases Institute Kampala","text":"<p>Suggestion:</p> <p>Distributed Microcontracts</p> <p>Personal and small business finance innovations increasingly come from low-income countries, as with the hugely successful M-Pesa mobile payment system. The goal of this project is to create a distributed payment and ledger system for organisations that commission many small pieces of work in remote locations. It should use the sensor capabilities of smartphones (e.g. camera, accelerometer, GPS) to authenticate contracts, payment and verification of commissioned work in an intuitive, secure and traceable way.</p> <p>Might potentially work with local company Obex Technologies</p>"},{"location":"Influencing_Health.html","title":"Influencing Health","text":"<p>Many more people get their news from social media than TV, but much national and international public health policy relies on public broadcasting as the primary channel of communication. Your job is to make a tool that helps reconnect local health emergencies and interventions to local influencers who may be motivated to help. This will involve using APIs from TikTok, Instagram etc, but mapping these against local health statistics in a way that doctors and government officials can see what is going on.</p>"},{"location":"Informetis.html","title":"Informetis","text":""},{"location":"Informetis.html#2021-discussion","title":"2021 Discussion","text":"<p>Jos\u00e9 Alcal\u00e1, Head of Data Science Team,</p> <p>Boruo Xu (Bono), Head of Data Solutions Team,</p> <p>A keystone in the transformation to Smart Grids is the synergy between solar panels and batteries. This is a complex task that heavily depends on the weather, energy tariff and human stochastic behaviour. Informetis is an AI energy start up company that aims to empower the user in the Digital Transformation of electricity data. We propose the implementation of an Artificial Intelligent Agent capable of deploying the best strategy for charging and discharging of domestic batteries. This will aid the user to select the correct battery size to maximise household energy bill savings. Thus a communication channel, such as a native or web based app, needs to be opened with the user. The project is suitable for a team of 6 people and it might be divided into three modules: Machine Learning strategy for battery control, 2 people; backend to support communication with the cloud, 2 people; and front-end interface to show results to the users and, potentially, receive feedback, 2 people. Informetis will provide historical household power consumption and historical household solar generation for a set of houses. We are hoping to use the tool that you develop to showcase to stakeholders as a demonstration of smart energy technology.</p> <p>Feedback:</p> <p>I can see that implementing an algorithm to optimise battery selection would be an important problem, but unfortunately our students are not taught any topics relevant to battery technology, so would have to treat the battery as a black box. My own estimate is that, if you had a suitable training dataset, then implementing a machine learning algorithm to solve this task on a black box basis might only take an hour or two using Keras and TensorFlow (perhaps followed by a few more hours playing with hyperparameters).</p> <p>A p2p energy trading system sounds more appropriate. Here are a few examples of previous projects that involved the implementation of market or trading systems.</p> <ul> <li>Trading Assistant</li> <li>Fly-past Finance</li> <li>AI racing market</li> <li>Scrobble Exchange: A massively multiplayer   game</li> </ul> <p>Revised suggestion:</p> <p>Home batteries are rapidly evolving and disrupting the market along with PV panels. However, do you actually know whether you can benefit from it? How much energy can you save? When do you reach the ROI? Finally, if the number works for you, which one to buy? Your task is to create an application that helps consumers to answer these questions. The user will input through the interface different parameters for batteries such as capacity, price, cycles, voltage, and so on. Your application will use these user inputs and the historical data (i.e. energy consumption and solar panel generation) to run a simulation of the best battery control strategy and will yield how much energy will be saved. The application may also recommend changes to user habits to improve efficiency. This task entails very challenging Machine Learning problems such as pattern usage modelling and forecasting, reinforcement learning (for battery control policies) and optimization. Regarding the interface, it has to be friendly and intuitive so the user can interact often and give continual input to the system. In the future, p2p energy trading can be also implemented.</p> <p>Feedback:</p> <p>- You say \u201cin the future p2p energy trading can be also implemented\u201d. Does this mean that the team should implement an API for future integration with another system after the project ends, or is energy trading part of the system requirement? (If it is part of the system requirement, then how should the team interpret \u201cin the future\u201d?)</p> <p>- If the main purpose of the application is battery selection, why would users be required to give \"continual input\"? Would users need to replace new batteries very often, or does the continual input relate to some other area of functionality?</p> <p>- If reinforcement learning is to be used, what system would be used to test the control strategies? Would this be a battery simulation, or actual batteries?</p> <p>- Where machine learning is to be applied for pattern usage modelling and forecasting, are there existing data sets for training and test, or would the students need to construct or acquire these?</p> <p>- If I understand correctly, the main output of the system is \"which one to buy\u201d. Presumably this is dependent on retail price, availability, and installer / supplier bundling. Are there existing suppliers whose sites could be scraped for this data, or would the purchase decision be based purely on technical performance and OEM pricing?</p>"},{"location":"Informetis.html#2020-project","title":"2020 Project","text":"<p>Client: Jos\u00e9 Alcal\u00e1 jose.alcala@informetis.com</p> <p>Proposal awaiting finalisation:</p>"},{"location":"Informetis.html#activity-analysis-based-on-smart-meter-data","title":"Activity Analysis based on Smart Meter data","text":"<p>A rapidly aging population means assisted living is fast becoming a major societal challenge. To support \u201cCarers\u201d assisting \u201cCarees\u201d, local technology company Informetis provides smart sensors installed in the fuse-box that determine if household appliances are ON/OFF. As routines are typically closely related to appliance use, this proxies for inhabitants' wellness. Your task is to create an app for carers to support householders when they struggle to perform daily routines. You may choose focus on detection of activities from the raw data, or the interaction design challenges of choosing what should be communicated to the carer and when.</p>"},{"location":"Informetis.html#past-years","title":"Past Years","text":"<p>2020 project: Activity Analysis based on Smart Meter data</p> <p>2019 suggestion: Activity Recognition and Analysis based on Smart Meter Data</p> <p>2018 project: Energy Budget</p> <p>2017 offer: Energy with Social Conscience</p> <p>2017 suggestions:</p> <p>Smart Homes and IoT</p> <p>The Internet of Things (IoT) is now almost mainstream. There are a lot of internet-enable devices such as smart sensors, connected appliances, connected medical appliances and of course smart phones. These devices are all constantly generating big data dependent on individual lifestyles. In particular, smart homes are increasingly a growing topic of interest amongst IoT technologies. Informetis, provides a cloud based service which, through the use of a \u2018single clamp\u2019 sensor, provides consumers with an \u2018itemised view\u2019 of their electricity bill. In other words, the Informetis solution can transform ordinary and \u2018non-connected\u2019 appliances such as fridges, washing machines and microwaves into \u2018virtual\u2019 smart appliances. Your task is to design and implement an application which complements the itemised power consumption data (that we will provide) with other 3rd party data such as temperature, personal information and social demographics data to make the combined user experience more useful and fun. Your ultimate goal is to make the user far more engaged with their energy consumption than they are today!</p> <p>Alternative</p> <p>When electrical appliances \"waste\" electricity, they convert it into heat. The irony is that if you \"save\" energy by switching off a TV or lightbulb, you then have to switch on a heater to stay warm! Since heating accounts for most energy use in the UK, The only really effective way to save energy at home is to turn the thermostat down. But nobody likes to be cold. You have a business opportunity to compete with an incredibly successful Internet of Things product - the \"Nest\" intelligent thermostat. Instead of wasting energy on toasty houses, your product will help customers stay warm for free by regulating your own comfort. Monitor humidity, differential airspeed etc to maintain comfort by putting on suitable clothes, eating hot food or even going to bed.</p>"},{"location":"Instrument_Landing_App.html","title":"Instrument Landing App","text":"<p>Phil.Marsden@softwire.com</p> <p>Landing a plane using the instrument landing system (ILS) requires regular practice to keep the necessary skills up to date. Unfortunately, it's expensive and inconvenient for amateur pilots to get ILS landing slots so they can practice. The goal of this project is to simulate ILS using the GPS capabilities of a mobile phone, so that pilots can practice their ILS skills even during a normal landing. The phone screen should simulate actual ILS instruments when the plane is descending. You may need to think about how to test this system without access to a plane and airport - perhaps by providing descent guidance to cyclists coming into town down Castle Hill?</p>"},{"location":"Instrumental_Visits.html","title":"Instrumental Visits","text":"<p>The Royal College of Music Museum maintains one of the richest collections of music-related objects in the UK and Europe. Standing in excess of 15,000 items, it represents a range of music-making activities over a period of more than five centuries. After undergoing extensive redevelopment, the Museum is reopening to the public in October 2021. The permanent exhibition has been designed in three sections on the same floor. These sections are highlighted in, for example, their spatial arrangement, colour of the walls, and content. The curator\u2019s intention is for visitors to follow a particular route around the museum. However, it is currently unclear which routes visitors will take, where they will most pause, and the extent to which visitors will be similar to each other in their choices. A system that automatically traces and maps visitors' routes around the museum, where they look, as well as where and how long they pause for will help inform future developments of the museum.</p> <p>I just had another idea which is rather novel. We could do step counting on the phone to try and do dead reckoning of distances people walk and where they might have gone to. It may also be possible to get *some* GPS information through windows, or location services from your WiFi hotspots if these are configured with accurate location.</p> <p>Perhaps we could use QR codes so that visitors are able to access an audio sample related to a displayed object or case, request cookie permission to record the device ID, and then include an optional app that records steps and partial location data for later correlation with the times that we know a visitor requested the audio for a specific location within the exhibition?</p>"},{"location":"Intellectual_property.html","title":"Intellectual Property","text":""},{"location":"Intellectual_property.html#ownership","title":"Ownership","text":"<p>University of Cambridge policy is effectively that undergraduate students own the IP rights to their work. Technically the University owns IP in collaborative work, but this is only so that the University can intervene if the students cannot agree what should be done; if the students agree then the University does not assert ownership. Project groups may choose to release the results of their work under an open source license, or even form a company to commercialise the design. They are free to do so. If their design relies on patented algorithms, or source code in which others hold copyright, clients might wish to warn them of this. It would be unwise to divulge commercial secrets to the project group.</p>"},{"location":"Intellectual_property.html#licensing","title":"Licensing","text":"<p>If a client believes that the software created by the group could be of value to their company, they are free to discuss fair terms on which it might be licensed. However, students carry out this exercise for course credit, not as a commercial arrangement. More appropriate ways to carry forward results from a project include offering summer employment to one or more members of the team, or proposing a related research exercise that might be the topic of a final year undergraduate project for one of the team, or even a PhD topic. If software written by the rest of the team is required in these circumstances, it should be licensed on fair terms.</p>"},{"location":"Intellectual_property.html#follow-up-meetings","title":"Follow-up Meetings","text":"<p>Please note that any follow up (other than to make arrangements) with students should be carried out after exams in early June. The students are under considerable pressure at this time of year.</p>"},{"location":"Intellectual_property.html#confidentiality-agreements","title":"Confidentiality Agreements","text":"<p>In rare cases, it may be necessary for students to receive sensitive information, for which there is a need for a confidentiality agreement. Where necessary, this can be discussed with the group project organisers.</p>"},{"location":"Intelligent_Game_Designer.html","title":"Intelligent Game Designer","text":"<p>Entertainment](King_Digital_Entertainment \"wikilink\") Vince.Darley@king.com</p> <p>There has been a lot of recent publicity about the success of CST alumnus Demis Hassabis' company Deep Mind, in creating an AI system that can learn to play 1980s arcade games. Of course, there is not much profit in playing computer games - the real business opportunity is designing them! The goal of this project is to create a fully automated AI system that can design original new levels of a casual game such as Candy Crush Saga. There is an art in designing good levels - they should be easy at first, get a lot harder, but be ultimately solvable. You will need to construct a population of simulated players, at all different levels of ability, to assess the quality of the levels generated. By optimising simulated play, each level should be challenging, motivating, while also being aesthetically pleasing.</p>"},{"location":"Intelligent_Graph_Reader.html","title":"Intelligent Graph Reader","text":"<p>Main client: Nilu Satharasinghe, Sparrho nilu@sparrho.com</p> <p>Additional contact: Vivian Chan vivian@sparrho.com</p> <p>Google Scholar is a good way to find scientific results, but it only reads the words - not actual data. The goal of this project is to create document analysis algorithms that can automatically identify and describe graphs of scientific data - something like \"find a graph where blood pressure decreases with age\". Users should be able to feed in complete HTML or PDF documents, which are automatically parsed for graph content, and stored in an archive that supports sophisticated data queries and comparisons between graphs in different documents.</p>"},{"location":"Intelligent_Orchestrator.html","title":"Intelligent Orchestrator","text":"<p>We are increasingly deploying our telephony systems in cloud environments as that allows us to increase and decrease capacity elastically in a way that has never before been possible. In the past, the only way to cope with peaks in demand (such as during X Factor voting) was by engineering in lots of capacity which of course adds expense. One of the challenges of an elastic system, though, is that it can take of the order of ten minutes to bring a new resource on-line, so judging when to increase capacity is not straightforward. If you bring the resource on-line too early the carrier faces increased costs, but if you bring the resource on-line too late calls will fail and the carrier faces lost call revenue and upset customers. To make matters more interesting, resource cost may not be fixed, but may have steps or vary by demand and/or time of day.</p> <p>This project would define an algorithm (or algorithms) to decide when to add and remove (\u2018orchestrate\u2019) resources in the cloud to balance the competing pressures of cost and customer service.</p> <p>We will provide datasets that can be used to train the system and to test how it behaves with new data.</p> <p>Feedback: An interesting challenge, but I don't think it would be easy to divide this among a team of six. Is there some other way that a team might create a demonstrator based on the data sets that you have?</p>"},{"location":"Intelligent_Tools_for_Coeliac_Disease_Diagnosis.html","title":"Intelligent Tools for Coeliac Disease Diagnosis","text":"<p>jdg18@cam.ac.uk</p> <p>In principle, computer vision and machine learning methods can be used to recognise coeliac disease. \u201cCoeliac disease\u201d is a very common autoimmune condition triggered by eating gluten, and treatable by following a gluten-free diet. Currently, in order to diagnose coeliac disease, pathologists manually inspect biopsies of gut tissue. We would like to automate this diagnosis process. Unfortunately, there are some difficulties; for example, different microscopes make the colours of the images look different, different samples look very different from each other, the images are huge, and we are interested in both small-scale and large-scale features. This project involves working on part of this process to allow for much faster and more accurate diagnosis, making use of computer vision and machine learning methods with other tools (for example image editors).</p>"},{"location":"Intensive_Care_for_Ebola.html","title":"Intensive Care for Ebola","text":"<p>One of the major challenges in Ebola outbreak regions is information management. Most patient care is done by people with neither medical nor IT experience, and often low levels of literacy. Their training is often only 3 or 4 days, mostly focusing on hygiene and use of protective clothing. Your goal is to create an electronic patient record system that will run on a smartphone, suited to the network connections, power supply and hardware limitations in rural Africa. The system should help regular collection and progression monitoring of symptom reports and vital signs as would be done in a hospital intensive care unit, for example using TPP's SystmOne. It might also present users with advice on triage and patient care. Deployment should be easily customisable for local languages, and provide mechanisms to feed data back to international coordination bodies such as the World Health Organisation.</p>"},{"location":"International_Treasury_Service.html","title":"International Treasury Service","text":"<p>richard@bigpayme.com or James Hinshelwood</p> <p>Many companies have to work across currencies. BigPay operates in both Malaysia and Singapore, and has to use an external service provider to move money between the two. It would be more efficient to do this themselves, managing reserves of both currencies (MYR and SGD), setting an exchange rate, and executing and settling transfers taking at least a day to complete. Your job is to design a software system capable of managing and visualising these reserves. It should take a feed of the buy and sell rates available from partners at various distances in time (1 day, 7 day, 30 day) and export an API allowing users to give a target currency and amount and receive a price (and then confirm the transfer). As far as possible, the system should achieve optimal revenue. You will need to write a simulator for exchange rates and for customer behaviour.</p>"},{"location":"Investment_Provenance.html","title":"Investment Provenance","text":"<p>There are many online forums that offer investment advice, but not much of it is original. Your task is to create a tool for use by traders, that annotates investment tips with a plausible history of where they might have come from. Any correlation with historically objective information, such as share price movements, may be a helpful source of causal evidence. This project is likely to require some research into text processing algorithms and statistics, as well as an intuitive front end that helps users understand the \"genetics\" of specific investment trends and memes.</p>"},{"location":"Investre.html","title":"Investre","text":"<p>Originally introduced by Markus Kuhn, also worked with IfM?</p> <p>Shayan Keyhan-Rad Investre Ltd S Keyhan-Rad shayan@investre.co.uk</p> <p>From: S Keyhan-Rad 1 Sent: 23 October 2017 17:25 To: Alan Blackwell afb21@cam.ac.uk Subject: Re: group project proposal</p> <p>hi alan</p> <p>thanks for your email we dont have anything for now - will be in touch for next year</p>"},{"location":"JAID.html","title":"JAID","text":"<p>Received from Sam Henshall-West sam.henshall-west@jaid.io</p> <p>Earlier contact: Mark Barton mark.barton@jaid.io</p> <p>In a sentence, the project would be to represent vector embeddings of an AI model in 3D projection using VR headsets (rather than the traditional 2D) including the ability to interact.</p>"},{"location":"JPMorgan.html","title":"JPMorgan","text":"<p>redirect to JP Morgan (they keep changing their name - this year, actually seem to be \"J.P.Morgan\"</p>"},{"location":"JP_Morgan.html","title":"JP Morgan","text":"<p>\"Agozino, Biko JJ\" biko.jj.agozino@jpmorgan.com</p>"},{"location":"JP_Morgan.html#ideas-for-2022","title":"Ideas for 2022","text":"<p>will be coming</p>"},{"location":"JP_Morgan.html#ideas-for-2019","title":"Ideas for 2019","text":"<p>\"Agozino, Biko JJ\" biko.jj.agozino@jpmorgan.com</p> <p>We certainly do have ideas from earlier in the year that we put aside for the Cambridge group projects. Let me see where they got to in the end and get back to you.</p>"},{"location":"JP_Morgan.html#ideas-for-2018","title":"Ideas for 2018","text":"<p>From PDF to Practice</p> <p>Background:</p> <p>The Royal College of Anaesthetists ran their own internal hackathon and came up with a few ideas. The idea they\u2019d most like to take forward is a Perioperative Medication Advice app.</p> <p>Currently, individual consultants / trusts have use their own experience guidelines around medicines (pre through to post) operation. This leads to incomplete and non-optimum information being provided to patients. For example patients taking anti-coagulants may be given differing advice as to when they should stop taking them prior to operation, possibly increasing the dangers through bleeding or result in more costly (to the NHS) blood transfusions. Often there is other physiological information that needs to be taken into account as well as just the information provided by the drugs companies. The number of possible drugs makes giving an individual patient specific, personalised perioperative drug advice difficult.</p> <p>The desired solution would be reduce the reliance on human knowledge, leveraging the best practice, which currently reside in individual trusts\u2019 policy documents. Specific, tailored information could then be given to individual patients.</p> <p>My thought was we could run this as a challenge at CFG (our external hackathon) London, and as a Cambridge Undergad project next term. This could then lead into a FFG (our internal pro-bono effort) project next year, where we can make sure the development is heavily test driven / rigorous. The challenge is likely to be in getting sufficient info to build a prototype. When I bounced this off Biko, he suggested we could use Machine Learning to scrape info from any documentation (PDFs) RCoA can provide. ---</p> <p>From my perspective the key challenges of this project will be:</p> <p>1. Leveraging Machine Learning and Natural Language Processing techniques to scrape and rationalize sufficient data from PDF documentation detailing the guidelines</p> <p>2. Creating an Application that will help patients and doctors get advice on Perioperative Medication specific to the patient I think this project could provide a Techincal Challenge, and Business Opportunity, as well as the obvious Human Interest.</p> <p>What do you think? Could we mold this into something acceptable for the group projects?</p> <p>Kind regards, Biko</p>"},{"location":"JP_Morgan.html#2017-suggestion","title":"2017 suggestion","text":"<p>Micro-Volunteering</p> <p>\"Many charities rely on volunteer networks, but small local charities sometimes don't have the staff to maintain those networks. On the flip side, many people would like to volunteer to help a local charity but aren't able to commit a set number of hours per week. Micro-volunteering allows individuals to offer up their skills on an ad-hoc basis and for charities to take advantage of that, and is extremely valuable to smaller charities or community organisations.</p> <p>Your task is to design a micro-volunteering exchange, that can match volunteers to opportunities in their local area. Locality is critical in micro volunteering, perhaps a graph database (like neo4j) would be interesting here.</p>"},{"location":"JP_Morgan.html#2016-project","title":"2016 project","text":"<p>Drive by Age</p>"},{"location":"JP_Morgan.html#earlier-version","title":"earlier version","text":"<p>Michael says: \"I don't know that we have street by street data, but let me find out.\"</p> <p>Different areas of the UK, or of cities like Cambridge, have wide-ranging differences in average age. Your task is to help people understand these differences by changing the appearance of an online map and/or street view, to simulate the issues faced by the people who live there. You can start with an interface allowing the user to drive through Open Streetmap or Google Maps, but modify local parts to reflect the age of people who live in that area. For example, the appearance of text and graphics might be modified to simulate visual capability of older users, navigation controls might simulate fine motor control issues (shaking hands, etc), and street scenes modified to show effects of reduced sensitivity to light in night driving. The resulting interactive system can be used both to better understand age distribution, and to help younger users appreciate the needs of the older population in particular areas.</p>"},{"location":"JP_Morgan.html#even-earlier","title":"even earlier","text":"<p>The first idea would be an application or game with the theme of \"How does it feel to be old?\". Some initial thoughts from AgeUk on that are:</p> <p>\"For a lot of Gen Y (or even Gen X) who use the internet, apps, games, social media on smartphones or tablets all the time, every day, it is really hard to imagine how using this sort of thing might be a really different experience for an older person. Older people may have fine motor control issues (shaking hands, etc), eyesight and hearing issues, and even just issues in processing information at a slower speed. All of these things may affect how comfortable someone feels about using websites, apps, or even doing simple things on a smartphone. How can we create a tool or an app or a game that brings this to life for younger people \u2013 and maybe helps them to think about getting involved with Age UK or donating as an outcome? \"</p> <p>The second idea would be data analysis and visualization around data representing the problems faced by older people in different regions of the UK (e.g. those in rural areas may be more affected by issues of isolation, whereas those in cities by issues of crime and security). Again, a very early description</p> <p>\"How can Age UK represent our complex regional-based data about older people in a commanding, visual way? We have complex data sets (we can send) in spreadsheet form that map occurrences of many different issues for older people, e.g. regional stats on disease, mortality, loneliness, health, etc etc. Could we find a way to visually represent this in a way that might be useful for PR purposes, to show to potential funders or donors, in a way that brings to life the multiple issues that older people use, and the way that Age UK helps in all its 165 localities\"</p> <p>If you think these are promising, I will work to flesh them out into more fully fledged projects. I think the first has some interesting aspects of user experience design, and has good scope for delivering a fully featured end product. The second perhaps offers scope for some creative thinking about data representation.</p>"},{"location":"JP_Morgan.html#2015-project","title":"2015 project","text":"<p>Careers from Here</p>"},{"location":"Jagex.html","title":"Jagex","text":"<p>Considering possibility for 2019</p>"},{"location":"Jagex.html#suggestions-for-2017","title":"Suggestions for 2017","text":"<p>Project 1:</p> <p>Personal Reality</p> <p>Project 2:</p> <p>Multidimensional descriptive engine and visualisation system</p> <p>Eric Lagel - Senior Producer (eric.lagel@jagex.com)</p> <p>Joel Graham - Director of Analytics &amp; Data Science (joel.graham@jagex.com)</p> <p>In games, as well as wider entertainment, there exist many different systems to describe features of a product. From the user perspective though, there is no consistency across vendors or platforms to provide a common understanding of the products I may be interested in (e.g. is this \u201cMOBA\u201d on PC the same as that \u201cAction MMORPG\u201d on Android?); it is also not possible to describe what you want in anything other than a narrow prescribed set of terms (e.g. how can I find a \u201claid-back\u201d game to play, looking across genres and platforms?).</p> <p>The solution to that problem will require abstracting (is \u201claid-back\u201d similar to \u201ccalming\u201d?) from multiple diverse datasets (e.g. parsing user reviews? Ingesting App Store databases?), but this still leaves a significant challenge in terms of making a powerful and intuitive system that users can explore to find what they\u2019re looking for. Does that mean users prioritising match importance for chosen terms on a scale? Does it mean a 3D space to navigate from the closest matches through less similar games of potential interest? Can I \u2026</p> <p>Feedback:</p> <p>We\u2019ve certainly done related projects in the past. An effective method for this kind of problem is to create word clusters using Latent Semantic Analysis, or some other vector-based bag of words technique. However, past experience is that the resulting functionality is rather one-dimensional, and that our computer science students don\u2019t have the visual design imagination to create anything other than the first idea you might think of (a word cloud in the projected vector space with font size varied according to word frequency).</p> <p>So if we were to offer something in this area this year, I\u2019d like to extend it a bit. Do you have a good training set of labelled user reviews for your own products?</p> <p>One thing that just occurred, looking at other design briefs under development. I know that Runescape has players in other languages. Do you have customer reviews in multiple languages?</p> <p>Thanks for the feedback Alan - replying here as there's not been a time when Eric and I are both in the office, so I thought better to at least get an initial response (which Eric can always correct as needed!).</p> <p>From my side, I was expecting that one of the biggest challenges would be engineering the ability to ingest and abstract from diverse datasets in the wild. It's not something we have a training set for, and I think Eric (who's closer to the understanding of end user needs) would be imagining that the utility in the concept would require a far more diverse set even for training than we would be able to provide.</p> <p>That, and your two points about likely visual design constraints and previous projects' similarities, make me suspect that this is not a well-suited brief; I may be mis-interpreting though, and I'll wait to see what Eric thinks - although my availability is limited, I will have email access over the coming days.</p> <p>Yours,</p> <p>Joel.</p> <p>Although there would indeed be a degree of parsing and plumbing work involved in ingesting a range of datasets, my guess is that this technical work is likely to be very limited, by comparison to the amount of time that the team would need to spend identifying candidate datasets and negotiating access.</p> <p>Generic tools for content-scraping of semi-structured data are more challenging, but we already have a fairly sophisticated project in that area for this year: https://wiki.cam.ac.uk/cl-design-projects/Retail_Startup_Automator</p> <p>I do think that visualisation of linguistic datasets is interesting - and indeed, I have a couple of research projects going on in that area at the moment. Perhaps if you had a specific example of a visualisation (e.g. from another domain) that you would like to emulate, we could consider that as a starting point?</p> <p>Original suggestion for project 1: Social positioning and influence in a virtual space</p> <p>Mark Ogilvie - Design Director (mark.ogilvie@jagex.com)</p> <p>How we perceive ourselves socially is subject to many influences, and it is a difficult subject to study objectively due to those influences. Your goal is to use a virtual reality environment to study social perception. The focus of the project should be to deliver a system architecture that allows sociologists to track decisions and alter the experience to challenge or support trends discovered in the data.</p> <p>Within a virtual reality environment, we could allow subjects to create their perceived self, using virtual, abstract objects of various shapes, colours and sizes in an attempt to mimic the way our self-perception changes under various influences. How are their creations influenced by the objects available? How are the creations influenced by the other creations in the area, be it anonymous or named? When tracked against the creator\u2019s personal details, what trends can be discovered? What happens when subjects have the ability to \u201cbuild\u201d their perception of others? Such a product could evolve to a mobile state, locking a creation to a device and monitoring how a subject might change their creation based on new locations and influences.</p>"},{"location":"Jagex.html#projects-in-2016","title":"Projects in 2016","text":"<ul> <li>Listening to a million   voices</li> </ul> <ul> <li>Dynamic Narrative</li> </ul>"},{"location":"Jagex.html#further-proposals","title":"Further proposals","text":"<p>Sponsor: David Solari Email: david.solari@jagex.com</p> <p>Full motion video adventure game engine and toolset:- This project is about creating an engine and tool set which allows video footage to be utilised for the production of adventure games. Film features would include cutting, arranging, linking, freezing, zooming, and digital items to be inserted in film, digital special effect insertion slow mo and time lapse. Game features would include, two way dialog, path selection, inventory, 360 camera control, nodal integration points and a quick time interaction system. Control interface features would include mouse and keyboard; mobile touch and VR gesture. A simple proof of concept demonstrating the engine and tools would be required.</p> <p>Strategy Card Game Creator (Sponsor: Mark Killey, email: mark.killey@jagex.com)</p> <p>Chronicle: RuneScape Legends is a new strategy card game based around an innovative core mechanic and experimental card systems. While The Strategy Card Game Creator would be the Super Mario Maker of the genre!</p> <p>It would be a game in which someone can create their own collectable card game, either single or multiplayer and share it with their friends. A player needs to create their own ruleset, cards, card effects and obviously a name for the game itself, which is then submitted to a central server. Other people can then play the game, leave a rating and feedback. The creator of the game will be able to see this feedback plus other key metrics, such as how many people have played the game. Players will also need to be identifiable so there would need to be some form of account system. The key for success will be to provide an intuitive yet sophisticated system that allows people to easily create or modify rulesets and cards in which can sit innovative mechanics. On top of that there will need to a be an effective system to ensure there is a meritocracy where the best games are easy to find and play!</p>"},{"location":"Jagex.html#more-appropriate-to-mphil-student-flame-charts","title":"More appropriate to MPhil student: Flame charts","text":"<p>(Sponsor: Philip Bielby, email: philip.bielby@jagex.com)</p> <p>Google Chrome and Mozilla FireFox have some excellent profiling frameworks that produce charts that show time on the X-axis, and what has been taking up that time against that. This is extremely useful when profiling games written in JavaScript. However, there is no readily available complete solution to do this for a game not written for the browser.</p> <p>We would like to have a series of functions we can call from C++ to:</p> <ul> <li>Mark when a frame ends</li> <li>Record custom \u2018method calls\u2019 from game scripting languages</li> <li>Record other custom events</li> </ul> <p>We would also like to record what is happening in our C++11 code without having to manually instrument everything (perhaps using a custom LLVM instrumentation pass or similar, although an idea that works on multiple compiler frameworks (e.g. MSBuild/VS2015, llvm, gcc) might be preferable (but tricky)). It might be wise to allow shorter running methods to be filtered out if the data-set is too large, however (which I imagine might require a buffering step).</p> <p>This data could then be transferred to a web browser interface (perhaps using the trace-viewer framework from Google Chrome: https://github.com/catapult-project/catapult/tree/master/tracing), preferably using WebSockets or similar to allow online gathering of data in as simple a fashion as possible, so that you can simply press a \u2018profile\u2019 button in the game to start and a \u2018stop\u2019 button when you are done, and have the view update with the profiling data that was collected.</p> <p>The display of data should</p> <ul> <li>Be as a \u2018flame chart\u2019, allowing the user to drill down to find exactly</li> </ul> <p>what is happening and when</p> <ul> <li>Handle processing on different threads as separate charts, so</li> </ul> <p>multithreaded behaviour can be seen clearly</p> <ul> <li>Highlight different types of event separately</li> <li>Show when frames end clearly</li> </ul> <p>Possible extensions could involve adding events/instrumentation to track memory usage/allocation, or ideas regarding profiling of GPU utilisation.</p>"},{"location":"Jane_Street.html","title":"Jane Street","text":"<p>Contact in summer 2022 to confirm</p> <p>Expected client for 2023: Cheng Sun csun@janestreet.com</p>"},{"location":"Jeff_Patmore%2C_Engineering_Design_Centre.html","title":"Jeff Patmore, Engineering Design Centre","text":"<p>Happy to work with any Raspberry Pi project</p>"},{"location":"John_McMillan.html","title":"John McMillan","text":"<p>John McMillan mcmillantech@btconnect.com</p> <p>Happy to consider project proposals</p> <p>Author of \"How to Write Software for Sale\" http://www.mcmillantech.co.uk/Book.html</p>"},{"location":"John_Norman%2C_UIS.html","title":"John Norman, UIS","text":"<p>Are ideas with hardware in scope? A recent BBC Click programme reported cheap sensors for people entering and leaving rooms. The way they said it suggested it picked up mobile phone signatures. The idea that you might be able to cheaply count the mobile phones in the room is intriguing from several perspectives, not least to do with audience polling. But it could also be a useful proxy for occupancy in our room utilisation problem. I can\u2019t remember the price at which Steve Young said he would want to equip all teaching rooms, but I have \u00a3100 in my head. We have something in the order of 500-600 teaching rooms so that would be \u00a350-60K which sounds reasonable.</p> <p>Would designing and building a prototype system be a CL project or should it be something for Engineering..?</p> <p>One of the teams did something related last year ...</p> <p>https://wiki.cam.ac.uk/cl-design-projects/Location-based_teaching</p> <p>We might be able to use that infrastructure for a utilisation project, but would need to extend it with enough functionality to provide things for different members of the team to do.</p> <p>Not quite the concept I had in mind as the beacon is passive and the phone app does the work (and holds the data). The main challenge for this concept in the context of my room occupancy goal would be to create the app that used the beacon and which all students and staff would want to install, then get permission to collect location data.</p> <p>One idea might be a cell phone signal booster like this: http://www.amazon.com/Sprint-Airave-Airvana-Version-reception/dp/B00B18LKU4</p> <p>You could then record how many unique connections you pick up. There is probably a better idea. I don\u2019t know enough about how phones pick up mobile masts. Essentially you would be \u2018sniffing\u2019 for an active mobile phone. Of course you would need to let people know you were doing this and they would have the option of switching their phones off.</p> <p>I guess another possibility would be to use Eduroam registrations - if I remember correctly, there is quite a lot of data exchanged with the local access point. Are you familiar with what this is?</p> <p>(It would assume that the mobile devices are using WiFi, but this is a reasonable constraint for building a demonstrator - it\u2019s much easier for us to get access to WiFi traffic than GSM traffic)</p>"},{"location":"Jump_Trading.html","title":"Jump Trading","text":"<p>Initial enquiry from Nik Banerjee nikbanerjee@jumptrading.com</p>"},{"location":"Junco_Films.html","title":"Junco Films","text":"<p>Contact Juan Manuel Biai\u00f1</p> <p>Producer | Director</p> <p><code>&lt;jbiain@juncofilms.org&gt;</code></p>"},{"location":"Just_Maps.html","title":"Just Maps","text":"<p>Cambridge has been named the most unequal city in the UK, with homelessness, poverty, and unaffordable housing exacerbated by unequal access to land. The goal of this project is to produce an interactive visualisation that combines data from the Cambridge Land Justice campaign with census data, pollution data, the Green Space Index, and crowd-sourced reports on public access. This project provides an opportunity to interact with local groups advancing spatial and social justice in the city, while applying data science to real problems.</p>"},{"location":"Kalamna_CIC.html","title":"Kalamna CIC","text":"<p>Recommended by Emma Salgard Cunha in November 2021:</p> <p>I am working with a social enterprise spinout called Kalamna CIC, who offer secular Arabic teaching for children and parents in UK-based families with Arabic as a spoken home language. Their classes aim to introduce vernacular rather than \u201chigh\u201d forms of written Arabic. They use a phonics-based Arabic learning method which was developed by the founder, Dr Saussan Khalil (Faculty of Asian and Middle Eastern studies). Saussan imagines that it would be possible to create an app gamifying and making interactive some of the phonics-based content which the younger students already use on paper and through existing very basic digital flashcards and pdf books.</p>"},{"location":"Keeping_Key-Workers.html","title":"Keeping Key Workers","text":"<p>The design strategy of \u201cgamification\u201d uses familiar features of videogames like high scores, personal bests or daily streaks to improve incentives and enjoyment of everyday life. In the retail logistics sector, especially key-worker areas like food retail, there are many data feeds and performance measures available. Some retail sites do provide game-like feedback to staff and customers, but there are many opportunities to make this enjoyable rather than an oppressive obligation. Your client is a leader in retail data science, and you\u2019ll have an opportunity to work with real data from real stores to see how key-worker\u2019s lives might be improved.</p>"},{"location":"Kettles_Yard_Gallery.html","title":"Kettles Yard Gallery","text":"<ol> <li>REDIRECT Stride Design</li> </ol>"},{"location":"King_Digital_Entertainment.html","title":"King Digital Entertainment","text":"<p>2017:</p> <p>Introduction to Elm Partners</p> <p>2016:</p> <p>Intelligent Game Designer</p> <p>Slightly crazy suggestion by Alan:</p> <p>Humans are still better at making real world decisions than robots are - self-driving cars are notoriously bad at judging novel situations. The concept for this project is to use an abstract version of a real-world scene to collect and aggregate judgments from millions of users. Using the game mechanics of Candy Crush Saga, take the pixels from some part of a real-world image (say a blurry traffic light or road sign), and give prizes when large numbers of players agree on which action is best - left, right, go or stop. Player motivation can be increased by rendering the pixels as candy, so players don't feel they are being exploited, but individual intelligence will be aggregated by an algorithm that applies the results back to real images - perhaps by training a neural network.</p>"},{"location":"KisanHub.html","title":"KisanHub","text":"<p>We no longer have any contact at KisanHub</p> <p>Previous contact was Tim Wilkinson tim@kisanhub.com, after October 2019 will be tsw@tswdesign.co.uk</p> <p>(Has been a client before, when at UNEP-WCMC</p>"},{"location":"Kynesim.html","title":"Kynesim","text":"<p>2017:</p> <p>Auto-Archive</p> <p>Earlier suggestion:</p> <p>Workable backups for small offices</p> <p>Based on:</p> <p>Small offices, of 2-8 people, have networks of PCs, connected typically by 100Mbit ethernet (1Gbit if you are lucky). They generate quite large quantities of data - our office turns over perhaps 1Gb/person/month over a dataset of maybe 8Tb/person.</p> <p>We have a net connection of about 200Mbit down/ 20Mbit up.</p> <p>We would like an off-site backup system; we're prepared to use USB hard discs to physically carry data off site, but really important data should be uplinked to somewhere in the cloud, like tarsnap or perhaps Amazon S3 directly.</p> <p>There are a few challenges here :</p> <p>- Locating what has changed is quite hard; remember, people are using these machines constantly (and when they aren't, their daemons are); you can't just scan the hard disc.</p> <p>- Deciding if it is important is difficult; yet another git clone of the Linux kernel probably doesn't need (or want) to be backed up. My \"extra_special_ca_key.pem\" probably does.</p> <p>- Transferring that data over the local network is nontrivial: 1Gbit for 6 hours transfers 21.6Tbyte of data in total, at line rate.</p> <p>- Incremental off-site backups mean you need to index the data, both so you can locate it for retrieval and so you know what is already stored elsewhere</p> <p>- Budgeting the uplink for the most important data can also be tricky - even USB3 hdds have fairly limited bandwidth.</p> <p>- .. and, of course, you need to somehow assign names to the data so it can be specified for retrieval.</p> <p>- If you are of a paranoid bent (and even if you aren't) you will want to encrypt the backups.</p> <p>This project invites you to write a backup system suitable for a small office environment. It should contain some kind of agent which runs on the workstation PCs, and provide reliable on-site and off-site backup of data which it considers to be important, according to some set of criteria.</p> <p><code>It\u00a0should\u00a0intelligently\u00a0schedule\u00a0backups\u00a0so\u00a0as\u00a0not\u00a0to\u00a0hog\u00a0the\u00a0local</code></p> <p>network, internet uplink, or attached media.</p> <p><code>You\u00a0will\u00a0likely\u00a0want\u00a0to\u00a0implement\u00a0some\u00a0level\u00a0of\u00a0deduplication.</code></p> <p><code>If\u00a0you\u00a0finish\u00a0that\u00a0off\u00a0easily,\u00a0you\u00a0could\u00a0look\u00a0at\u00a0providing\u00a0encryption.</code></p> <p><code>(b)\u00a0Automatic\u00a0location\u00a0of\u00a0\"interesting\"\u00a0features\u00a0in\u00a0large\u00a0datasets.</code></p> <p>Large compute engines can create an awful lot of data - from eg. traffic logs, or load monitoring.</p> <p>This data is commonly quite unstructured - XML files, syslogs,databases, CSV files. This makes it quite time-consuming to write python scripts to spot \"anomalous\" data patterns which might indicate resource starvation or incoming attacks.</p> <p>This project invites you to implement a set of data extractors which can break apart common file formats.</p> <p>It then invites you to build a set of classifiers which attempt to spot \"anomalous\" areas of data.</p> <p><code>..\u00a0and\u00a0then\u00a0a\u00a0set\u00a0of\u00a0visualisations\u00a0with\u00a0which\u00a0you\u00a0can\u00a0present\u00a0those\u00a0areas</code></p> <p>to the user.</p> <p>It is likely that you will want to do this by at the very least heuristically labelling types of data (e.g. \"time since the epoch\"), and then running statistical classifiers, or NNs over the data to locate areas of uncertainty.</p> <p>I believe I have a source of supply of these datasets (Ian Jackson has some from his build farms that he can probably let loose on unsuspecting IBs)</p>"},{"location":"Laser_cutting_round_boxes_from_square_sheets.html","title":"Laser cutting round boxes from square sheets","text":"<p>Kerf bending is a cute method for making round boxes with a laser cutter, but it requires quite a bit of planning. The goal of this project is to build a system that can be used by customers to design their own wooden boxes in arbitrary shapes (e.g. letters of the alphabet), with the templates for the round sides automatically produced using kerf bending. The resulting pieces should be suitable for posting in a flat-pack format, in as few pieces as possible, with tongue and slot assembly. Examples of the resulting designs will be fabricated using the Computer Laboratory laser cutter.</p> <p>Background on kerf bending: http://hackaday.com/2012/06/12/bending-laser-cut-wood-without-steam-or-forms/</p> <p>Special resource - interfacing details and access to laser cutter will need to be arranged with Brian Jones bdj23@cam.ac.uk</p>"},{"location":"Last.fm.html","title":"Last.fm","text":"<p>Will propose a new project for 2014 - topic to be confirmed</p> <p>Contact: David Jeffery david@last.fm</p> <p>Previous project in 2013 won the professional achievement prize for Scrobble Exchange: A massively multiplayer game</p>"},{"location":"LawBot.html","title":"LawBot","text":"<p>tetiana@lexsnap.com</p> <p>Many people don't know where to start when they have legal problems, but lawyers are expensive. Would it be possible to combine standard approaches such as crowd-sourcing, wikis or forums with the free (but much too technical) online content available on sites like legislation.gov.uk? Your task is to create a system that works at first like a chatbot, but helps users to paraphrase and interpret both their own questions and pieces of actual legislation, so that the chatbot gets smarter over time.</p>"},{"location":"Leadership_Transition_Simulator.html","title":"Leadership Transition Simulator","text":"<p>International agencies work hard to support low-income communities in becoming self-sufficient and taking control of their own progress toward the sustainable development goals. However Western-style policy reports and training documents are not always the best way to support local leadership skills. Your task is to develop an app that can be used in conversation between local communities and international partners, building on training documents like \u201cHow to Access Unrestricted Funding\u201d from the Stopping as Success project. The interactive features should build the users' confidence in determining their own future, for example through simulations, group role play or scenario development, and be more digestible for local language translation and adaptation than plain text documents.</p>"},{"location":"Leapian.html","title":"Leapian","text":"<p>Nathan Wilson nathan.wilson@cantab.net</p> <p>carlo.minciacchi@cantab.net</p> <p>Potential project ideas</p> <p>Converging on: Mixed-reality PDF editor</p> <p>Others:</p> <p>1. Speed reader</p> <p><code>There\u00a0was\u00a0a\u00a0lot\u00a0of\u00a0hype\u00a0around\u00a0spritz,\u00a0but\u00a0does\u00a0it\u00a0actually\u00a0help\u00a0you</code></p> <p>learn faster? Spritz is a powerful tool that lets you read content faster, however one of its shortfalls is a decreased ability at comprehending what is being read. Can we find a better ways to do speed reading on digital content which improves comprehension and learning.</p> <p>2. Photo-based deal finder</p> <p><code>You\u00a0are\u00a0in\u00a0a\u00a0shop\u00a0and\u00a0you\u00a0see\u00a0a\u00a0good\u00a0deal\u00a0on\u00a0a\u00a0DVD\u00a0-\u00a0but\u00a0is\u00a0it\u00a0the</code></p> <p>best deal out there? Can we build an app that automatically gathers prices from various vendors based on a photo you take with your phone.</p> <p>3. Network of local events</p> <p><code>There\u00a0are\u00a0lots\u00a0of\u00a0events\u00a0and\u00a0activities\u00a0going\u00a0on\u00a0in\u00a0Cambridge\u00a0every</code></p> <p>day but finding out about them isn't always easy. Can we build a system that gathers events from different student societies, public concerts, university talks and clubs into one place and lets you search and get updates of what is available to you at any one time. Can I tell this service where I am and at what times I am free and receive recommendations of events I would be interested in on a timeline within a 5km radius?</p> <p>4. Contact manager</p> <p><code>Keeping\u00a0track\u00a0of\u00a0your\u00a0friends\u00a0and\u00a0contacts\u00a0across\u00a0different</code></p> <p>platforms is time consuming and liable to mistakes. Let's make a system that puts all these contacts in once place and can smartly help you stay up to date and in touch. Could look at the potential for automatic replies and updates of new events - new jobs/relationships etc. There's nothing worse than forgetting to reply and losing touch with people we found interesting.</p>"},{"location":"Learn_to_be_an_Alien.html","title":"Learn to be an Alien","text":"<p>eashton@frontier.co.uk</p> <p>Procedural landscape generators are often used in videogames, for example to create new unexplored planets. What would a procedural creature generator look like? Recent experiments demonstrate that a neural network can learn how to control robot arms, if it has enough to explore with. Your task is to create a 3D editor that allows users to define a new kind of alien creature - legs, claws, sensors whatever - which then learns how to behave through experimentation with the laws of physics applying to its own body in a simple environment (furniture food etc).</p>"},{"location":"Lee_Wilson.html","title":"Lee Wilson","text":"<p>Apologies for late response, meant to get back to you earlier but am busy in Qatar with another WHO digital project. Yes, be happy to help out with your students.</p>"},{"location":"Lexsnap.html","title":"Lexsnap","text":"<p>Perhaps: LawBot</p>"},{"location":"Lexsnap.html#proposal","title":"proposal","text":"<p>Law tech startup Lexsnap is building a web application where users can instantly access legal advice. This is powered primarily through question-matching, where the most relevant question-answer pair is shown for a particular query. The underlying knowledge-base consists of 500 manually created question-answer pairs focused on Family Law. Your task will be to utilise NLP techniques to explore ways of automatically adding new areas of law into the knowledge base. This will consist of extracting snippets of information from UK legal sources, converting them to a question-answer format and automatically simplifying the language.</p>"},{"location":"Lexsnap.html#response","title":"response","text":"<p>This is certainly an area that would be appropriate for one of these projects. I\u2019m fairly familiar with this kind of system, having been involved in the early days of Transversal, whose original product was also based on question-answer pair matching.</p> <p>We like to be able to offer students the chance to design an end-to-end solution of some kind, in part to gain experience of problem analysis, but also so that the each member of the six-person team can address different aspects of the problem.</p> <p>We could perhaps suggest that they create something along the lines of your current service (including construction of the question/answer bank, and thinking about the most appropriate metrics for approximate matching of new questions), but maybe in a different application domain?</p> <p>Alternatively, they could experiment with an approach that works in the legal domain, but disguises or replaces the basic question-answer mechanic, for example using an automated chatbot interaction.</p> <p>I\u2019d be happy to take a look in more detail at your existing service, if you could give me permission to do so without legal constraint (I did take an initial look, but I noted that the terms and conditions say that I cannot access the site without agreeing to the terms and conditions - seems to be a catch 22, as I had to access the site to see them, but couldn\u2019t agree to them without seeing them :-)</p>"},{"location":"Likeness_Trainer.html","title":"Likeness Trainer","text":"<p>The human visual system is highly evolved to recognise faces even from a few lines. AI systems are improving, but we need more efficient tools to communicate which lines are meaningful to humans. The goal of this project is to create a tool for drawing the most essential lines onto photographed faces, as a starting point for psychological research into this fascinating human skill.</p>"},{"location":"Liker-bot.html","title":"Liker bot","text":"<p>Modern teenagers have to spend hours every day pressing like buttons on Facebook and Instagram. Your task is to automate this drudge-work. Of course, these companies really want to trap eyeballs, so they won't make it easy for you. You will probably have to emulate a web browser, which at least pretends to be looking at the posts before automatically \"clicking\" on the like-link. It will also be embarrassing if it likes the wrong thing, so some machine learning will be involved to monitor, learn and then anticipate the user's real preferences (kittens = like, parents = dislike etc).</p>"},{"location":"Listening_to_a_million_voices.html","title":"Listening to a million voices","text":"<p>Automated sentiment analysis tools are big business, but often inaccurate - consider the difference between the tweets \u201cpractically the best game I\u2019ve ever played\u201d and \u201chardly the best game I\u2019ve ever played\u201d, which can get very similar scores. A key to future success will be far more rapid training, collecting actual human responses to huge data sets. Your task is to create an engaging interface for navigating and coding millions of items from in-game chat and forum posts. Analysts should start by typing a word, with the system responding by showing frequency-weighted distributions of neighbouring words from all other texts. Users should be able to move left and right, filter out texts they are not interested in, and \u201cdeep-dive\u201d to check meaning of individual texts. The system should dynamically build a thesaurus, learning which words might have similar meanings from context, and adjusting the sentiment weighting of words and phrases. You\u2019ll need to use a super-fast index algorithm such as the Symmetric Compacted Directed Acyclic Word Graph from Schulz &amp; Mihov. The client will provide a sanitized set of chat data from their own industry-leading games, and would appreciate a dashboard-style visualisation of current status.</p>"},{"location":"Listening_to_the_Land.html","title":"Listening to the Land","text":"<p>Land management on a large scale requires a balance between productivity and ecological diversity, but it can be very difficult to integrate different data sources for strategic planning. This project will integrate remote satellite sensing from the Google Earth Engine with local bioacoustic surveys from the BTO acoustic pipeline, to visualise both historical and projected future measures, supporting land managers to make decisions about crops. harvests, irrigation, tourism and so on.</p>"},{"location":"Live_Cloud_Video_Remix.html","title":"Live Cloud Video Remix","text":"<ol> <li>REDIRECT Surgery in the Cloud</li> </ol>"},{"location":"Live_Lecture_Comprehension.html","title":"Live Lecture Comprehension","text":"<ol> <li>REDIRECT Live Lecture Comprehension     Tracking</li> </ol>"},{"location":"Live_Lecture_Comprehension_Tracking.html","title":"Live Lecture Comprehension Tracking","text":"<p>Alastair.Beresford@cl.cam.ac.uk</p> <p>Lecturing a large group is a challenging task, not least because there are few feedback cues: how much of the room is understanding? Too fast? Too slow? Your task is to develop a system that provides a feedback loop. Firstly, it should allow students to rate their current comprehension of lecture material through a mobile app, displaying the aggregated results live as a distribution in a corner of the presented screen. Secondly, the app should allow students to submit questions anonymously that, once upvoted to a preset level, flash up on the screen.</p>"},{"location":"Live_coding_for_blind_children.html","title":"Live coding for blind children","text":"<p>Educational programming languages like Scratch are rather disappointing for blind children - the visual syntax feedback is no help, the animated visual output is not motivating, and audio screen readers can't read the source code back to you. But it should be possible to make an educational programming language that is easy and motivational for blind children. It would output music, rather than animations, so blind children can create their own artistic results. It would create standard text source code, so screen readers work. Both of these things are already provided by Sam Aaron's amazing Sonic Pi system, but Sonic Pi doesn't have a very convenient way for blind children to create musical code. Your task is to design a simple customisable musical instrument, using Modular Robotics Cubelets, that outputs its state as a running Sonic Pi program for children to inspect (using a screen reader) and modify. You will be able to use a newly-released API for Sonic Pi that supports code insertion via standard Open Sound Control messages.</p>"},{"location":"Living_Salad_Bar.html","title":"Living Salad Bar","text":"<p>Commercial salad growers must operate at scale, stripping whole plants to truck around the country. In contrast, a typical salad plate or sandwich may only require a few leaves, beans or fruit from a plant that can keep growing. Your client has the components for a vertical garden, but wants to manage this in the most versatile and efficient way possible, using soil and water sensors together machine vision to identify every optimal picking point, control water supply, and optimise use of the energy (intensity of light) for growing the plants.</p>"},{"location":"Locally_Augmented_Retail.html","title":"Locally Augmented Retail","text":"<p>New retail support apps often focus on providing uniform services to individual consumers, regardless of where they are in the world. A key part of many such business models is that the service operator owns the relationship with the buyer, sometimes leaving local retailers as little more than a supply chain fulfilment node. However, in taste-based sectors such as the wine trade, a relationship with an expert who knows your tastes is far more valuable than a recommender algorithm. The goal of this project is to provide similar augmented reality functionality to the Vivino app (which records information on your wine tastes by recognising photographs of wine labels), but in a way that develops a personal relationship with a local retailer rather than just a personal diary. Cambridge wine merchant Paul Bowes will act as client to provide an expert industry perspective.</p>"},{"location":"Location-based_teaching.html","title":"Location based teaching","text":"<p>iBeacons/Bluetooth4 beacons are now being deployed in public, retail, and office spaces and offer the opportunity for micro-location applications (i.e. you are near X so execute Y). The CL has a large deployment of beacons that can provide phones location throughout. Your task is to create a platform that receives beacon sighting information from Android/iPhone devices and exposes it as location information that other can build location-aware applications on. You will then use this platform to create an educational system. It should be possible for anyone to use this platform to create new types of face-to-face interactive content that are advertised as available at particular times and location. Existing content could be imported automatically from sites such as talks.cam.ac.uk, lecture and seminar timetables, supervision management systems and so on, but users should be able to create new location-based content relevant to other learning or event types.</p>"},{"location":"Logistics_for_Clients.html","title":"Logistics for Clients","text":"<p>This briefing information is provided for potential client/mentors of group design project teams.</p>"},{"location":"Logistics_for_Clients.html#preparation","title":"Preparation","text":"<p>We will work with you to define a reasonably open-ended one-paragraph design brief, in a technical and business area that interests you. For more information, see What makes a good project?.</p> <p>We collect potential project ideas in September or earlier, and the design briefs are finalised in October. Projects are pitched to students in November, after which they express their preferences. A few briefs are usually cancelled at this stage.</p>"},{"location":"Logistics_for_Clients.html#kick-off","title":"Kick-off","text":"<p>Students are assigned to projects, in teams of 5 or 6, at the start of term in mid-January.</p>"},{"location":"Logistics_for_Clients.html#progress-meetings","title":"Progress meetings","text":"<p>The group project course runs for 8 weeks, in January-March each year. Client contact with the groups involves four one-hour progress meetings in weeks 1, 2, 4 and 6 of the project. Actual dates in the current year are advertised in the course timetable: https://www.cst.cam.ac.uk/teaching/part-ib/group-projects/important-dates</p> <p>Note that clients are not required to attend the briefing lecture in November or project kick-off session in January. They are welcome to attend the public screening of the final video demonstrations and prize-giving, or view these online, but this is not essential.</p> <p>Each meeting is planned within a three-day period and the student group is tasked with agreeing a meeting slot with you in that period. Meetings can take place online, although students appreciate the opportunity to meet their client in person, where this is convenient for you.</p> <p>Please let us know if a student fails to come to a meeting. Attendance is compulsory, and vigorously enforced. If a student does not turn up, this is most often a welfare problem, so it is important that we learn of it as soon as possible in order to get assistance from the student's college.</p>"},{"location":"Logistics_for_Clients.html#deliverables-resources-and-ownership","title":"Deliverables, Resources and Ownership","text":"<p>During the project, the team will deliver a frozen version of working documents by email to you on the day before the meeting. Email delivery must be copied to the course administrators.</p> <p>Although we use the term \"client\" to describe this mentoring relationship, no payment is involved, and the projects involve no formal transfer of intellectual property. Some further detail is provided in the page on Intellectual property</p> <p>As an undergraduate course, the group projects do not have a research budget for special equipment, compute resource or data licenses. We therefore ask client companies to either loan or donate any specialist resources necessary.</p>"},{"location":"Logistics_for_Clients.html#public-demonstration","title":"Public demonstration","text":"<p>At the end of the term, groups are required to demonstrate their achievements in pre-recorded videos, accompanied by a public exhibition/demo session.</p> <p>Presentations are followed by a vote, and the award of prizes to the groups voted the best in three categories. We hope you are able to participate, but it is not essential.</p> <p>A selection of presentations from previous years:</p> <ul> <li>2025:   https://www.youtube.com/playlist?list=PLstyePOvf2d1HSBklMXWbdLd_4T2X8pIT</li> <li>2024:   https://www.youtube.com/watch?v=zeCRJYL3suw&amp;list=PLstyePOvf2d3jOfc6j8cG7CmmVD6LyMe_</li> <li>2023:   https://www.youtube.com/watch?v=WcITCNXbEzM&amp;list=PLstyePOvf2d2ZvC92BQkpR6WiaiROytev</li> <li>2022:   https://www.youtube.com/watch?v=9xs5f6csNiQ&amp;list=PLstyePOvf2d3oPJOBgNoeA-aPA7lhUIGS</li> </ul>"},{"location":"Logistics_for_Clients.html#correspondence","title":"Correspondence","text":"<p>Please send all official correspondence, especially notes on attendance or other problems during the project, to group-project@cl.cam.ac.uk .Email sent to this address is received by the course directors (for projects in Lent term 2025, these are Alan Blackwell and Tobias Grosser), and by the undergraduate student administrators (in 2024/25, these are Becky Straw, Dean Dodds and Aidan Bishop)</p>"},{"location":"Logistics_for_Clients.html#assessment","title":"Assessment","text":"<p>The client is not required to assess or grade the students. It is Computer Laboratory policy to award a flat mark (called a \u201ctick\u201d) for adequate participation in a group project (actually four ticks \u2013 one based on group performance, and three on performance of each individual within the group). The standard of adequate performance is determined by independent examiners, based on project documentation submitted by students. Clients are simply requested to inform the course administrators if any group member fails to attend, or seems unwilling / unable to contribute to discussion. These precautions are mainly motivated by concern for student welfare. Reports from the client are not the sole grounds for withholding a tick, but students are told that if they fail to attend meetings, this will jeopardize their chances of getting the tick. It is important that we know this as soon as possible, so that students can receive tutorial or pastoral support if necessary.</p>"},{"location":"Logistics_for_Clients.html#data-protection","title":"Data Protection","text":"<p>We publish the name of the client, and keep these in an open public archive as with academic publications. Personal details can be removed from the archive on request, but please note that personal mentorship by a named professional is an essential feature of the course.</p>"},{"location":"London_Stock_Exchange_Group.html","title":"London Stock Exchange Group","text":"<p>Potential contact for 2023: Mick Gregorovic Miro.Gregorovic@lseg.com</p> <p>Previously discussed with Oli Bage of Refinitiv, before their merger with LSEG</p>"},{"location":"Louise_Allen%2C_Addenbrookes.html","title":"Louise Allen, Addenbrookes","text":""},{"location":"Louise_Allen%2C_Addenbrookes.html#2016-agreed","title":"2016 agreed","text":"<p>Eye-Tests on Demand</p> <p>Louise notes: If the test is to be useful in clinical practice the matching process is important a 50/50 chance of getting the correct answer won't do!</p>"},{"location":"Louise_Allen%2C_Addenbrookes.html#earlier-suggestion","title":"earlier suggestion","text":"<p>DIY eye-tests</p> <p>Many people would benefit from a way to take calibrated eye tests at home or in public places, rather than requiring special equipment and professional supervision. Your task is to design a visual acuity test that can be set up and administered using two screens - one four metres away, and one in the user's hand (their own phone or tablet). The distant screen could be anything capable of running a web browser, such as a TV or public display, with authenticated coordination to the user\u2019s phone via a separate HTTP server. Once the test starts, users will need to operate the local device without looking at it - using easy touch controls, with instructions given by audio. You\u2019ll need to investigate the relevant standards and procedures to ensure that the result is clinically valid.</p>"},{"location":"Louise_Allen%2C_Addenbrookes.html#original-background","title":"Original background","text":"<p>There are two projects, the simplest is a DIY visual acuity testing system for hospitals / vision screening in the community</p> <p>We see over 50,000 patients a year in the eye out patients dept at Addenbrooke's and this sort of number is typical for a large teaching hospital. Every patient has to have a test of visual acuity (threshold of resolution, tested in a clinic setting using a Snellen or LogMAR chart) before they have other tests and their consultation. This is the bottleneck of the clinic because a nurse currently has to do every visual acuity test and we only have 2 nurses to do this despite having 8 doctors seeing patients in clinic. Each test takes about 10 minute so you can see how easy it is to fall behind.</p> <p>I estimate that about 30% of patients would be able to assess their own visual acuity if given an automated process, which is what I am looking to develop. My idea is to have a touch screen tablet in front of the patient which drives a second monitor 4 metres away. Optotype letters would be shown on the distant screen, decreasing in size using a staircase algorithm and the patient would match the letter to one of a number displayed on the tablet screen in front of them until they make 50% errors. This would then give a threshold visual acuity which would be recorded.</p> <p>The optotype standards / sizes are well established. Auditory and visual instructions would need to inform the patients what to do. We could use accepted optotypes for kids - who would probably respond more positively to this as a game than most of the elderly.</p> <p>I imagine that it might be a little like the automated check outs in supermarkets, gradually people will prefer to use the system so they get through quicker!</p> <p>The second project is to work on a visual acuity testing system for pre-verbal children. I have previously developed a system called KidzEyez which is now licenced which uses a webcam feed from the centre of a display screen to monitor the responsive eye movements of an infant to cartoon targets appearing in the periphery of the screen - which informs us about the peripheral visual field of the infant. I have the prototype at Addenbrooke's. Hazel Kay (who developed the established Kays pictures visual acuity cards for children) and I would like to develop a visual acuity test along the same lines - giving the infant two targets of diminishing size to distinguish between and measuring visual acuity as the smallest size of optotype to which the child sees and looks towards. See  for info about Kidzeyez."},{"location":"Low_energy_ECC_%28Elliptic_Curve_Cryptography%29_library.html","title":"Low energy ECC (Elliptic Curve Cryptography) library","text":"<p>Contact: Alistair Morfey alistair.morfey@cambridgeconsultants.com</p> <p>An increasing number of our projects need to include embedded security. This is particularly true as more devices expect to support remote software upgrades in the field throughout their installed life. We see this a lot in smart metering. Many of these devices are battery-powered and need to implement modern security algorithms at low energy. There are open source libraries available for symmetric (e,g AES-128) and asymmetric (e.g ECC 256 primes) crypto algorithms, but they are mainly aimed at computers and require far too much memory and energy. We have found good open source libraries for symmetric crypto algorithms that are suitable for low energy use in embedded systems with small memories. However we have not been able to find any suitable libraries for asymmetric crypto algorithms such as ECC-256p. The challenge is to develop such a portable code set for an embedded 32-bit or 16-bit processor with a small amount of memory (code flash and data RAM). It should identify clever techniques to minimise energy usage and memory requirements. It should be made available as open source software.</p> <p>feedback</p> <p>Do you think that this project would be feasible on the ARM core used in the Raspberry Pi?</p> <p>All students have their own Raspberry Pi this year (just for hobby use - we don't do any teaching on it), so this would be a reasonable target for a low-power implementation.</p> <p>However, to make the project feasible for a group project, we might need to anticipate plausible ways that it could be divided among a team of 6. At present it looks more like a one or two person project.</p>"},{"location":"Lyzeum_Ltd.html","title":"Lyzeum Ltd","text":"<p>2021 project:</p> <p>Intelligent Tools for Coeliac Disease Diagnosis</p> <p>Julian is also affiliated to the Cambridge Image Analysis Group at DAMTP.</p>"},{"location":"MQA.html","title":"MQA","text":"<p>Something audio/music related? www.mqa.co.uk</p>"},{"location":"MSR.html","title":"MSR","text":"<p>Azure Sphere for citizen science</p> <p>Choose an issue important to you or others, and use Azure Sphere to build a proof-of-concept IoT sensor network for environmental sensing around that issue in the pursuit of citizen science</p>"},{"location":"Machine_morse.html","title":"Machine morse","text":"<p>Flash a light - perhaps on a monitor - to hide an encoded message on the far side of the Intel lab. Use live video feed from a camera at the other end to identify location of the coded message, use machine learning to determine clock rate and decode.</p>"},{"location":"Magna.html","title":"Magna","text":"<p>Client for Clean Cycle systems-development project proposed by Sensors CDT CamBike using Sensors CDT CamBike hardware.</p> <p>Working with Mark Barnett mark.barnett@magna.com</p>"},{"location":"Managing_Agile_Researchers.html","title":"Managing Agile Researchers","text":"<p>Software companies use agile project management to ensure that a backlog of feature requests is implemented in a timely way. Universities are not so agile, but often employ people with a wide range of technical skills, including computer officers and research engineers. Your task is to use natural language processing methods to automatically collect and classify skill areas from GitHub and StackOverflow accounts associated with Cambridge staff, and match these against feature requirements in a backlog of requests such as \u201ccollect lecture feedback\u201d, \u201cimprove performance of video download on Android\u201d and so on. It\u2019s likely that web pages or research publications associated with the individuals will provide further natural language clues to relevant application areas.</p>"},{"location":"Mapping_Addenbrooke%27s.html","title":"Mapping Addenbrooke's","text":"<p>Stefanie Reichelt reichelt.stefanie@gmail.com</p> <p>On 22 Oct 2017, at 10:13, Alan Blackwell afb21@cam.ac.uk wrote:</p> <p>I\u2019m chasing up the remaining design briefs for projects next year. I\u2019d be happy to contact your IfM colleague directly, if that would help.</p> <p>On 23 Aug 2017, at 23:12, Stefanie Reichelt reichelt.stefanie@gmail.com wrote:</p> <p>Yes I am interested in following up. I discovered a colleague in IfM has done a project streamlining processes within the hospital. We will think of a project discription.</p> <p>Original enquiry:</p> <p>A question and a project proposal:</p> <p>I am interested in visualising the Addenbrooke's Hospital departments and affiliated CBC institutes by developing an Android or iPhone APP. This would be for researchers, clinicians and patients.</p> <p>Background: I am developing a technology platforms network across Cambridge with support from CUHP and Pro-VC Chris Abell and the clinical school.</p> <p>I am using Google Maps and geo-coding to localize labs and facilities in the wider Cambridge area. But: the Hospital Site is really difficult to geo-code as all departments use one postcode.</p> <p>Feedback:</p> <p>Do you know whether the University Map is staying reasonably up to date? In principle, they do show location of departments and institutes around Addenbrookes: http://map.cam.ac.uk/Addenbrooke%27s+Hospital#52.174718,0.140628,17</p>"},{"location":"Mapping_the_Missing.html","title":"Mapping the Missing","text":"<p>Police](Metropolitan_Police \"wikilink\") Adam.G.Basill@met.police.uk</p> <p>When people are reported missing to the Metropolitan Police, and specialist search advice is required to try and find them and return them to safety, Police Search Advisors are assigned to the case. One of the search tools used to assist locating the missing is documented statistics from previous cases. However, the current data used is 8 years old and none of the data studied was from London. Police Search advisors cannot be familiar with all the thousands of cases in their database and London's individual demographics are likely to display behaviours and patterns unique to London. Your task is to use (an anonymised version of) their database to help visualise and guide search efforts, based on the characteristics of similar cases in the past. Note that this team will need to interact with data that is sensitive and may be distressing.</p>"},{"location":"Mark_Gotham.html","title":"Mark Gotham","text":"<p>Suggestions from 2023 round - may be starting point for a more open-ended brief in future:</p> <p>==============</p> <p>1. Client: Mark Gotham (mrhg2), \"Four Score and More\" (https://fourscoreandmore.org) Title: \"Playback time\" Brief: \"Playback time\" will offer users the opportunity to play along with short, simple musical exercises on a MIDI keyboard or similar and receive automated feedback on their timing and accuracy. The resource centres on basic scale and melodies, along with musical fragments called \"partimenti\". The app thus resembles the format of home practice assistance apps, but will be free, open source, and centre on a set of musical materials that have been developed over hundreds of years to teach both playing and musical understanding simultaneously. The initial implementation for this app was completed some time ago, building on top of the music21j library (https://github.com/cuthbertLab/music21j) and including some dynamic programming for handling user input. This project will need to bring that initial implementation up to date and provide a more robust UI.</p> <p>==============</p> <p>2. Client: Mark Gotham (mrhg2) and Felipe Martins for \"Four Score and More\" (https://fourscoreandmore.org) Title: \"TiLiA: Timeline Annotator\" Brief: TiLiA (short for \"Timeline Annotator\") is a GUI-based tool for aiding in the creation and use of graphic annotations on audio and video files. It is primarily intended to aid musical analysis by showing aspects such as the structure (e.g., the verse-chorus structure of a song). Those graphics and annotations may be used to control playback and enable filtered searches over a corpus of annotation resources produced in this way. It is somewhat similar to the existing AudioTimeliner (http://www.singanewsong.org/audiotimeliner/), although already significantly more full-featured. The long-term goal is that it will serve as the first step in creating an online platform where many kinds of musical analyses can be easily shared and accessed. The current state is an initial, offline implementation (https://github.com/FelipeDefensor/TiLiA). The task for this project is to build a web version of this on the \"Four Score and More\" (https://fourscoreandmore.org) website. This may involve using elements of the offline version, but will more likely mean building from scratch, simply using that offline version for guidance.</p> <p>==============</p>"},{"location":"Marker_of_the_Beast.html","title":"Marker of the Beast","text":"<p>In the future, we\u2019ll all have barcodes tattooed on our foreheads, but until then, it would be very helpful if Google Glass could recognise your friends (or enemies) by some kind of visual code that doesn\u2019t look quite so apocalyptic. Your task is to create some kind of unique visual ID that can be applied to a face localised within an image, giving feedback to the Glass wearer such as what bands or sports teams you follow, what kind of beer they should buy you, or so on. The Viola-Jones face tracker can identify faces within an image, so from this starting point, you should work out what kind of coloured dots, stripes, or other decorations would uniquely identify any person in (say) your College.</p>"},{"location":"Mashup_tutorial_builder.html","title":"Mashup tutorial builder","text":"<p>Maker and hacker communities like the hundreds of thousands of Raspberry Pi users need illustrated tools to explain tricky techniques or give introductory tutorials. Those tools can also be used to tell mashed-up stories based on other content - the huge expansion of Minecraft videos on YouTube is one example. The goal of this project is to create a tool that can grab any kind of content from a Raspberry Pi screen, allow users to edit that content with added text, voice-over or drawn annotations, and publish it via a forum in the style of www.instructables.com</p> <p>Category:Raspberry Pi</p>"},{"location":"MathWorks.html","title":"MathWorks","text":"<p>2021 projects:</p> <p>Consignment Tetris</p> <p>West Cambridge Airfreight</p> <p>2020 project: Robot Backgammon Arm</p> <p>Previous contact: Milos Puzovic Milos.Puzovic@mathworks.co.uk</p> <p>final project: Unlocking the graphics power of the Raspberry Pi</p>"},{"location":"MathWorks.html#previous-suggestions","title":"previous suggestions","text":"<p>Uncovering the Unimaginable Pace of Raspberry Pi</p> <p>Graphical Programming for Budding Engineers on Raspberry Pi</p>"},{"location":"Maths_tutoring_on_Raspberry_Pi.html","title":"Maths tutoring on Raspberry Pi","text":"<p>Proposed by Denes Szucs, Faculty of Education ds377@cam.ac.uk</p> <p>This will involve some kind of interactive mathematics exploration.</p> <p>Current candidate brief is the Rule-tris introduction to programming project, which includes both mathematical and visuo-spatial elements of interest to Denes.</p> <p>Category:Raspberry Pi</p>"},{"location":"Matthew_Postgate.html","title":"Matthew Postgate","text":"<p>Trading as Informate Ltd.</p> <p>Potential project for 2023: Fossil or Future</p> <p>Client in 2022: Carbon Accounting</p>"},{"location":"Measuring_glass-to-glass_video-conference_latency.html","title":"Measuring glass to glass video conference latency","text":"<p>A key consideration in the design of video-conferencing systems is to minimise the latency added to the video and audio, since this can have a marked effect on the naturalness of communication. Many software solutions exist for measuring various aspects of the system latency, but there is no substitute for end-to-end (often called glass-to-glass, referring to the lens of the camera and display screen) measurements of video and audio latency. This type of measurement has traditionally been subjectively measured by humans, and is hence prone to error and bias. Your task is to automate this by presenting an audio plus video signal to one end of a video-conference link, and measure the latency of the screen/speaker output at the other end. The two ends may be geographically separated - even in different continents. The Altera teaching board will be used to provide I/O facilities. Some technical ingenuity will be involved in ensuring that any delays or offsets in measurement are accounted for.</p>"},{"location":"Medecins_Sans_Frontieres.html","title":"Medecins Sans Frontieres","text":"<p>Proposed project for 2021:</p> <p>Clinical Nursing for Children</p> <p>In wealthy countries, hospitals use complex clinical information systems to capture and analyse data such as heart rate, respiration, oxygen saturation, temperature etc. In countries like Myanmar, nurses working in child healthcare have no access to computers that could be used to monitor and chart the condition of multiple patients every 1-2 hours over the course of their treatment. Your goal is to design a mobile app that can be used to capture data, generate clinically relevant output and empower nurses to escalate patient care as appropriate. Challenges will include transferring data between shifts, protecting patient confidentiality, and potentially integrating with existing apps.</p>"},{"location":"Meeting_Zoom.html","title":"Meeting Zoom","text":"<p>imdad.sardharwalla@argondesign.com</p> <p>Meetings by Skype often connect rooms full of people, each appearing as a tiny dot within the video from a wide-angle camera. It should be possible to use cross-correlation of signals from separated left and right microphones to identify who is currently speaking and automatically zoom the image to a specific region, enlarging the person who is currently talking to fill the screen. You should implement your solution as a replacement (software-defined virtual) camera that outputs a modified video stream, to a standard conferencing application such as Ring for Linux.</p>"},{"location":"Memories_Retold.html","title":"Memories Retold","text":"<p>Design and develop an application to help people with memory loss create an oral history through interactive prompted storytelling. The application should use AI to identify suggested talking points and ask contextual questions to trigger the unlocking of long-term memories. The application should accept images as input prompts, and use speech-to-text conversion to capture the user's responses. Ethical aspects should be considered, including who might use the application, in which circumstances, and when.</p>"},{"location":"Message_to_the_future.html","title":"Message to the future","text":"<p>There are so many things that only happen once a year - birthdays, start of term, insurance renewals - if only your email system could remember what you did last year, and take care of it next time! Your job is to implement an email server @nextyear, that will interpret the content of any message it receives, work out which things will have to change next year, and then draft an automatic update. It would be safer if this went to the user for checking a few days in advance, and provided a web interface to review currently active processes, but everything should be achieved with the absolute minimum of mouse clicks or wasted user attention</p>"},{"location":"Metaswitch_Networks.html","title":"Metaswitch Networks","text":"<ul> <li>Emma Gordon Emma.Gordon@metaswitch.com</li> <li>Lancelot Robson Lancelot.Robson@metaswitch.com</li> </ul> <p>Other contacts:</p> <ul> <li>John Palombo John.Palombo@metaswitch.com</li> <li>Beth Gorman Beth.Gorman@metaswitch.com</li> </ul>"},{"location":"Metaswitch_Networks.html#project-proposals-for-2016","title":"Project proposals for 2016","text":"<p>Client: Lancelot Robson Lancelot.Robson@metaswitch.com, with advice from stephen.remington@yahoo.co.uk and Neil.King@uis.cam.ac.uk</p> <ul> <li>Sailing by sound</li> </ul>"},{"location":"Metaswitch_Networks.html#projects-offered-in-2015","title":"Projects offered in 2015","text":"<p>Confirmed:</p> <ul> <li>Extrusion finder</li> </ul> <ul> <li>Culture Glasses</li> </ul> <p>Others under discussion:</p> <p>1. VoIP Network Quality Tester</p> <p>2. Intelligent Orchestrator</p>"},{"location":"Metropolitan_Police.html","title":"Metropolitan Police","text":"<p>Mapping the Missing</p> <p>When people go missing in London because of mental health or family problems, the Metropolitan Police use examples of previous cases to help find and return them to safety. But even expert tracers can\u2019t be familiar with all the thousands of cases in their database. Your task is to use (an anonymised version of) their database to help visualise and guide search efforts, based on the characteristics of similar cases in the past. Note that this team will need to interact with data that is sensitive and may be distressing.</p>"},{"location":"Micro-Volunteering.html","title":"Micro Volunteering","text":"<p>Michael.Elliott@jpmorgan.com</p> <p>Many charities rely on volunteer networks, but small local charities sometimes don't have the staff to maintain those networks. On the flip side, many people would like to volunteer to help a local charity but aren't able to commit a set number of hours per week. Micro-volunteering allows individuals to offer up their skills on an ad-hoc basis and for charities to take advantage of that, and is extremely valuable to smaller charities or community organisations. Your task is to design a micro-volunteering exchange, that can match volunteers and their skills to opportunities and needs in their local area. Locality is critical in micro volunteering, perhaps a graph database (like neo4j) would be interesting here. Remember also that skills and needs often involve different terminology - how will your system understand that the skill of \"simple wiring jobs\" should be matched to the need of \"broken bulb in shelter\"?</p>"},{"location":"Micro-friends_video_diary.html","title":"Micro friends video diary","text":"<p>This is your chance to be the next Instagram! As more people carry video-capture devices (Google Glass, Go Pro) we collect hours of video. Some of those hours include sequences of friends enjoying themselves. But nobody has time to review and edit all that footage. Your task is to use a face detection algorithm (Viola Jones works well) to extract those precious seconds where a friend's face is moving enough to be exciting. If your friends are a little less expressive, you can crop or speed them up as necessary. The goal is to turn the most engaging video extracts into a collection of animated GIFs, each one or two seconds long, that are embedded in a web page to provide a moving diary of your social life.</p>"},{"location":"Microsoft.html","title":"Microsoft","text":"<p>Contact Lee Stott leestott@microsoft.com and Geoff Hughes Geoff.Hughes@microsoft.com</p>"},{"location":"Microsoft.html#proposals-for-2018","title":"Proposals for 2018","text":"<p>Satavia https://www.satavia.com/ is a Cambridge-based start-up that provides digital environmental intelligence to help make aviation smarter and safer. Satavia has developed a data intelligence platform to provide environmental factor (e.g., dust, ice, sulphur, volcanic ash) exposure products for aircraft, and point locations such as airports. The core of the technology is a patent-pending cloud-based data analytics platform that combines technology from numerical weather prediction (NWP), Earth observation, with geospatial location data. The system architecture is being developed in the Azure cloud in partnership with Microsoft (through BizSpark Plus) to achieve demand-driven operational scalability and high levels of cyber-security. Satavia\u2019s mission is to minimise unscheduled aircraft maintenance caused by the environment. Satavia's solutions also support \u2018smarter flying\u2019, which will reduce fuel burn and aircraft emissions, and have a positive impact on climate. Satavia\u2019s future product road map includes environmental intelligence for moving vehicles such as ships, drones, and autonomous vehicles, and for fixed locations like ports and cities.</p> <p>The second project is with Sport England https://www.sportengland.org/ and Matthew Smith in our Microsoft Consulting team. ( see attached) You will recall it was Matthew that proposed the Cambridge Air Quality Radar project that Henry Faull, Jirka Lhotka, Sisi Liang, Henry Mercer, Pan Song, Michael Tang and Henry Mercer did such a super job with last year: https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/04/24/air-quality-radar-empowering-city-users-with-open-data/</p>"},{"location":"Microsoft.html#projects-in-2017","title":"Projects in 2017","text":"<p>Project 1, Client Matthew Smith Matthew.Smith@microsoft.com</p> <p>Air Quality Radar</p> <p>Project 2, with Altitude Angel</p> <p>To enable drones to fly over long distances without human oversight they must be able to plan routes that meet certain operating and safety criteria. For example, a delivery drone may need to make a number of deliveries within a time constraint, while public safety and policing may require repeated surveys of a specific area or location. Different drones have different capabilities; some can hover, others cannot, while others regular more regular charging. Routing drone traffic safely through our skies is therefore challenging: avoiding airspace restrictions, manned aviation and ground hazards, like schools and parks.</p> <p>Your goal is to create a cloud-based air traffic control system that solves these challenges using Altitude Angel\u2019s safety data, can receive and de-conflict \u201cflight plans\u201d and also efficiently route drone traffic by making route alterations in real-time so they can avoid each other, manned aviation and even gatherings of people as identified automatically from geotagged social media, road traffic information or cell phone location data.</p> <p>Notes:</p> <p>Altitude Angel can provide sophisticated drone simulation software so that the team can model the inputs from multiple drones without needing physical hardware, however the goal will be to implement and test the final solution with drone hardware, which we\u2019ll supply.</p> <p>Altitude Angel have a fairly robust cloud platform running now from which the students will be able to obtain the majority of the data they\u2019ll need. Some data, such as mobile phone location data/traffic flow data) they have not yet integrated, so if there is a source of this available that the University can assist with that would be greatly appreciated.</p> <p>As part of the project we will arrange for access to a development environment into which members of the team will be given all the access required to utilise our data.</p>"},{"location":"Microsoft_Africa_Research_Institute.html","title":"Microsoft Africa Research Institute","text":"<p>Project suggested to MARI director Jacki O'Neill</p>"},{"location":"Microsoft_Research.html","title":"Microsoft Research","text":"<p>2021 project: Saaras Mehan, on behalf of Azure Sphere team</p> <p>2020 project: Azure Sphere for Citizen Science (client was James Scott)</p> <p>Earlier possible ideas from Darren Edge:</p> <p>Comparative visualisation of Unicode script semantics</p> <p>Picture book translation from image search</p> <p>Learn European</p> <p>learn multiple languages at once, with mapping across for semantic comparisonm, and most appropriate learning order inferred.</p> <p>Presentation / Picture book / Comic book reflow</p> <p>Translate text, and fit it to the pictures - include CHines and Arabic?</p> <p>Previous contact: Scarlet Schwiderski-Grosche scarlets@microsoft.com</p>"},{"location":"Microsoft_Research_Cambridge.html","title":"Microsoft Research Cambridge","text":"<ol> <li>REDIRECT Microsoft Research Cambridge (2     projects)</li> </ol>"},{"location":"Microsoft_Research_Cambridge_%282_projects%29.html","title":"Microsoft Research Cambridge (2 projects)","text":"<ol> <li>REDIRECT Cycle path mapping with a custom hardware     platform</li> </ol>"},{"location":"Migration_Simulation.html","title":"Migration Simulation","text":"<p>Steffen.Oppel@rspb.org.uk</p> <p>The Yelkouan shearwater is a bird that migrates through the Bosphorus to reach the Mediterranean, but nobody knows how many there are. Your client has video of the migration as seen from different distances and angles. Unfortunately computer vision algorithms can\u2019t be trained without ground truth count of how many birds are there. You will create a CGI simulator of the flocking birds, including realistic atmosphere and viewing conditions, to generate simulated video with known ground truth bird numbers. The final stage is to train a machine learning system using your simulation to automatically retrieve the number of simulated birds, and then test it on a real migration video to yield the number of real birds.</p>"},{"location":"Milk_and_More.html","title":"Milk and More","text":"<p>Chief Technology Officer</p> <p>www.milkandmore.co.uk</p>"},{"location":"Million_Plant_Map.html","title":"Million Plant Map","text":"<p>Lauren Gardiner, Cambridge University Herbarium lmg32@cam.ac.uk</p> <p>The University of Cambridge Herbarium has over a million specimens (including nearly 1000 personally collected by Charles Darwin). Many of these have alternative names and classifications. Public resources such as theplantlist.org have brought together a consensus list of names and their alternatives, but many specimens are stored under their old names. Your task is to use machine learning methods to optimise the indexing of the Herbarium specimens, provide simpler and more intuitive retrieval, and visualise the relationships between parts of the collection, using data from their databases, theplantlist.org and other scientific resources.</p>"},{"location":"Mindi.html","title":"Mindi","text":"<p>https://mindi.io</p>"},{"location":"Mixed-reality_PDF_editor.html","title":"Mixed reality PDF editor","text":"<p>carlo.minciacchi@cantab.net</p> <p>PDF documents lead a double life, on screen and as hard copies. But when people modify hard copies (such as the proofreading marks that copy editors use, or annotations by students on their lecture notes), the digital versions stay the same. If you have a photo of an annotated document, it should be possible to match this against the PDF image, extract the annotations as an image diff, and apply them to the PDF. The simplest approach is just to overlay the annotation ink as a bitmap, but ideally, proofreading marks should be interpreted as edit operations on the original document, potentially including OCR of any clearly handwritten text. Your client can provide some specialist assistance in PDF processing.</p>"},{"location":"Mixed_Reality_Training.html","title":"Mixed Reality Training","text":"<ol> <li>REDIRECT Simulation and Warning for     Cyclists</li> </ol>"},{"location":"Mobilising_the_University.html","title":"Mobilising the University","text":"<p>Services](University_Information_Services \"wikilink\") amc203@cam.ac.uk</p> <p>Many University systems used by Cambridge students can be extended using the new UIS API Gateway service, including location and access facilities that are currently delivered via the University Card, but which could in future be accessed via NFC authentication from the student\u2019s phone. The goal of this project is to create a new student arrival experience, delivered via a phone app that integrates their official physical access to Cambridge with administrative onboarding and the online knowledge resources of the University.</p>"},{"location":"ModularSynth.io.html","title":"ModularSynth.io","text":"<p>Sophisticated digital music composition tools like the Sonic Pi language rely on an internal architecture of samples, waveforms and filters. In the popular SuperCollider system, a new synthesiser is defined by software-wiring together these \"UGens\u201d. Your task is to create a SuperCollider client that looks like a retro-style modular synthesiser or guitar pedal board, where connecting literal wires between pictures of hardware modules on the screen will construct an exact digital equivalent within the SuperCollider server. A live audio input would give you a universal guitar pedal, sample mixing makes you a DJ/producer, or if bleeps and whooshes are your thing, you can impress your Grandpa by channelling Brian Eno in the glory days of Roxy Music.</p>"},{"location":"Money_World.html","title":"Money World","text":"<p>UK voters are quite accustomed to seeing good quality visualisations of economic data, tax and public expenditure. But these aren't accessible in many parts of the world having low literacy, or where the only internet access is via the mobile network. Your task is to create an app that will run on a low cost Android phone, not using too much bandwidth, that allows developing world users to visualise, share and comment on economic data. Initiatives such as Gapminder, Africa's Voices and the Open Data Initiative might provide a starting point for design ideas, but you'll need to think about what information sources are both useful to developing world users and publicly available - www.globalintegrity.org is one organisation with the right kind of focus. You could consider designs based on the Mo Ibrahim Foundation indices, or even allowing citizens to see how their country compares to others on the Millennium Development Goals. Keep in mind that the kinds of visualisation suitable on a small screen will be very different to what might appear on a newspaper site. JavaScript visualisation libraries might come in handy, for example using a platform like PhoneGap. In any case, users should be able to find out how the visualisation was derived from the data, so that people in other countries can share, reuse or extend it.</p>"},{"location":"Morgan_Stanley.html","title":"Morgan Stanley","text":"<p>Primary contact</p> <p>David Blake David.M.Blake@morganstanley.com was suggested for 2022</p> <p>It would be particularly great if we could find a design project that aligns with Morgan Stanley's \"Giving Back\" themes around community, health and sustainability</p> <p><code>https://www.morganstanley.com/about-us/giving-back</code><code></code> <code></code><code>https://www.morganstanley.com/about-us/sustainability-at-morgan-stanley</code></p> <p>Previous Clients: Oli Bage and Theo Mauger (both have now left)</p> <p>In 2019: Probable Causes</p> <p>In 2017: The Deep Learning Society</p> <p>In 2016: Safer Chicken from Farm to Fork</p> <p>In 2015: Live coding for blind children</p>"},{"location":"Multi-lingual_SMS.html","title":"Multi lingual SMS","text":"<p>Robert.Catherall@arm.com</p> <p>Services such as Google Translate are a useful tool for global languages like Mandarin or French, but many people in remote rural areas contribute to public life in their own local languages. It's not necessary to translate these, but it's useful for UNICEF and other international agencies to know what general concerns these people share with neighbouring regions. Cambridge organisation Africa's Voices has datasets of SMS messages collected from different African countries, in local languages, addressing shared health and human rights issues. Your goal is to create a visual browser, perhaps in the style of word clouds, that would allow international policy teams to explore topic maps bringing multiple languages together. The LDA algorithm might be a useful approach to topic map construction.</p>"},{"location":"Multi-touch_Conference.html","title":"Multi touch Conference","text":"<p>Rather than flying all over the world to attend meetings and conferences, it seems as though governments and businesses could save money and time by collaborating remotely. Existing collaboration tools such as Webex and Google Hangouts work quite well to connect small groups of people together for a single presentation or discussion. However, the networking aspect of real world conferences is missing in these tools. During face to face networking sessions small clusters of people form and many different conversation threads are generated. Delegates can walk between groups of people, joining in with conversations that interest them and introducing themselves or saying hello to people they would like to speak with. There might easily be several specialised sub-topics being discussed at the same time. Your task is to create a multi-touch, multi-user browser extension that lets groups of people convene and spontaneously form discussions in a simulated networking session. The screen might be used to connect local special interest meetings to other similar meetings around the globe. Sub groups should be able to see who they are talking to in other places, and a single large screen should support multiple users at the same location contributing to more than one topic at the same time. You may like to use the theme to enhance the conversations that emerge, by for example extracting the keywords and themes and forming an indicator above each conversation cluster indicating the topic. The interface should be as simple and usable as possible, without requiring significant training. It may be more important to order the conversation clusters and avatars in terms of relevance and relatedness than to place people into a simulated geographical setting. Each user may have an additional device such as a smart phone or wireless keyboard which can be used for typing messages.</p>"},{"location":"Multi_Chat.html","title":"Multi Chat","text":"<p>mjohnson@frontier.co.uk</p> <p>Many games allow online players to chat in one form or another. More adult games allow free chat in lobbies, or within the game. Some products with younger appeal allow regimented exchanges of \u2018phrases\u2019, such as \u2018I\u2019m the fastest\u2019, \u2018This time let\u2019s play Rainbow Road\u2019 to avoid inappropriate discussion.</p> <p>Both of these formats have drawbacks, either being too limited to make meaningful conversation, or too open for inappropriate behaviour and abuse.</p> <p>Create a tool and module to provide a multiperson chat experience based on a configurable grammar where the users can converse through the stringing together of grammatical tokens to make meaningful, but limited conversational exchanges.</p> <p>The module should provide both a lobby and an ingame mode of conversation, and provide configurable options for the tokens visual and aural representation.</p>"},{"location":"Multiplayer_Rift.html","title":"Multiplayer Rift","text":"<p>We could have two Oculus Rift headsets, so the goal of this project would be to find an application for two users in a shared world.</p> <p>First-person jousting for multiple players, or auction room where multiple bidders wear Oculus Rift to see investment opportunities of different values to them?</p>"},{"location":"Music_Enhancement.html","title":"Music Enhancement","text":"<ol> <li>REDIRECT Soft Music Notation</li> </ol>"},{"location":"NFTs_for_Digital_CVs.html","title":"NFTs for Digital CVs","text":"<p>When people move jobs they take the knowledge they\u2019ve gained with them, but their learner records often stay with their employer. This is not only impractical, but ethically questionable. The advent of Web 3.0 technologies allows people to take ownership of their learner records and control who they share their data with. Utilising SoulBound Tokens (SBTs) your task is to build a model that captures a user\u2019s learning engagement data, certificates etc. via a non-transferable NFT smart contract (known as a \u2018Soul\u2019), based on Ethereum. Your smart contract code will likely be written in Remix IDE and Sol/Python language with \u201cmint\u201d and constructor rules. Another challenge is to think about a data structure standard and how data exchange and editing will be done. There are two use cases: 1) when someone wants to share their Soul with their current employer; 2) when someone wants to add or update data on their Soul. The main priority is to make this process safe and secure for the user.</p>"},{"location":"NHS_Digital.html","title":"NHS Digital","text":"<p>contact \"HAJ-NAJAFI, Arran (NHS DIGITAL)\" a.haj-najafi@nhs.net</p> <p>Too late for 2019, but possible for 2020:</p> <p>https://digital.nhs.uk/ Client: Rob Sinclair, NHS Digital</p> <p>Unknown waiting times either in an emergency or outpatient clinics cause anxiety and frustration to patients. Develop an application that provides a personalised waiting time that can be controlled by clinicians to allow patients not to be tethered to the waiting room but are notified in advance when to return to ensure a smooth flow through the service resulting in a better patient experience and less congested waiting rooms.</p> <p>Three suggestions for 2019:</p>"},{"location":"NHS_Digital.html#models-deployment","title":"Models deployment","text":"<p>Models deployment NHS Digital use routinely collected data to build models to support NHS. Some of these are predictive models identifying high risk patients, the models themselves do not contain any sensitive or identifiable information. We invite you to explore/build tools to support the implementation and deployment enabling NHS Digital to share these models with health bodies so they can run these models at their end with minimum development work required. Model Background \u2013 Did Not Attend (DNA) are estimated to cost NHS over \u00a31B a year. NHS Digital has explored HES data, and used feature engineering to build random forest models to identify patients at high risk of not attending an appointment. The output of the above machine learning model is a list of variables with estimates (i.e. gender; male = 0.234, female = 0.145). These models are to be run on booking data which Trusts hold with predictors and additional information on appointment. This will produce a RAG rating for every attendee i.e. Red \u2013 high risk of DNA, Amber \u2013 medium risk and so on. Challenge - There are multiple IT suppliers and various booking systems that Trusts use. These booking systems will have different formats and data quality issues amongst others. We invite you to explore how this model (R/Python script) can be executed on booking data at Trusts end with minimal development required for the Trusts. The model does not have any identifiable/sensitive information. However, the booking systems may contain personal, identifiable and/or sensitive information.</p>"},{"location":"NHS_Digital.html#poc-live-ae-attendance-app-for-public","title":"PoC - Live A&amp;E attendance app for public","text":"<p>Emergency Care Dataset (ECDS) contains hospital code, hospital postcode, Accident and Emergency attendance amongst other variables. Create an app that is updated in real time showing attendance at any Accident and Emergency site to enable patients to make informed choice on which A&amp;E site to visit when required.</p> <p><code>*\u00a0Could\u00a0you\u00a0clarify\u00a0whether\u00a0some\u00a0part\u00a0of\u00a0the\u00a0ECDS\u00a0data\u00a0is\u00a0available\u00a0as\u00a0a\u00a0realtime\u00a0feed,\u00a0or\u00a0would\u00a0it\u00a0simply\u00a0be\u00a0used\u00a0to\u00a0train\u00a0a\u00a0predictive\u00a0model\u00a0for\u00a0triage\u00a0estimation?</code></p> <p>Some kind of back end functionality seems necessary. We did discuss this one with one of his team in a call I had earlier in the summer. I think the plan was that the static dataset would be used to build a predictive model for improved interactive triage.</p>"},{"location":"NHS_Digital.html#enabling-independent-living-for-an-ageing-population","title":"Enabling Independent Living for an ageing population.","text":"<p>When the NHS was founded in 1948, 48 per cent of the population died before the age of 65; that figure has now fallen to 14 per cent. Life expectancy at 65 is now 21 years for women and 19 years for men and the number of people over 85 has doubled in the past three decades. By 2030, one in five people in England will be over 65. This success story for society and for modern medicine has utterly transformed our health and care needs. Many people stay healthy, happy and independent well into old age, and there is mounting evidence that tomorrow\u2019s older people will be more active and independent than today\u2019s.</p> <p>The right supply of housing in terms of location, affordability, size, tenure and facilities is a crucial factor in enabling people to remain in their own homes as they age. It is essential that new housing stock reflects the needs of the local ageing population, with sufficient extra care, sheltered and age-friendly housing available . Existing housing stock can also be adapted with aids and technology to assist older people with daily living and maximise their independence and safety. Adaptations and care packages can aid older people\u2019s recovery after a hospital stay and can help them to remain in their own homes at the end of life. Providing adaptations to support an older person to remain at home for just one year can save \u00a328,000 on long term care costs.</p> <p>We invite you to build IoT tools to support Independent living for older adults cognisant of the fact that people over 55 make up 94 per cent of non-users of the internet (Centre for Ageing Better).</p> <p>Idea led to Grand Remote</p>"},{"location":"NIAB.html","title":"NIAB","text":""},{"location":"NIAB.html#proposal-for-2022","title":"Proposal for 2022","text":"<p>Simon Smart Simon.Smart@niab.com</p> <p>Analysis of satellite imagery has become a crucial part of the business of agriculture. One problem that needs solving at scale is a method to automatically and accurately delineate the areas of crops, to enable the imagery to be clipped for analysis.</p> <p>Current offerings typically generate field boundaries which are not the same as the planted area are a crop. They are also usually based on old imagery. This can cause big discrepancies when used to forecast production, especially in high value crops such as potatoes and vegetables.</p> <p>NIAB is seeking a service, ideally delivered via API, which can accept a single geographic point and time period, and return the crop boundary in a suitable format (e.g. GeoJSON). The image analysis system could make use of temporal changes in the imagery, which provides valuable added information. Classical image analysis should be able to solve this problem although ML classifiers would also be of interest.</p> <p>Since last year, we have found an alternative solution for acquiring the data we need which combines SAR and optical data. The limiting step that remains is to generate cropped area boundaries from a single point. There are commercial services available, but they tend to limited in geographic scope, and as Charles said they are the entire field rather than the cropped area. Some that we have tested just returned openstreetmap data. It is an active area of research - see e.g. https://gtr.ukri.org/projects?ref=106000 https://www.researchgate.net/publication/343802377_A_DEEP_LEARNING_ARCHITECTURE_FOR_BATCH-MODE_FULLY_AUTOMATED_FIELD_BOUNDARY_DETECTION although this is not our area of expertise.</p> <p>The account would be to https://www.sentinel-hub.com/ which provides an API to easily acquire sentinel data for specific areas of interest.</p> <p>Feedback:</p> <p>Thanks for the link to the Hummingbird project.</p> <p>I\u2019m reluctant to set tasks for undergraduates where they are directly competing with well-funded professional researchers. Do you think we might be able to find an alternative way of framing the problem that did not focus so much on the core algorithm, but a systems perspective that incorporates a variety of technical elements in a novel way?</p> <p>For example, the joint impact of Covid and Brexit seem likely to result in major disruption of the field-to-table infrastructure that supports arable farming in the East of England. Is there potential to use crop imaging for crowd-sourced deployment of human resources in harvesting, packing and distribution?</p>"},{"location":"NIAB.html#confirmed-2021-project-virtual-agronomist","title":"Confirmed 2021 project: Virtual Agronomist","text":"<p>Background:</p> <p>Using pesticides in an effective and responsible way is a critical step in both reducing the quantities used and ensuring their impact on the environment and the health of farmers and consumers is minimised.</p> <p>NIAB holds one of the most comprehensive pesticide and plant protection products databases in the UK. This database is used by farmers and agronomists to search for products to use to protect their crops from pests and diseases. There are many complex restrictions around the use of pesticides including: timing of application and growth stage of the crops, pest thresholds, maximum dose rates and number of applications, to name a few.</p> <p>NIAB would like to leverage this database to help advisors verify that their pesticide recommendations are valid according to label restrictions by building an \u2018Agronomy engine\u2019. The agronomy engine will accept an input consisting of a list of pesticide applications and use the information in the database to validate the input. Additionally, the engine should be able to account for approved tank mixes (combinations of pesticides in the same application) as recommended by the manufacturer.</p> <p>We would like the agronomy engine to report on the geographic locations of the queries (at county level or equivalent) and the nature of the queries in a consolidated way.</p> <p>Feedback:</p> <p>This looks like a nice application. I think I would include a pointer to the the technical approach that might be involved - it looks as though classical expert systems methods might be an appropriate way to encode regulatory constraints, tank mixes and so on. Representing all the relevant knowledge in a way that can be checked and modified by agronomists, while offering clear advice to farmers, should be an interesting challenge.</p>"},{"location":"NIAB.html#2020-projects","title":"2020 projects","text":"<ul> <li>Automating Crop Canopy Data Collection for Crop   Management</li> <li>Collecting Farm-sourced Data on Pest and Disease   Pressure</li> </ul> <p>NIAB is the UK\u2019s leading Crop Science research centre. Within our portfolio of research we develop digital models to describe and predict crop development. This has significant implications for agriculture and more widely with regards availability of food.</p> <p>We have a number of problems which I think would make interesting 1B projects and I was wondering what the process and timings are for submitting proposals?</p>"},{"location":"Navigating_Evolving_Music.html","title":"Navigating Evolving Music","text":"<p>Cambridge composer Ewan Campbell creates cartographic scores where the musical notes are curved and rendered over maps or other pictorial representations of nature. His next project is to use the evolution of musical ideas to reflect the processes of zoological development and mass extinctions. The arboreal subdivision of evolutionary trees very quickly renders traditional notational formats impractical for displaying the array of musical path options available for the performers. Your task will be to create a real-time continuously animating programme that is able to be run simultaneously by several different aligned performers, offering them live musical options, whilst allowing them to control their pathway. Your software will have an initial array of musical fragments to work with, but will also need to be able to accommodate new pieces written to use the software, and subsequently presented in live performances at the Cambridge Festival, where a new nature-based work by Ewan is being commissioned.</p>"},{"location":"Navigating_Natural_Performance.html","title":"Navigating Natural Performance","text":"<p>Potential clients: John Fanshawe John.Fanshawe@birdlife.org Ewan Campbell eahc2@cam.ac.uk</p> <p>Cambridge composer Ewan Campbell creates beautiful graphic scores where the musical notes are curved and rendered over map landscapes or nature photographs. At present these have to be translated into conventional music notation to make them playable, but your task is to create a continuously animated view controller that navigates around the score as it is played. Your software will be used in live performance at the Cambridge Festival, where a new nature-based work by Ewan is being commissioned in collaboration with Birdlife International.</p>"},{"location":"Network_queuing_analysis.html","title":"Network queuing analysis","text":"<p>(Pedro.estrela@imc.nl)</p> <p>The Objective of this project is to measure network queuing in a distributed network, by correlating packets between locations and between different identifiers domains. Currently large financial networks are monitored by means of network packet captures that are pushed to central or distributed databases. These databases contain the full lifetime of an opportunity, from receiving a public tick packet in location A all the way to send a private order packet in a different location B, including all the datacenters and all the transformations/processing in between. Assuming that these captures are accurately time synchronized, and there is auxiliary databases that contain the exact or approximate mappings between identifiers domains, it is then possible to accurately reconstruct the full lifetime of all the packets that took part in an opportunity, and statistically compare these to all other billions of packets, of all the other opportunities that passed thought the same network equipment or trading applications. Doing this correlation will enable to measure every single queuing effect in every single step of every single packet, which will enable to optimize and tune the current systems by removing the bottlenecks or increase capacity at the choke points.</p>"},{"location":"Network_queuing_analysis.html#feedback","title":"feedback","text":"<p>This one looks quite interesting, with a solid technical component. However, I had one question before proceeding - does your company have a dataset suitable for analysis, and would you be prepared to share this with the students on the team?</p>"},{"location":"Network_queuing_analysis.html#response","title":"response","text":"<p>We have an SQL database containing pre-decoded packets, captured in multiple WAN and MAN locations, over several days. These timestamps are all UTC PTP-synchronized http://tagus.inesc-id.pt/~pestrela/timip/Challenges_deploying_PTPv2_in_a_Global_Financial_company.pdf</p> <p>We are willing to share this dataset after some form of sanitization, which we'll do before our first meeting.</p>"},{"location":"Neul.com.html","title":"Neul.com","text":"<p>Proposed by Peter Cowley</p> <p>Concept based on the NeulNET TV white spectrum receiver.</p> <p>http://www.neul.com/</p>"},{"location":"Neural_Guide.html","title":"Neural Guide","text":"<p>The NeuralTalk Model Zoo provides pre-trained deep neural net models that can be used to generate text descriptions of unseen images. In principle, such sentence generation could be used to assist blind people, allowing them to point their mobile phone at a scene, upload the camera image to a server, and receive the predicted text as synthesised speech. The results are likely to be far less reliable than for images from the NeuralTalk demo database, so you will probably have to provide audio or tactile feedback on image quality, prediction confidence, and guidance to help the user point the phone in a more productive direction.</p>"},{"location":"Next-Generation_Museum_Guide.html","title":"Next Generation Museum Guide","text":"<p>Visitors to the Fitzwilliam Museum in Cambridge can currently use a handheld eGuide, deployed on PDAs with location sensing infrastructure from local company Hypertag. Your task is to design a next-generation guide aimed at an audience of eight-year olds. The device should enable users to guide the rest of their family around the Museum during their visit. It should also allow users to construct a thematic story inspired by a selection of museum objects. By combining the user's narrative with multimedia material, the system will automatically generate a personalised (HTML-based) videogame that users and their friends can later play online.</p>"},{"location":"Nigel_Day%2C_ENEA.html","title":"Nigel Day, ENEA","text":"<p>Reliable cycle-aware traffic light</p> <p>Most central Cambridge junctions snarl up at critical moments between lectures, with accidents, broken limbs and worse as students jump red lights after realising they are running late. Your task is to create a fault-tolerant traffic light controller (using a pair of Raspberry Pis with a hardware fail-over), that builds a traffic model based on weather data, university building management systems, bus timetables, and any other data sources that you can discover to accurately predict cycle volumes. This database should be combined with traffic sensor data to invent a new cycle-aware junction control model.</p>"},{"location":"Nominet_Trust.html","title":"Nominet Trust","text":"<p><code>-\u00a0last\u00a0contact\u00a0November\u00a02016</code></p> <p>Possible Cambridge candidate companies:</p> <p>Konnektis</p> <p>konnektis.com</p> <p>Konnektis enables collaborative person-centred care older people living independently by integrating the network of professional and informal carers. Konnektis a secure, web-based platform that runs on a dedicated 3G Internet-enabled tablet that stays in the home, becoming the enabling hub for secure real-time collaboration between carers and communication with the older person receiving care.</p> <p>Zephx</p> <p>zephx.com</p> <p>Zephx provides gaming solutions that transform the daily physiotherapy routines of children suffering with respiratory conditions from sources of conflict into fun and engaging experiences.</p>"},{"location":"Non-WEIRD_Data_Science.html","title":"Non WEIRD Data Science","text":"<p>Many data journalists report information collected from people who are Western, Educated, Industrialised, Rich and Democratic, but this \"WEIRD\" demographic does not represent the majority of people in the world. AfroBarometer collects data from 33 different countries on the African continent, and makes it openly available. Your task is to create a tool that maps datasets from AfroBarometer onto key current issues in the UK news media, helping readers in this country get a better global perspective.</p>"},{"location":"Novel_interactive_data_visualisations_and_UI_demo.html","title":"Novel interactive data visualisations and UI demo","text":"<p>BT - suggestion from Ben Azvine</p> <p>This brief appears more suitable for Part II or MPhil project - has been shifted there.</p> <p>BT\u2019s networks are a source of huge quantities of time-varying data which have many variables. A wealth of information can be extracted from such data, but initial exploration of the dataset may be formidable, particularly when the features of the dataset are initially completely unknown. There are a few standard means of data visualisation including trend graphs, bubble diagrams, network diagrams, pie charts, geographical maps, sun ray diagrams, and radial views. This project asks you to discover alternative Opensource visualisation techniques beyond these methods and to build an interface using one of these for the purpose of exploring a large, complex graph dataset visually in a way that allows discovery of correlations and clusters in the dataset (such as relatedness in a single or multiple category).</p>"},{"location":"Obex_Technologies.html","title":"Obex Technologies","text":"<p>I am very keen to submit a project for next year and I already have some ideas that I think would work well within the context of the project space.</p> <p>Alan's suggestion:</p> <p>Machine Learning to Brain Surgery</p> <p>Your client has worked with surgeons at Addenbrookes to create a national database of brain surgery, recording every \u201ccerebral shunt\u201d operation in the country. Straightforward unsupervised machine learning methods could be used to cluster the records in this database, and advise trainees or even experienced surgeons in the operating theatre. Your goal is to make a tablet or mobile app that could be deployed in an operating theatre, presenting intelligent advice about the current patient as decisions are taken - is this surgery likely to be typical for this surgeon, or this hospital, or have unusual factors been detected? Your solution must be secure as well as smart, because NHS patient data is carefully protected.</p> <p>Suggestion from 2016 that did not proceed:</p> <p>Pocket Brain Surgeon</p>"},{"location":"Ocado.html","title":"Ocado","text":"<p>2020 project: Feeding Body and Mind</p> <p>I have heard on the media that there are UK school children who don\u2019t get enough to eat during the day because they are not eligible for free school meals and because they don\u2019t have enough money to buy proper food.</p> <p>I therefore suggest we consider a group project which develops a system that enables the following:</p> <p>1. Donors (either individuals or companies or other organisations or a combination of individuals plus matched-funding by companies/charities) can donate money (with gift Aid where appropriate) 2. Schools can sign up to use the donated money to buy food (and recyclable cutlery/crockery) on Ocado.com or morrisons.com and someone at the school organises the purchases/deliveries 3. Children can come along to a \u201cclub\u201d where the food is given out 4. At the \u201cclub\u201d the children get to eat the food and also get to learn how to code using Ocado\u2019s \u201cRapid Router\u201d and \u201caimmo\u201d online games</p> <p>This addresses the hunger problem and educates the children in computer programming so that they can get reasonably paid jobs and their children won\u2019t have the same problem.</p> <p>Do you think that a Group could create enough software for the above to be set up and to start the initiative during the project?</p> <p>We could support this with - technical help concerning interfacing to Ocado.com to create online orders - technical help with App development - particularly if a cross-platform (iOS / Android) technology such as Dart and Flutter was used - other help as needed</p> <p>Possible idea to explore:</p> <p>it was interesting to hear about your new mobile turtlebots being introduced into Amanda Prorok\u2019s course. This opens up some potential for \u201cSim to real\u201d experiments / reinforcement learning /projects.</p> <p>It would be great if we could encourage the Cambridge Engineering and Computing robotics research teams to connect together to create an activity in reinforcement learning for legged robotics to endeavour to create a rival to \u201cAnymal\u201d http://www.rsl.ethz.ch/robots-media/anymal.html from ETHZ and the MIT Cheetah https://techcrunch.com/2019/03/04/mits-speedy-mini-cheetah-robot-learns-to-backflip/</p> <p>Feedback:</p> <p>We will think about how your sim-to-real concept might be adapted to the course, and what kind of robot hardware could be used. Past experience is that CS students have only limited hardware construction skill - we usually have to arrange for them to have assistance from a technician. There also seems to be a slight tendency for them to be scared off from robot projects, rather than stimulated. Last year we had to cancel the following two projects for lack of interest, despite the fact that they both seemed fairly entertaining to me:</p> <ul> <li>Visual Pick and Place</li> <li>Robot Death Watch</li> </ul>"},{"location":"Online_Identity_for_the_Base_of_the_Pyramid.html","title":"Online Identity for the Base of the Pyramid","text":"<p>Initiatives such as Girl Effect and StoryBank provide new content channels for the poorest people in developing countries to gain a visible online identity. How could you minimise the educational and financial obstacles to their visibility in the global media ecosystem? SMS hubs such as Frontline SMS, or village kiosks containing Raspberry Pi with cameras? Are keyboards or screens essential? You'll need to consider user literacy and appropriate interaction mechanisms for those whose technical expertise may be limited, but who will be empowered by gaining new skills. Finally, don't forget that having a voice is not sufficient to have an identity - somebody has to hear it.</p>"},{"location":"Online_Loop_Jam.html","title":"Online Loop Jam","text":"<p>David Russell, The Fusion Works david@thefusionworks.com</p> <p>While many activities in Cambridge have transferred reasonably smoothly to the online world, music has not at all. It\u2019s not even possible to sing Happy Birthday properly via videoconference, let alone coordinate choirs or band rehearsals. The Web RTC standard does provide support for time synchronisation of asynchronous messages, so together with interfaces such as Web MIDI, it should be possible to get better-timed music performance. Of course latency doesn\u2019t go away (we still have the speed of light to deal with) so music made online can naver be like playing in the same room. Instead, we need music that can be played in cycles, so that each player contributes content that sounds good to their own ears now, and still sounds good after a fixed loop interval (perhaps 4 bars, perhaps 12, or even the next song verse), when the same notes are distributed and mixed in to the jam that everybody hears slightly later.</p>"},{"location":"Online_Programming_Game.html","title":"Online Programming Game","text":"<p>lex.vanderstoep@imc.com</p> <p>To teach beginning programmers problem solving and coding skills, we would like you to build an online programming game platform. The idea is for players to program bots which play a multi-player move-based game (e.g. Battleships, Snake, Pacman). The platform should expose a simple API through which the players can retrieve the current state of the game, and publish their next move. It should then display these moves into a visual representation of the game, allowing players to see how their bots are doing.</p>"},{"location":"Online_Ticking_Markbook.html","title":"Online Ticking Markbook","text":"<p>We have various systems in use to administer ticks, from paper to custom systems\u00a0 Students need a single place to view all their pending and awarded ticks, and DoSes need a view of their students\u2019 progress. There also needs to be a simple interface to requesting an extension and getting the relevant approvals (DoS, then department). Your task is to build a web-based system that can be used to bulk upload ticks either manually or from an automated ticker, presenting the right information to the right people, and allowing individual edits from authenticated individuals.\u00a0</p>"},{"location":"Online_advice_assistant.html","title":"Online advice assistant","text":"<p>dhardcas@amazon.co.uk</p> <p>The Citizens Advice Bureau is an organisation that helps people find information relevant to problems in their lives. A major area of activity is telephone advice consultations, at the end of which the caller might be directed to a website with information leading to assistance - for example, a family law practice or a social welfare agency. Your goal is to create a service that might be more comfortable for younger people, based on anonymous online chat rather than phone lines. The goal isn't to make an intelligent chatbot, because human contact is important to people with problems, but you could help make the process more efficient, for example by directing either callers or advisers to suitable parts of earlier conversations that seem relevant. Remember that a simple Google search won't work here. People describe their problems, not the answer they are looking for, and there are many commercial websites that aim to exploit people with problems rather than offer them neutral advice.</p>"},{"location":"Oodle.html","title":"Oodle","text":"<p>14 October 2021: Please keep us on your list for next year! Hopefully by then things will be much calmer and more predictable!</p>"},{"location":"OpenMarket.html","title":"OpenMarket","text":"<p>Contact via Jan Samols</p>"},{"location":"Open_Book_Publishers.html","title":"Open Book Publishers","text":"<p>Nik Sultana ns441@cam.ac.uk</p> <p>\"J.R.J. Gatti\" rupert.gatti@openbookpublishers.com</p> <p>Proposal: The technical textbook of the future</p> <p>Original discussion:</p> <p>We're still working out the details of the project, but this is an idea of what we have so far. Despite the original constraints on books (imprimaturs, etc), they have served as a force of liberation for people and the information which empowers them. Books have evolved over the last years as they migrated to e-reader platforms (Kindle, tablets, etc) but they are still somewhat attached to the old paradigm (in which a publisher fixes a book's appearance).</p> <p>We are thinking of proposing to build a platform where books can be taken apart, annotated, (and having annotations on annotations), and hyperlinked (to other books, annotations, sentences within books, videos on youtube, etc).</p> <p>Despite serving as a liberating force, it's somewhat ironic that books themselves are being bound behind DRMs and suchlike. We want our proposed project to fit the open-access paradigm quite well (e.g. if a book is distributed under a Creative Commons CC-BY license), to facilitate making mash-ups and extensions/modifications of books.</p> <p>Wikis, CMSs, and blog systems are too coarse or unstructured to implement this, but could serve as a basic technology on which to build. The target user of this technology is anybody who uses books (students, lecturers, but even casual readers). Ideally the resulting code from this project would be distributed as open source.</p> <p>There are still some ideas to pin down, in order to ensure that the project is defined-enough to make it feasible. There is something for everybody in such a project (e.g., theoretically-inclined students can play with graph algorithms, systems-include people can tune the engines, and graphically-inclined people can sharpen the UX).</p>"},{"location":"Open_Book_Publishers.html#feedback","title":"feedback","text":"<p>Perhaps it would be worth trying to start from the other end. Amazon's Kindle was an explicit attempt to create a more book-like experience as a counter to generic digital web platform. It doesn't seem like you're trying to be *more* book-like than the Kindle - so for people who like books, what will they gain from the trade-off of adding more complexity to the Kindle? Is the ability to add annotations a compelling proposition for Kindle customers? Who do you see being the market for that capability?</p>"},{"location":"Opposing_Views.html","title":"Opposing Views","text":"<p>eashton@frontier.co.uk</p> <p>Many people increasingly exist in an ideological bubble, getting all their news from a handful of sources that they trust and shunning everything else. This leads to polarised, insular viewpoints, stifling debate and increasing divisiveness. Your task is to make a web browser plugin which encourages users to read about a story from multiple angles. When reading an article, it can suggest an alternative, opposing source for the same topic. It needs to be able to categorise stories so that it can recognise the same topic in different publications, categorise sources so that it can find an interesting alternative stance (ideally not just how left- or right-leaning it is, but also things like the background of the author, the size and age of the publication, the tone of the articles), and also present this to the user in a way which will circumvent their defensive instincts and encourage an open mind.</p>"},{"location":"Optimising_Music_Notation.html","title":"Optimising Music Notation","text":"<p>The LaTeX typesetting system can be used to render many alternative styles of document from a master text specification. In contrast, music typesetting systems like Sibelius make all music look much the same. Your client has designed an optimised alternative style for music notation that has been found to improve performance. Your task is to define a specification language for these modifications, and implement a rendering pipeline either as Sibelius extensions, or using an open source music rendering back-end such as PMW (whose author, Philip Hazel, will be available as a consultant to the project).</p>"},{"location":"Optimising_Scores.html","title":"Optimising Scores","text":"<p>The LaTeX typesetting system can be used to render many alternative styles of document from a master text specification. In contrast, music typesetting systems like Sibelius make all music look much the same. Your client has designed an optimised alternative style for music notation that has been found to improve performance. Your task is to define a specification language for these modifications, and implement a rendering pipeline either as Sibelius extensions, or using an open source music rendering back-end such as PMS (whose author will be available as a consultant to the project).</p>"},{"location":"P2P_Social_Network.html","title":"P2P Social Network","text":"<p>Social networks are a major part of our lives. The acquisition of Twitter by Musk demonstrates how much influence one person can express by changing the platform to his liking where users have no say in the direction of the platform. Your assignment is to create a peer 2 peer honest social network: a social network that has no central server that anyone can join freely. You'll need to find or define a protocol that allows users to communicate. Will you go truly peer2peer? Or would you prefer a node-based approach where any server can join the network and serve requests for users? It's important to ensure that users cannot imitate each other. How do you prevent a hostile actor from joining the networking and pretending to be someone else? There's no central authentication server to verify this. Your solution should include a GUI that allows for browsing user accounts. How would this work? How do you fetch information about a user if there's no central server to provide that, and should there be any restrictions?</p>"},{"location":"Palantir.html","title":"Palantir","text":"<p>Interested in good cause initiative</p> <p>Previous correspondence: Palantir Technologies</p>"},{"location":"Palantir_Technologies.html","title":"Palantir Technologies","text":"<p>Laura Frankish lfrankish@palantir.com</p> <p>Introduction from Miklos Danka mdanka@palantir.com (Disney pico-projector project)</p>"},{"location":"Paper_Simulator.html","title":"Paper Simulator","text":"<p>Artisanal paper-making is an enjoyable hobby, and popular craft skill ranging from high-end art paper to unique personal notebooks. Cambridge has some of the world\u2019s leading paper researchers, who study the microstructure of the paper in historical books and documents. The goal of this project is to create a physical simulator that models the fibres, fluids and forms of a traditional paper making process. The result will be not only a valuable scientific tool, but potentially a popular plug-in component to the many painting and drawing apps that offer a rather trivial range of simulated paper textures and background images.</p>"},{"location":"Password_and_privacy_protection_with_Pi.html","title":"Password and privacy protection with Pi","text":"<p>Few children (or even adults) really understand what makes a password secure, or how to keep their online information safe. Your task is to create a simple set of password cracking and message encryption/decryption tools that children can run on the Raspberry Pi, together with a scripting language or GUI for them to run simple statistical experiments to understand what factors make their messages more secure. Children love code-breaking, so it should be easy to make this into an entertaining Raspberry Pi game, not just boring school work.</p> <p>Category:Raspberry Pi</p>"},{"location":"Pebble_Jogging_App.html","title":"Pebble Jogging App","text":"<p>dfang14@bloomberg.net</p> <p>We would like you to make a hazard warning app on the smartwatch Pebble. When a user takes their Pebble for a jog, he/she can record GPS location and details of any potential hazard they come across on the road, such as broken pavement, dog dirt, flooding... After the run, they can pair their Pebble to a computer program or mobile app, and upload the data via an interactive map. This allows other Pebble users to download the data, and receive an alarm when they are near the hazard. The relatively constrained set of controls on the Pebble, and the constraint that the jogger will want to work quickly before cooling down, means that you will need to provide a intelligent text entry method.</p>"},{"location":"Personal_Ambiguator.html","title":"Personal Ambiguator","text":"<p>Studies](Centre_for_Gender_Studies \"wikilink\") ed575@cam.ac.uk</p> <p>Many areas of life such as housing, health, education and employment are subject to gender, racial and other biases that can be detected with machine learning classification systems. Your task is to identify potential bias in personal documents such as a CV, health record or university application, and then to use a generative neural network approach to tweak these documents (perhaps by adjusting text or selectively removing information) so that they cannot clearly be classified. The algorithm should be packaged in an interactive tool that allows people to write ambiguated personal documents, and also highlights and educates them about the sources of bias.</p>"},{"location":"Personal_Reality.html","title":"Personal Reality","text":"<p>mark.ogilvie@jagex.com</p> <p>It is often hard to \u201cread\u201d people in social gatherings. But virtual reality can help us understand the relationship between different personalities and social situations. Your task is to create a virtual reality environment, in which people can create models of their perceived self, using abstract objects of various shapes, colours and sizes to mimic how their self-perception changes under various influences. You might consider aspects of the five-factor model of personality, to assess how these are affected by the personality of other people in the same space. The result will be a new kind of social gathering, allowing people to meet and interact without the guessing games that are usually necessary to interpret body language and subtle social cues. You might add ways to model other individuals, showing how our personal observations differ from other people\u2019s models of themselves, and shape the data to deliver meaningful trends and conclusions to sociologists.</p>"},{"location":"Personal_status_server.html","title":"Personal status server","text":"<p>There are several ways that computers can \"read your mind\" by observing emotional state - measuring skin conductance, or even estimating pulse rate with a camera pointed at your face. A dedicated device like the Raspberry Pi could run its own web server, serving a single page that is modified according to the detected emotional state of the user. Of course, it should be possible to customise this behaviour with a simple end-user language, so that different texts or images are included in the page in response to different detected emotions. Finally, friends should be able to add their own supportive feedback to the page ... using appropriate security!</p> <p>Category:Raspberry Pi</p>"},{"location":"Personalised_EULA_Visualisation.html","title":"Personalised EULA Visualisation","text":"<p>moinul.zaber@gmail.com</p> <p>Nobody takes the time to read the End User License Agreements (EULAs) that we all agree to whenever we create an account, install an app, or upgrade an operating system. Different people have different priorities, and although some clauses buried in the EULA might relate to your own concerns about privacy, cost, warranty or whatever, it would take hours to read through and find them. This project will allow users to personalise their own priorities in advance, then use NLP to instantly visualise and navigate the parts of any new EULA that they most want to check - perhaps raising red flags to highlight all the most worrying phrases in a single screen view.</p>"},{"location":"Peter_Cowley.html","title":"Peter Cowley","text":"<p>'Peter Cowley' peter.cowley@camdata.co.uk</p> <p>Countryside web server</p> <p>A ruggedized version of the Raspberry Pi can be used for outdoor applications, like monitoring wildlife activity via analogue and digital inputs. The kinds of hobbyist and researcher who do this need to specify data capture via a rubberised keyboard and LCD display, but also make that data available more widely via popular websites. Your task is to design a system that allows users to configure battery-powered data capture and website structure in the field via the embedded display, but then turn the same device into a fully-functional web server with data visualisations when it is brought inside and plugged back into a network port. If required, you will also be provided with a licence for the ENEA Polyhedra realtime embedded database.</p> <p>Category:Raspberry Pi</p>"},{"location":"Photo-chef.html","title":"Photo chef","text":"<p>Take your phone to Cambridge market, and take a photo of the vegetable stall. Your application should recognise the vegetables, identify a recipe based on them, and provide you with a shopping list of the other things you need to buy before you go home to cook.</p> <p>Has been proposed as a basis for possible project with Arm, to demonstrate machine learning on mobile devices</p>"},{"location":"Physical_Computing_for_Beginners.html","title":"Physical Computing for Beginners","text":"<p>Children and other beginners can understand the computational concepts involved in physical computing (controlling electronics components) before they are ready for the technical APIs provided to control hardware devices. Your task is to design and prototype a visual language or interface for programming the Raspberry Pi Pico microcontroller that can be used by beginners. The language should use concepts that are close to the kinds of projects that beginners would want to create. Users might drag and drop components such as buttons and LEDs and then click on them to configure how they should behave.</p>"},{"location":"Pigment_Analysis.html","title":"Pigment Analysis","text":"<p>Institute](Hamilton_Kerr_Institute \"wikilink\") cp574@cam.ac.uk</p> <p>Painting conservators at the Hamilton Kerr Institute often identify pigment substances in paint by analysing microscope images. They need a tool that enhances their expert judgment, using computer vision algorithms from the OpenCV library to automate mundane classification tasks. This interactive tool should provide a structured and flexible decision process that optimises search for the most likely substance, by allowing the conservator to quickly eliminate unlikely possibilities, and to focus on those properties that seem most ambiguous or problematic for any particular sample.</p>"},{"location":"Planet_Builder.html","title":"Planet Builder","text":"<p>Client is Matt Johnson, Frontier mjohnson@frontier.co.uk</p> <p>In large-scale space exploration games such as Elite:Dangerous, No Man's Sky and Star Citizen, procedural algorithms are used to generate planets. Your goal is to create a new tool that will help game authors, or even enthusiastic players, to create new alien worlds. You'll need to think about how to control terrain, settlements, life-forms and so on in a way that provides creative control while also being fast and efficient. The visual quality doesn't need to equal that of professional games (you might target delivery on a low-cost platform such as Raspberry Pi), but you should aim to provide a creative tool in which users have a dynamic preview of their work in progress as well as intuitive ways to define and adjust it.</p>"},{"location":"Planning_Tools_for_Large_Scale_Location_Tracking.html","title":"Planning Tools for Large Scale Location Tracking","text":"<p>Pete.Steggles@ubisense.net</p> <p>Our sensor system (https://www.ubisensedimension4.com) can be used to locate tools and cars on production lines, storing measurements and derived locations for audit purposes. Every day each factory generates ~2e8 locations from ~1e9 raw measurements. There is an environment-dependent function from tag-to-sensor distance/bearing to sensor measurement probability/error, and an environment-independent function from a set of sensor measurements/errors to the probability of a \u2018good\u2019 tag location. Your task is to use the stored data to characterize these functions, compare them across sites, and build a planning tool to optimize future installations.</p>"},{"location":"Planning_tools_for_Large_Scale_Location_Tracking%281%29.html","title":"Planning tools for Large Scale Location Tracking(1)","text":"<ol> <li>REDIRECT Planning Tools for Large Scale Location     Tracking</li> </ol>"},{"location":"Pocket_Brain_Surgeon.html","title":"Pocket Brain Surgeon","text":"<p>Technologies](Obex_Technologies \"wikilink\") m.j.gifford@mountainhare.com</p> <p>Brain surgery is difficult, but some procedures are quite routine. The surgeon could have an Android app with some understanding of the different options at each step of the procedure, that would advise on the best option at each step, based on statistical likelihood of success. The necessary raw data for these decisions is probably available in national data archives such as the UK Shunt Registry in Cambridge. However, this data is highly sensitive and confidential. You need to design a system that allows brain surgeons to authenticate themselves online before they go into the operating theatre, then download an encrypted data set that can be used to deliver customised guidance from their phone during surgery. Needless to say, the user interface is rather critical - the progress of the surgery must be communicated to the system without interrupting anything important, and any questions about what to do next involve minimum button presses before an answer is delivered (perhaps by speech output, from underneath the surgeon's sterile gown).</p>"},{"location":"Potential_Difference.html","title":"Potential Difference","text":"<p>With regard to Project Darknet - Potential Difference are dedicated to exploring science, technology and theatre crossover</p> <p>Contact: Russell Bender russellpbender@yahoo.co.uk</p>"},{"location":"Predictive_aircraft_maintenance.html","title":"Predictive aircraft maintenance","text":"<p>adam.durant@satavia.com</p> <p>Local company Satavia helps airlines and aircraft engine manufacturers to schedule maintenance based on the amount of exposure the components have had to air pollution, dust, ice, volcanic ash and other environmental factors. They have large data sets which could be used to train predictive models that might be added to the Microsoft Cortana Intelligence Solution Template Playbook (assistance from Microsoft Research will be available) for predictive maintenance in aerospace. You will need to deliver a data ingestion architecture for a range of global data, and also demonstrate an aircraft maintenance scheduling application based on machine learning that applies the results.</p>"},{"location":"Previous_ideas_that_have_not_been_used.html","title":"Previous ideas that have not been used","text":"<p>Most of these were eventually not offered because we could not find an interested client. Many of them are either fun or feasible, and we're happy to consider using them in future.</p>"},{"location":"Previous_ideas_that_have_not_been_used.html#2017","title":"2017","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#virtual-reality-cylinder-seal","title":"Virtual Reality Cylinder Seal","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#2016","title":"2016","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#message-to-the-future","title":"Message to the future","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#liker-bot","title":"Liker-bot","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#2015","title":"2015","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#machine-morse","title":"Machine morse","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#marker-of-the-beast","title":"Marker of the Beast","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#2014","title":"2014","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#digital-sheet-music-viewer","title":"Digital Sheet Music Viewer","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#rent-a-mob","title":"Rent-A-Mob","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#zombie-for-a-day","title":"Zombie for a Day","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#raspberry-pi-orchestra","title":"Raspberry Pi Orchestra","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#robot-bartender","title":"Robot Bartender","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#checkmate","title":"CheckMate","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#graphical-programming-for-budding-engineers-on-raspberry-pi","title":"Graphical Programming for Budding Engineers on Raspberry Pi","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#low-energy-ecc-elliptic-curve-cryptography-library","title":"Low energy ECC (Elliptic Curve Cryptography) library","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#application-for-the-new-32-bit-xap6-processor","title":"Application for the new 32-bit XAP6 Processor","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#locally-augmented-retail","title":"Locally Augmented Retail","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#cambridge-overlay","title":"Cambridge Overlay","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#2013","title":"2013","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#fix-the-past-with-raspberry-pi","title":"Fix the past with Raspberry Pi","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#transparent-public-identity","title":"Transparent public identity","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#raspberry-pi-orchestra_1","title":"Raspberry Pi orchestra","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#infect-your-friends","title":"Infect your friends","text":""},{"location":"Previous_ideas_that_have_not_been_used.html#mashup-tutorial-builder","title":"Mashup tutorial builder","text":""},{"location":"Privacy_International.html","title":"Privacy International","text":"<p>Introduction to come from Ross Anderson</p> <p>Here's an idea. I was at the Europarl yesterday and a green MEP said it would be great to have a \"tranparency app\" that would enable her and her colleagues to look up the registered interests of people who come to meetings. This would involve (a) writing apps for android and iphone (b) having a service that would go to the various registers of interests in Brussels, London etc, aggregate entries and make them available (c) some smarts to make it usable. For example it would help that if Mr Johann Schmidt were registered as getting funding from Infineon AG, that the app would say that Infineon makes smartcards for use in banking and as identity cards.</p>"},{"location":"Probable_Causes.html","title":"Probable Causes","text":"<p>Theo.Mauger@morganstanley.com</p> <p>The probabilistic programming stack developed by Mansinghka\u2019s team at the MIT AI Lab promises to deliver data science capabilities to a much broader range of users. Your task is to customise the bayeslite implementation of BayesDB to make an accessible and interactive tool for use in public debate, allowing more technically informed discussion of health and safety issues, for example among local administrators trying to improve bicycle safety in Nairobi, based on the data sets such as https://tinyurl.com/ybbj69cn</p>"},{"location":"Probably_Helpful_Planning.html","title":"Probably Helpful Planning","text":"<p>Foundation](Africas_Voices_Foundation \"wikilink\") luke@church.name</p> <p>It's hard to provide famine relief unless you can predict where it might take place. Your task is to build a front end to a probabilistic programming language (Stan) that allows models to be built to explore the likelihood of need based on factors such as weather and crop cycles, and to compare different intervention scenarios to produce plans. The results should be usable by UN aid workers. There will be an opportunity for members of the team to interact with a student team from Potsdam, also working with Africas Voices.</p>"},{"location":"Project_Darknet.html","title":"Project Darknet","text":"<p>russellpbender@yahoo.co.uk</p> <p>\"Darknet\" is a new experimental theatre production under development by a Cambridge graduate for performance next year. It explores computer hacking, cyber espionage and cyber warfare and aims to give the audience an experience of the dark side of internet use. We're not sure if this is legal*, but we've been thinking that we might use data from the theatre ticket booking system to mess with their minds at some point during the show and make them feel like they have been hacked. Your job is to build a system that helps us do this by any means you can think of. You can assume that there will be a data projector built into the set or lighting design, that there's a sound system, that we can change the script, and we can ask the audience to leave their phones on ... we have their numbers (and also their seats)!. It's up to you to create effects that will take the story somewhere a little creepy.</p> <ul> <li>(oh, alright \u2026 we'll ask their permission first)</li> </ul>"},{"location":"PromptPatrol.html","title":"PromptPatrol","text":"<p>Language models like ChatGPT and Claude.ai are becoming increasingly popular. These models affect every line of work, including student assignments. For some assignments, professors require students to hand in authentic work for their own personal development, not for the sake of handing in an assignment. In this project, you will design a system that is able to reliably detect text generated by LLMs in student assignments. User experience is a top priority; the system should be fast and simple to use. How will you test, measure or prove this? It should integrate seamlessly with the learning environment of Cambridge. The detection framework could use machine learning, but could an MVP use more simple approaches? What heuristics might determine if text is written by a human? Reports should offer statistics line-by-line, highlighting which parts are human-written or machine-written.</p>"},{"location":"Public_Robot.html","title":"Public Robot","text":"<p>Being proposed by Rachel Gardner, with Guy Laban from AFAR lab.</p>"},{"location":"Purchase_Abandonment_Predictor.html","title":"Purchase Abandonment Predictor","text":"<p>There are many online shopping sites where users become frustrated - they can't find what they want, get bored, or simply fail to complete a purchase. Retailers would be happy to help out such customers, if only they knew which ones were most likely to benefit. If you could predict which shoppers are about to abandon their shopping basket based on click stream analysis, then it would be possible to offer the customer incentives to stay on the site. Incentives could be discounts, pop-ups or contextual product recommendations.</p> <p>If successful, the system may be trialled on a large popular e-commerce site such as MyProtein.com, LookFantastic.com or IWantOneOfThose.com.</p>"},{"location":"Put_your_phone_to_work.html","title":"Put your phone to work","text":"<p>contact via Beth Gorman Beth.Gorman@gresearch.co.uk (later substitute Dominic.Nancekievill@gresearch.co.uk ?)</p> <p>When people browse social media sites on their phones for hours every day, most of the CPU power goes unused. The old desktop equivalent of this problem was the screensaver, which did little of value until it was co-opted for distributed computing projects such as SETI@home. Your task is to make a platform that can perform useful computation in the background on a large number of mobile phones, while the owners are on social media - or even while they are asleep. It will have to run cross-platform, perhaps using JavaScript, but must also give the appropriate incentives to users - will it drain batteries or incur network charges? If so, what kind of application would customers pay to run on such a platform? Would phone sensors offer any specific value? You need to demonstrate an end-to-end solution including servers, mobile clients and an example application, keeping in mind the security implications if either customers or phone owners try to cheat the system.</p>"},{"location":"Qualcomm.html","title":"Qualcomm","text":"<p>Contact is \"Scott, John (UK)\" scottj@qti.qualcomm.com</p> <p>'Tunmer, Luke' ltunmer@qti.qualcomm.com had proposed:</p> <p>Because the Pi is such a cheap computer, it seems it should be ideal for the increasingly discussed ideas of home-hubs, automated home and the internet-of-things. The Pi can play a dual role - the hub itself, and prototypes of small connected things. Software available for the Pi such as XBMC to power media centres, and Asterisk to enable voice/phone management seem to provide powerful hub capabilities, while the GPIO port on the board will open it up to be the prototypes for connected elements to all kinds of items in the home.</p> <p>I project which showed some real innovation in what could be achieved in the connected home could challenge a group of students with strengths in different aspects of computer science and user design.</p> <p>However, currently suggesting he may be client for Rule-tris introduction to programming</p>"},{"location":"RSPB.html","title":"RSPB","text":"<p>Project confirmed for 2022:</p> <p>Migration Simulation</p> <p>The Yelkouan shearwater is a bird that migrates through the Bosphorus to reach the Mediterranean, but nobody knows how many there are. Your client has video of the migration as seen from different distances and angles. Unfortunately computer vision algorithms can\u2019t be trained without ground truth count of how many birds are there. You will create a CGI simulator of the flocking birds, including realistic atmosphere and viewing conditions, to generate simulated video with known ground truth bird numbers. The final stage is to train a machine learning system using your simulation, and then test it on real migration video.</p> <p>Project confirmed for 2021: Computing for Bird Colonies</p> <p>Original suggestion:</p> <p>I would be interested to suggest a project as a client, that would allow wildlife managers to count bird calls automatically from acoustic recordings. Although there are several commercial packages available, the ones we have tried so far (Raven, Songscope, SoundID) are unsatisfactory (very high commission and omission errors) and all require substantial up-front investment in defining the variability of calls of the target species.</p> <p>Ideally, we would like a simple-to-use software tool (R package or GUI) that would allow users to upload recording files (in batches, as there will generally be hundreds), click \u2018run\u2019, and then download a table of the number of calls of different species in each recording file.</p> <p>There has been huge progress in the automatic detection of bird vocalisations in recent years (http://dcase.community/challenge2020/), but most of these high-end algorithms are not accessible to wildlife managers who generally do not have a programming background. So essentially we would be asking students to translate existing algorithms into an accessible platform that would work for wildlife managers in the field. We have many hours of recording from seabird colonies that can be used as training or test data.</p> <p>Initial feedback:</p> <p>Thanks very much for this suggestion, and I\u2019m sure it would be an area of interest to students.</p> <p>I\u2019m fairly familiar with this general field, having recently supervised a PhD that set out to improve machine learning tools for bird call identification by citizen scientists. Based on that experience, my understanding is that the main problem holding the field back is lack of segmented and labelled training data that has been collected in the same environmental context where the system is to be applied (the question of how a model trained with bird calls recorded in captivity can transfer to natural environment is probably one for researchers).</p> <p>I presume that your colony recordings haven\u2019t been segmented, but it might be interesting to train a model that aims to estimate colony size from acoustic characteristics, rather than counting and classifying individual calls. Do you have a range of recordings from colonies of different sizes? If there are a mix of species in a given colony, are estimates of the relative proportions available in your training data?</p> <p>My PhD student ended up creating tools for field recording and segmentation of bird calls with a mobile phone, and a game-based interface to educate and practice identification (neither particularly valuable in scientific terms, I\u2019m afraid).</p> <p>More details:</p> <p>Thank you for the feedback - yes, we have recordings from colonies of different sizes, and it is relatively straightforward to derive acoustic 'indices' for entire recordings (there are several R packages available), but these indices don't often correlate very well with the actual number of calls where we determined the number manually. Also, the relationship between colony size and vocal activity will vary a lot by species and is unlikely to be transferrable, so a more general tool that simply enumerates the number of calls will have much broader utility.</p> <p>You are right that the lack of segmented training data is a big problem, and one of the key issues of using any commercial software (which requires a big up-front effort, and manufacturers will always blame poor performance on the poor quality of your training data). However, my limited understanding of the more sophisticated algorithms now employed to automatically process acoustic recordings is that they can either harness recordings for thousands of species from xeno-canto or the Cornell Macauley library to identify species, or simply classify sounds without supervision and then return counts of distinct categories of calls. Basically, an unsupervised algorithm would first classify all the sounds in a recording into more or less coherent groups, then return a list of their abundance and some samples, which the end user can then use to select the species of interest (and to discard background noise, e.g. waves, cars, crickets, etc.).</p> <p>We have many recordings from seabird colonies where there is mostly 1 species present, which should be an easier and more feasible data set to work with than rainforest recordings with hundreds of simultaneously vocalising species.</p> <p>Further response:</p> <p>Thanks for confirming the technical constraints. This is certainly an interesting area, and a great opportunity for undergraduates to gain some experience of working with such valuable data. One possible outcome of these projects is that one or more members of the team, after gaining some familiarity with the problem through a group project, may wish to explore specific technical challenges in more detail either in a final year dissertation, or even through graduate research.</p> <p>I think your suggestion of starting with an unsupervised approach seems very appropriate, and it would definitely be interesting to consider the design of a tool-chain that makes experimental investigation of such data sets more convenient. We try to scope the projects so that different members of the team can contribute in different ways - for example some could work on segmentation, some on development of regression estimators, and some on interactive facilities for browsing, labelling or data enhancement</p> <p>I really like this demonstration (perhaps runs only on Chrome) https://experiments.withgoogle.com/ai/bird-sounds/view/</p> <p>As a demonstration of bioacoustics in creative applications I used to load this full-page on a large touch screen and \u201cplay\u201d the clustered vocalisations like a musical instrument!</p>"},{"location":"Race_the_wild.html","title":"Race the wild","text":"<p>Conservation Monitoring Centre Craig.Mills@unep-wcmc.org</p> <p>The UNEP-World Conservation Monitoring Centre wants to improve public engagement with wildlife conservation. One very successful approach is to help those interested in wild animals to learn more about their daily activities, and to imagine the environments that the animals have to survive in. The goal of this project is to create a game that runs on a mobile phone platform, allowing players to compare their own movements to those of wild animals that are fitted with satellite tracking devices. You are free to design a game scenario in any genre that makes use of play location data and animal tracking information.</p>"},{"location":"Ramping_Up_Sustainable_Crops.html","title":"Ramping Up Sustainable Crops","text":"<p>Charles Gentry, NIAB charles.gentry@niab.com</p> <p>Arable crops in the countryside around Cambridge rely on soil nitrogen, but many farming practices are wasteful of this critical resource, potentially leading to other environmental risks. Your goal is to use recent advances in satellite imagery and robot/drone application to implement optimisation algorithms for the Ramp Calibration Strip method. Real data can be used in to construct realistic field simulations, but there may also be an opportunity to engage with trial tests in an experimental field north of Cambridge.</p>"},{"location":"Rangespan.html","title":"Rangespan","text":"<p>Client contact: Jurgen Van Gael jurgen@rangespan.com</p>"},{"location":"Raspberry_Pi_Foundation.html","title":"Raspberry Pi Foundation","text":"<p>2023 project: Physical Computing for Beginners</p> <p>For 2024, Tracy suggested contacting Marc Scott: marc@raspberrypi.org</p> <p>2023 project followed discussion with</p> <p>Tim Regan tim.regan@raspberrypi.org</p> <p>Tracy Gardner tracy@raspberrypi.org</p> <p>Regarding possible experiment with a Mark Guzdial \"teaspoon language\"</p> <p>https://computinged.wordpress.com/?s=teaspoon&amp;searchbutton=Go%21</p> <p>Michael Morehouse might provide assistance if the language relates to image / film processing.</p>"},{"location":"Raspberry_Pi_Orchestra.html","title":"Raspberry Pi Orchestra","text":"<p>The Raspberry Pi is cheap enough that it could be used instead of instruments in a school orchestra. Each one needs a small speaker, but not necessarily a screen - either a mouse or keyboard can control sound synthesis. If some devices had screens, they could be used to \"conduct\" (via a shared network clock signal, with tempo variations as appropriate), or even distribute code for remote execution elsewhere. A technical approach to synthesising good quality sound can build on the source code for the recently released Sonic Pi, and networking ideas can be borrowed from international laptop orchestras (PB_UP offers code distribution): https://esp-mcmaster.wikispaces.com/Laptop+Orchestra+bibliography</p> <p>Category:Raspberry Pi</p>"},{"location":"Raspberry_Pi_orchestra%281%29.html","title":"Raspberry Pi orchestra(1)","text":"<p>The Raspberry Pi is an ideal platform for kids to learn more about computing with sound and video by working in social groups. Create a system that will allow a number of people in the same or different locations to play instruments of the Indonesian gamelan, producing a single music performance that can be heard by each of them. If a player needs to take a break,they can set their session to a robot mode, in which the appropriate notes are played at the right times relative to other players. Note that relative timing of the event streams, even in the case where no robots are playing, is likely to be a hard problem!</p> <p>Category:Raspberry Pi</p>"},{"location":"Rational_Trading.html","title":"Rational Trading","text":"<p>The valuation of investments according to their expected future value is a key part of our economy. Unfortunately, sometimes investment decisions are made as joke or in the absence of a justified reason, as in recent scandals over GameStop and Dogecoin. The goal of this project is to create an alternative investment platform in which every trade is securely associated with a reason for the valuation, including links to public sources. Other investors should be able to make judgements based on individual trends of the asset, overall markets trends and the aggregated assessments of the reasons given, based on natural-language processing methods, to help assess how serious the opportunity really is (i.e. if associated risk of investment is justified by the reasons given).</p>"},{"location":"Reading_the_Leaves.html","title":"Reading the Leaves","text":"<p>j.godding@gardin.co.uk</p> <p>Plant leaves are anatomically complex but can be structured in ways to make a digital model of the plant. In this project your goal will be to use time-lapse photography to render a 3D model of plants growing in a vertical farm in real-time; mapping a grid-search of chlorophyll fluorescence measurements and displaying phenotype properties such as leaf area and weight, calibrated against ground truth measurements.</p>"},{"location":"Real-pedia.html","title":"Real pedia","text":"<p>The training data for AI large language models mixes up Wikipedia articles with random text from social media trolls and commercial sponsors. Many voices are excluded, from the girls not being educated in Afghanistan, to the women who teach their own families all over the world. Your goal is to make an alternative wiki architecture, where the benchmark of authority is not who has the most money or followers, but the best reflection of those voices. You\u2019ll need to think about what motivates women to spend their time this way, what kind of devices they have access to, and what makes knowledge reliable. Your prototype might be a small start, but the AI of the future depends on a better way of understanding what is meaningful, and Wikipedia founder Jimmy Wales should be available to discuss this with you.</p>"},{"location":"Real-time_AI_research.html","title":"Real time AI research","text":"<p>Javier Gonzalez Hernandez, Amazon gojav@amazon.co.uk</p> <p>Machine Learning researchers often try multiple configurations of machine learning algorithms using libraries such as GPyOpt. The convergence resulting from different configurations is unknown in advance, but could be visualised in real time, while multiple alternatives run concurrently in the cloud. Your task is to create a control panel with architecture support that will allow researchers to monitor large numbers of simultaneous Python experiments, interactively shutting some down, or tweaking parameters via the user interface, in response to what they see.</p>"},{"location":"Real_Life_Arabic.html","title":"Real Life Arabic","text":"<p>Mother tongue literacy is a major problem for young people across North Africa and the Middle East. The classical Arabic they are taught is like an Italian learning Latin. Apps like Duolingo do not help learners connect with the everyday language. They need a language learning app that enriches their lives with \u201ckalamna\u201d - the Arabic for \u201cour words\u201d. Your task is to design an app with motivating game functionality that connects to the Arabic needed in real life.</p>"},{"location":"Recipe_Curator.html","title":"Recipe Curator","text":"<p>Cambridge Consultants</p> <p>One area of my life that could do with the addition of a bit of technology is recipe curation. I have a shelf full of cookery books, a few websites that I like, and I occasionally get given recipes by other people. I also have a veg box delivery with unpredictable contents, a desire to eat seasonal ingredients and try new recipes, a variable availability of cooking time, two daughters with a only partially overlapping Venn diagram of food fussiness and not a poor memory. What I'd like is some sort of database of recipes to which I can send queries such as \"Find me something that doesn't contain cabbage or tomatoes that takes less than 30 minutes to prepare\" or \"I've got kohlrabi in the veg box AGAIN, are there any recipes I haven't tried that might make something edible out of it?\" or \"I've actually got a couple of hours free to cook this weekend, what was that complicated Ottolenghi recipe I flagged two weeks ago to try later?\" The database needs to cope with the fact that ingredients can have different names but mean the same thing: e.g \"flour\" and \"plain flour\", and that \"1/4 lb\" and \"4oz\" are the same thing and equal to \"100g\" (and not 113g). It would be great if once I've chosen this week's menu, it could produce a shopping list I can plug into www..com, and it needs to have a high WAF, i.e. be usable by non-engineers."},{"location":"Reducing_food_waste_with_IoT.html","title":"Reducing food waste with IoT","text":"<p>vaiva@dovetailed.io</p> <p>15 million tonnes of food are thrown away every year in UK alone and almost 50% of this comes from our homes. It seems likely that Internet of Things (IoT) devices, mobiles and wearables could be used to detect and avoid some causes of this problem, for example by sharing surpluses or reducing stockpiles by sharing \u201cbuffers\u201d of food between neighbours. Your task is to recover some traditions of sharing food among neighbours, with a community platform that enhances social connections through sharing food. Your client will provide a prototype of one novel IoT device - \u201cSpare Bite\u201d (www.sparebite.com), but you should also consider the ways that other connected devices may contribute - iPads used in the kitchen for online references, or even the infamous Internet Fridge.</p>"},{"location":"Refinitiv.html","title":"Refinitiv","text":"<p>I would indeed love to get Refinitiv and the London Stock Exchange Group (we are merging at the moment) to engage with the group projects. We have a 60PB treasure trove of data and tools that students could theoretically play with, including the high interest area of ESG.</p> <p>Response:</p> <p>Do you think that it might be an interesting challenge for students to engage with some of the infrastructure design questions too? For example, I expect your day to day work with that data relies on high-end compute and networks. We could ask students to create scalable toolchain for any range of specification - perhaps down to a Raspberry Pi, or low-end Android phone on a 2G data connection (a typical scenario in Ethiopia)?</p>"},{"location":"Reinfection_Monitor.html","title":"Reinfection Monitor","text":"<p>Intelligence](BAE_Systems_Applied_Intelligence \"wikilink\") james.dickin@baesystems.com</p> <p>A constant problem for PC owners is that, even after someone helps them remove a malware infection, they soon repeat the same action that caused the infection in the first place. And because malware doesn't usually advertise its existence, the user never learns how to stop it happening. The goal of this project is to create a network monitor dongle (possibly prototyped on a Raspberry Pi) that can simply be inserted as a router between the PC and home router, and will identify the network traffic that is characteristic of a particular piece of malware. It can be configured and left in place by the technician who cleans up an infection, and will send that person an email as soon as a reinfection is spotted (of course, it should also notify the user, provide a visible warning on the unit itself, and provide a local status report that can be accessed from a browser, with details helping users to understand what has happened). Some knowledge of networking on Linux will be required.</p>"},{"location":"Reliable_cycle-aware_traffic_light.html","title":"Reliable cycle aware traffic light","text":"<p>Most central Cambridge junctions snarl up at critical moments between lectures, with accidents, broken limbs and worse as students jump red lights after realising they are running late. Your task is to create a fault-tolerant traffic light controller (using a pair of Raspberry Pis with a hardware fail-over), that builds a traffic model based on weather data, university building management systems, bus timetables, and any other data sources that you can discover to accurately predict cycle volumes. This database should be combined with traffic sensor data to invent a new cycle-aware junction control model.</p> <p>Category:Raspberry Pi</p>"},{"location":"Remote_Animal_Recovery_Monitoring.html","title":"Remote Animal Recovery Monitoring","text":"<p>hr264@cam.ac.uk</p> <p>Like humans, dogs often suffer from injuries and joint problems but, unlike humans, there is no data resource to monitor postoperative recovery in small animals. Your task is to create a mobile phone app enabling dog carers to monitor progress of their dogs during revovery after orthopaedic surgery, provide information on what to expect, and connect them with their consultant. You will work with a leading veterinary orthopaedic surgeon specialising in treatment of these conditions, with the potential to significantly improve the quality of life for many animals with this new form of remote patient support.</p>"},{"location":"Remote_Reading.html","title":"Remote Reading","text":"<p>lex.vanderstoep@imc.com</p> <p>In recent times, many small children are more likely to have multiple smartphones in their house than multiple grandparents. Can multiple phones, tablets, TVs and laptops be used to provide some physical experience of cuddling up in an armchair while somebody far away reads a picture book? Grandparents often have only a single device, so other aspects must be simulated. Can the reader\u2019s voice be recorded for future replay (using voice recognition to synchronise to page turns and allow special requests)? And if the book is digital, can children add their own pictures (either drawing or photos) and offered in an online library for all to enjoy?</p>"},{"location":"Rent-A-Mob.html","title":"Rent A Mob","text":"<p>Contact: Matt Johnson mjohnson@frontier.co.uk</p> <p>Create a structured framework with a rudimentary graphical display which allows the loading of scripted scenarios, consisting of environment information, objects, targets, and properties, and also allows the loading of externally authored \u2018Bots\u2019 to function and execute objectives within the given environment.</p> <p>The framework will offer these bots access via an API to information about the environment and other bots within it. The purpose of the application is to provide a workbench to trial different programmed AI\u2019s, and strategies to navigate to targets and achieve a goal, either alone, as a crowd of either one type, or a mixture of different types of bots.</p> <p>At least two different examples of bot logic should be provided along with the framework to demonstrate it\u2019s functioning.</p>"},{"location":"Resilient_and_Rapid_Raspberries.html","title":"Resilient and Rapid Raspberries","text":"<p>Dominic.Nancekievill@gresearch.co.uk</p> <p>In today\u2019s world of high frequency trading, understanding the rapidly changing quotes from a myriad of trading algorithms is a colossal data processing problem. With tens of thousands of updates per second in a single market, and limited space and power constraints, it is important to be able to maximise throughput and resiliency with the hardware available. Given a day of actual stock exchange data, your challenge is to create a cluster to process and aggregate the data. Doing this with real hardware is more fun - we can\u2019t give you our data centre, but we can supply you with a Raspberry Pi cluster.</p> <p>Dynamically dealing with hardware failure, visualisation of the order book, automated deployment and performance statistics are all areas that you can explore.</p> <p>We have supplied the Computer Lab with some additional notes indicating where you can find sample data to work with and giving a little background information. Please collect a copy of these notes (and some Raspberry Pis and other kit) before getting started.</p>"},{"location":"Resilient_and_Rapid_Raspberries.html#additional-notes","title":"Additional Notes","text":"<p>Firstly, you will need some sample market data to work with. The New York Stock Exchange (NYSE) have a page describing their ARCA feed at http://www.nyxdata.com/page/1084. At the bottom of the page are two tabs: \u201cSpecifications\u201d and \u201cSample Data\u201d. Download everything from both, then follow the instructions in \u201cNYSE Arca Integrated Feed Sample Data Directory Layout\u201d to download the sample data.</p> <p>The specifications provide all the information required to decode the sample data, however they are written for an audience with a basic understanding of how financial markets work. See \u201cA Brief Introduction to Financial Market Data\u201d below for a few notes which might be worth reading before getting started with NYSE\u2019s spec.</p> <p>Architecture-wise, it\u2019s OK to write something on an ordinary PC to read the sample file and distribute messages from it over a network. You can then use the Pis to pick up the messages, display order books and compute analytics. You do not necessarily have to write a decoder for every message type in the specification \u2013 the lion\u2019s share of the messages will be trades and order book updates, these are the most interesting things to visualise or compute analytics from but they only use a small number of the message types.</p>"},{"location":"Resilient_and_Rapid_Raspberries.html#a-brief-introduction-to-financial-market-data","title":"A Brief Introduction to Financial Market Data","text":"<p>The data in the sample file is an example of the market data an electronic trading system would receive from the NYSE Arca exchange during a trading day. Messages in the other direction (orders from the electronic trading system to the market) are not included. Market data messages generally serve one of three purposes:</p> <ol> <li>To update clients on the current state of the market, e.g. \u201cthe     market is now open\u201d, or \u201ctrading in Vodafone shares has been     temporarily suspended\u201d.</li> <li>To indicate when trades have occurred, e.g. \u201c200 shares of Vodafone     have been traded at a price of \u00a32.22/share\u201d.</li> <li>To describe the current state of the order book for each product     traded on the market (more on order books below).</li> </ol> <p>Most financial markets use some variant of a central limit order book. The easiest way to explain this is by example:</p> <p>Suppose I want to buy 1000 shares in Vodafone and I\u2019m willing to pay up to \u00a32.21/share. I would send an order to the exchange saying as much. To begin with the exchange doesn\u2019t have a seller willing to sell to me so it records my order on the order book for Vodafone and disseminates it to all market participants via the market data. The order book has a bid side (indicating potential buyers with how much they want to buy and what price they\u2019re willing to pay) and an ask side (indicating the same for sellers). After my order the book looks like this:</p> <p><code>No\u00a0Ask</code> <code>--</code> <code>Bid\u00a01000\u00a0@\u00a0\u00a32.22</code></p> <p>Now suppose someone is willing to sell 500 shares but they won\u2019t take less than \u00a32.24. Their order doesn\u2019t match mine because we disagree on price, so their order goes onto the book too and it looks like this (note that this isn\u2019t a terribly good way to visualise an order book \u2013 just one that works in email where any formatting I add may be mangled \u2013 you can do better in the visualisations you\u2019ll write for the Pis):</p> <p><code>Ask\u00a0500\u00a0@\u00a0\u00a32.24</code> <code>--</code> <code>Bid\u00a01000\u00a0@\u00a0\u00a32.22</code></p> <p>Suppose another seller comes along with a better price, and another buyer offers a worse price. The order book is sorted by price so it might look like this (there have still been no trades):</p> <p><code>Ask\u00a0500\u00a0@\u00a0\u00a32.24</code> <code>Ask\u00a0800\u00a0@\u00a0\u00a32.23\u00a0(New\u00a0seller)</code> <code>--</code> <code>Bid\u00a01000\u00a0@\u00a0\u00a32.22</code> <code>Bid\u00a02500\u00a0@\u00a0\u00a32.17\u00a0(New\u00a0buyer)</code></p> <p>A bit of terminology before continuing: My order to buy 1000 @ \u00a32.22 is the highest bid price, which is referred to as \u201cbest bid\u201d. Similarly \u00a32.23 is the lowest sell price, \u201cbest ask\u201d. The best bid and ask prices are collectively called \u201ctop of book\u201d or \u201ctouch\u201d. The difference between the two touch prices is the \u201cspread\u201d, currently \u00a30.01 in this example. Prices can be in fractions of a penny (although they aren\u2019t in my example) \u2013 the minimum price increment is defined by the exchange on a per-product basis.</p> <p>Now imagine I decide that actually \u00a32.23 is not such a bad price and I really do want to buy Vodafone shares so I\u2019m willing to pay it. I would cancel my order for 1000 @ \u00a32.22 and place a new order for 1000 @ \u00a32.23. The exchange will not normally disseminate a book where the best bid and ask prices overlap (this is called a locked book if the prices are equal or a crossed book if best bid &gt; best ask \u2013 there are cases where it happens but if you see it happening all day long then your decoder is probably not working). Instead a trade happens. In this case what you would see in the market data is something along the lines of the following:</p> <ol> <li>My order for 1000 @ \u00a32.22 being cancelled.</li> <li>The existing sell order for 800 @ \u00a32.23 being executed \u2013 either one     execution message which removes it from the book and simultaneously     indicates that a trade of 800 shares at \u00a32.23 has occurred, or     alternatively some exchanges will send this as two messages, one to     remove the 800 shares from the order book and the other to indicate     the trade. You\u2019ll have to check the ARCA specification to see which     they do.</li> <li>The remaining 200 shares from my order being added (since my order     has only been partially executed).</li> </ol> <p>After these messages, the order book would look like this:</p> <p><code>Ask\u00a0500\u00a0@\u00a0\u00a32.24</code> <code>--</code> <code>Bid\u00a0200\u00a0@\u00a0\u00a32.23\u00a0(This\u00a0is\u00a0what\u2019s\u00a0left\u00a0of\u00a0my\u00a0order)</code> <code>Bid\u00a02500\u00a0@\u00a0\u00a32.17</code></p> <p>Category:Raspberry Pi</p>"},{"location":"ResponsibleAncestry.com.html","title":"ResponsibleAncestry.com","text":"<p>Older people often get interested in tracing their family trees on sites like ancestry.com. Perhaps it would be more useful if they spent the time planning for their grandchildren? Responsible ancestry.com should be a repository of traceable planning for the future, helping people to be responsible ancestors, so that the decisions they make about their lives today can be evaluated for their impacts on grandchildren and great-grandchildren</p>"},{"location":"Responsible_AI_Copilot.html","title":"Responsible AI Copilot","text":"<p>Marios Constantinides, Nokia Bell Labs marios.constantinides@nokia-bell-labs.com</p> <p>Many AI-driven applications turn out to have built-in biases, or problems of trust and transparency. In principle, developers could be warned of such problems as they write code, adding additional code to address the problems, recommending a specific debiasing algorithm, or adding inline comments or sticky notes that warn of need for future action. Your task is to provide such facilities in a modified version of Jupyter notebooks, perhaps using generative language models such as GPT-3 or OpenAI Codex to generate the relevant code and text output.</p>"},{"location":"Responsible_Construction.html","title":"Responsible Construction","text":"<p>Akvile.Valentukonyte@qualisflow.com</p> <p>Collecting accurate data about materials entering and leaving a construction site is essential to ensure minimal waste and climate-responsible behaviour. However, most of the available information arrives on paper documents or pdf receipts. Optical character recognition helps identify what is written on the tickets, but the challenge is reliably identifying actionable information like arrival times, certifications, and especially key data that has *not* been captured. Your task is to create a phone app that can instantly capture and advise drivers and gate staff, while populating a dashboard that can be presented to local residents on a public display.</p>"},{"location":"Retail_Category_Mapper.html","title":"Retail Category Mapper","text":"<p>leigh.simpson@fusepump.com</p> <p>Ecommerce retailers face a seemingly insurmountable barrier to being able to fully automate their online marketing activity. Many marketing channels, such as price comparison sites Google Shopping and Kelkoo, or marketplaces eBay and Amazon, require formatted product data, but each has its own format. Most retailers struggle to adapt their product data to these many distinct formats. This problem manifests itself mostly in the process of product category mapping: that is, the mapping of a retailer's list of product categories onto a different category taxonomy. This is an issue that has caused problems for some of the world's largest ecommerce companies. The aim of this project will be to develop an ecommerce-optimised tool that uses heuristic or statistical algorithms to takes an unmapped category (and potentially other product information) and output a proposed mapping and confidence level. A user interface will need to be created to allow human users to view a list of mappings by confidence level, make manual corrections to mappings, add to the training set, and view the progress of the mapping.</p> <p>As an example, this bicycle retailer example https://wiki.cam.ac.uk/cl-design-projects/Bicycle_retailer_example should be mapped to categories in http://www.google.com/basepages/producttype/taxonomy.en-GB.txt</p>"},{"location":"Retail_Startup_Automator.html","title":"Retail Startup Automator","text":"<p>Harry.Collard@thehutgroup.com</p> <p>Online retailers invest heavily in reformatting information from product catalogues into their own databases, and this is a barrier to entry for new businesses. But it should be possible to automate the startup process, by using artificial intelligence to extract the common data structure for standard products that get sold by dozens of different retailers. You must first create a machine learning algorithm that can automatically infer page templates by comparing product detail pages for the same product being sold on a variety of existing retail sites. Those templates can then be applied to extract the semi-structured data from retail sites for further products that have not been seen in the training phase. The resulting database will then be automatically published as a brand new shopping site, offering instant startup at the press of a button, allowing specialist entrepreneurs to cater for niche retail markets such as toothpaste-compare.com, muesli-and-sandal-world, or toysforhamsters.</p>"},{"location":"Rivos_Systems.html","title":"Rivos Systems","text":"<p>Tim Ramsdale timr@rivosinc.com</p> <p>Bring-up and optimisation of SYCL on a high-performance RISC-V platform - sponsored by Rivos and Intel. We could target it towards a specific application if desired, so we could give it some direct business relationship, and that would also give it some specific goals. I think it's a pretty interesting space - and it does have a real business purpose for us.</p> <p>We could certainly try and have a LLM/ChatGPT/other application running on-top of SYCL for example, and that could be prettified. Or anything relevant.</p>"},{"location":"Robot_Backgammon_Arm.html","title":"Robot Backgammon Arm","text":"<p>fciriell@mathworks.com</p> <p>Challenges in game theory the likes of Deep Blue and AlphaGo have inspired generations of AI enthusiasts and researchers. Your objective is to design, build and teach a robotic manipulator arm to play the classic game of Backgammon. Your team will be able to test their knowledge of robotics, computer vision, game theory and neural networks. The team will have access to a LEGO Mindstorms EV3 kit and a Raspberry Pi board &amp; webcams to design and build the system. MathWorks offers several hardware support packages for MATLAB and Simulink to simplify deployment of these kits and boards.</p>"},{"location":"Robot_Bartender.html","title":"Robot Bartender","text":"<p>Proposed by Raoul-Gabriel Urma rgu20@cam.ac.uk</p> <p>I have a fun proposal that would combine raspberry pie, robotics &amp; mobile programming.</p> <p>Essentially the students would have to build a remote controlled cocktail machine like this one: http://www.youtube.com/watch?v=hJIkJ9x0-JQ We could have it on display during Friday's happy hour.</p> <p>I think it could be challenging for the following reasons:</p> <ul> <li>build a system that takes orders from mobile phones (with a queue   system)</li> <li>processes a big list of recipe from the internet (crawling)</li> <li>programming with raspberry pie and electronic components</li> </ul> <p>There's even a startup who presented at techcrunch disrupt that is trying to do something similar: http://monsieur.co/</p> <p>Category:Raspberry Pi</p>"},{"location":"Robot_Death_Watch.html","title":"Robot Death Watch","text":"<p>Predictive](Faraday_Predictive \"wikilink\") will.boulton@artesis.co.uk</p> <p>Many kinds of domestic robot and home appliances rely on small motors that have an unknown time to failure. Your task is to create a monitoring system that uses voltage and current profile to predict number of cycles until a failure. This should be offered as an online service that can be used by the homeowner to order spare parts, or a contract maintenance company responsible for keeping the household running without hitches. The project will involve testing a number of motors to destruction in order to build machine learning prediction profiles.</p>"},{"location":"Robot_Farm_Monitor.html","title":"Robot Farm Monitor","text":"<p>Much of agricultural work is difficult and dangerous, leading to a labour shortage across the sector and an increase in robotics and automation on farms. Growers today commonly employ cutting-edge technologies including temperature and moisture sensors, robots, and GPS technology to perform the tasks that humans don\u2019t want to do. Your task is to design an app-based system that reports sensor data and health and safety information from our asparagus picking robot, over both The Things and Helium IoT networks.</p>"},{"location":"Robot_Science_Ambassador.html","title":"Robot Science Ambassador","text":"<p>Imagine a robot science ambassador at the Cambridge Festival that engages visitors in lively discussions about science and their experiences. This project will develop an embodied agent based on the world's most advanced social robot from Furhat Robotics, and using the LEXI framework for speech-based interaction. The system should allow customisation, so that users of all technical abilities can create and deploy their own AI agents able to interact naturally in spoken conversation in a variety of social settings. In the setting of the Cambridge Festival, the humanoid robot would be able to gather feedback, as well as enhancing visitor engagement.</p>"},{"location":"Robotic_Warehouse_Design_Suite.html","title":"Robotic Warehouse Design Suite","text":"<p>opowell@frontier.co.uk</p> <p>Online shopping is taking over the world! A current growth area is the use of robots and AI in efficiently running warehouses and retail storage facilities. Your task is to produce a virtual warehouse simulation and demonstrate how AI may be applied on this training suite to control bots in their storage and retrieval of randomised streams of orders for items to allow the suite to find efficient methods of organising and driving a robotic warehouse area. How AI is applied to the system, whether in terms of organisational control, or manipulation, or both is up to the teams to decide.</p>"},{"location":"Royal_College_of_Music.html","title":"Royal College of Music","text":"<p>Initial discussion of potential museum application with Gabriele Rossi Rognoni and Neta Spiro</p> <p>Exhibition Inference</p> <p>The Royal College of Music Museum has one of the richest collections of music-related objects in the UK and Europe, spanning over 500 years of musical activity. A new layout has just been created, and the museum needs to learn how visitors respond to it in order to refine the design in future. We suggest tracking (with permission) visitors who may use QR codes to access media or links from a specific exhibition case. Your task is to combine time-stamp records of QR access with dead reckoning from a phone's step counter, glimpses of GPS signal through the museum windows, prior knowledge of valid walking paths around the museum layout, and any other sources of data you can find, to get the best estimate of how visitors travel around the museum, as well as which exhibits they pause at and in which order.</p>"},{"location":"Royal_College_of_Paediatrics_and_Child_Health.html","title":"Royal College of Paediatrics and Child Health","text":"<p>2021 project; Clinical Nursing for Children</p>"},{"location":"Rule-tris_introduction_to_programming.html","title":"Rule tris introduction to programming","text":"<p>All kids love Tetris, so why not help them learn programming by making a Tetris-playing robot? You need to start with a simple Tetris port on the Raspberry Pi (code your own, or use an open source version), then add facilities allowing kids to \"play\" it automatically with the assistance of an interpreted rule language. This language can be applied by users to define piece rotations and movements based on queries of the current game state and simple algebraic expressions. The rule condition queries and actions must be sufficiently constrained that it would take significant coding effort to make an optimal player, but should also be simple enough to provide incremental feedback for students, so that each new rule (if correctly specified) produces satisfying improvements.</p> <p>Category:Raspberry Pi</p>"},{"location":"SEAT.html","title":"SEAT","text":"<p><code>Just\u00a0so\u00a0it\u00a0is\u00a0on\u00a0your\u00a0radar,\u00a0SEAT\u00a0who\u00a0recently\u00a0joined\u00a0the\u00a0Club\u00a0and\u00a0visited\u00a0the\u00a0Department\u00a0yesterday\u00a0are\u00a0interested\u00a0in\u00a0getting\u00a0involved\u00a0in\u00a0the\u00a01B\u00a0projects.\u00a0I\u00a0will\u00a0send\u00a0them\u00a0some\u00a0further\u00a0details\u00a0on\u00a0it\u00a0for\u00a0now.</code></p> <p><code>Ben\u00a0Karniely</code></p>"},{"location":"SMARTRI_Indonesia.html","title":"SMARTRI Indonesia","text":"<p>Local contact: Becky Heath rh862@cam.ac.uk</p>"},{"location":"SMART_Climate_Goals.html","title":"SMART Climate Goals","text":"<p>vkumar@ciff.org</p> <p>The COP26 conference has highlighted the need for decisive action on climate change, both for governments and companies around the world. But which of these are just talking, and which are setting concrete goals? Goals can be evaluated using the SMART framework (https://www.atlassian.com/blog/productivity/how-to-write-smart-goals). The SMART acronym stands for Specific, Measurable, Achievable, Relevant and Time-Bound. Create a system which can be used to analyse reports and statements, and identify climate change-related \"goals\" within them, and then evaluate these goals against the SMART criteria.</p>"},{"location":"Safer_Chicken_from_Farm_to_Fork.html","title":"Safer Chicken from Farm to Fork","text":"<p>Gerard.Hester@morganstanley.com</p> <p>The campylobacter bacterium is commonly found in the UK food chain, causing 22,000 hospitalisations and 110 deaths each year. It is important for schools to teach basic principles for avoiding infection in farms and shops or cross-contamination between uncooked chicken and other food or utensils. Your task is to design a distributed whole-class education app, in which everyone in the class must learn together what steps to take, acting at the same time. You could base this on the popular Crossy Road game, but adopting a farm and kitchen setting. The whole class should learn to cooperate in guiding a new-born chicken as it travels from farm to fork, making decisions based on what they have learned.</p> <p>Originally suggested by Andrew Grant, Vet School,</p>"},{"location":"Safer_social_media.html","title":"Safer social media","text":"<p>Young people with learning disabilities such as Down's Syndrome, ADHD or dyslexia are increasingly excluded from social media opportunities. Your goal in this project is to create a new front end for Facebook (using the Facebook API) to provide a straightforward set of social functions optimised for users who have very limited ability to use text in any form. Rather than the single-user mode of typical Facebook usage, it is also likely that a parent or carer may need to assist or review interactions. Your design should take account of this in a sensitive manner, including considerations of privacy and vulnerability.</p>"},{"location":"Sailing_by_sound.html","title":"Sailing by sound","text":"<p>People with visual impairments enjoy outdoor activities as much as we all do, and local sailing organisations are pleased to provide opportunities for disabled and visually impaired people to experience sailing. One disappointing limitation is that the standard navigation instruments (location, windspeed, compass heading etc) all have visual readouts, so visually impaired people are not able to participate in this central aspect of sailing. Your task in this project is to create an embedded device (you will have technical assistance with hardware - bdj23@cam.ac.uk) that uses a Raspberry Pi to communicate with navigational instruments using the NMEA2K standard, and provides users with speech output in response to commands given via a small number of waterproof buttons on the outside of the unit.</p>"},{"location":"Sainsbury_Laboratory.html","title":"Sainsbury Laboratory","text":"<p>Ioana Valea ioana.valea@slcu.cam.ac.uk</p>"},{"location":"Sainsbury_Laboratory.html#feedback-in-discussion","title":"Feedback in discussion","text":"<p>The machine learning methods that might be used to address your problem are reliant on large training data sets to be effective, and it's not clear that this could be done within the timeframe.</p> <p>On the most optimistic timescale, could we imagine project structure along the following lines?</p> <p><code>Week\u00a01\u00a0-\u00a0scoping\u00a0and\u00a0planning</code> <code>Week\u00a02-4\u00a0-\u00a0build,\u00a0program\u00a0and\u00a0test\u00a0the\u00a0image\u00a0capture\u00a0array\u00a0and\u00a0data\u00a0annotation\u00a0system</code> <code>Week\u00a05\u00a0-\u00a0collect\u00a0and\u00a0label/annotate\u00a0data</code> <code>Week\u00a06\u00a0-\u00a0train\u00a0machine\u00a0learning\u00a0system</code> <code>Week\u00a07\u00a0-\u00a0integrate\u00a0and\u00a0demonstrate\u00a0results</code></p> <p>Would 1 week of growing time be long enough to capture sufficient variety of images for your research question? This timescale would also require that your experts be available for data annotation / labelling to be done in parallel with the data collection.</p>"},{"location":"Sainsbury_Laboratory.html#project-proposal-for-phenotyping","title":"Project proposal for Phenotyping","text":"<p>Internal project description Goal is to take pictures of growing strawberries at different developmental stages to observe potential phenotypical differences in Biosensor/Highlighter transformed plants. The phenotypic traits include: \u2022 Leaf enrichment of 2-month-old plants, i.e. transition from vegetative to reproductive stage o how and where the next leaves emerge \u2022 Runnering vs. flowering o Does exogenous GA affect the switch between them? o Does runnering exclude flowering? \u2022 Flower development o Is flowering induced by blue light periods in the morning hours?</p> <p>\u2022 Fruit development</p> <p>Materials: Plant material are 2-months old strawberries grown in a pot. The time-lapse pictures must be taken in light and dark conditions over a long period of time: o Runnering/Flowering 2-4 weeks of data collection o Flowering/Fruiting 5-6 weeks of data collection</p> <p>Method: Arduino platform with control of light (array) LED lights in a growth chamber seem to work well. Lights and cameras (light and IR) must be under Arduino control. Humidity and room temperature can be regulated by the growth chamber. Cameras: three cameras per pot (light camera for side growth and from above, one IR camera from the side) At any one time at least two plants (WT vs. treatment/transformant) have to be able to be observed. If possible two pots per treatment, total at 4 pots at any one time is best. Each pot needs its own cameras and picture collection due to the analysis afterwards. Data analysis: Design a package for image-based tracking of strawberry development Jupyter/Python \u2022 Tracking of runner growth \u2022 Tracking of fruit development \u2022 Mature flower characterization Students should write code that could be eventually shared via the PlantCV/Fiji platform or use available one. The program must be able to identify and differentiate between runners, flowers, leaves and fruit. Also identifying colours and their intensity is important. Detecting size and changes in size is imperative. Being able to quantify changes in size and structure is important. E.g. different leaf shapes between treatments, different flower, fruit and runner sizes as well. Taking pictures with object identifiable by bare eye is also an important point.</p> <p>Course of action</p> <p>We will be firstly responsible for building a scaffold of how everything should be positioned in the chamber, students will be responsible for optimizing the positioning of cameras and sensors for optimal data collection. They will then continue with the Arduino programming and data analysis.</p> <p>Project advertisement draft for students:</p> <p>Are you interested in consulting for a team of international and energetic synthetic biologists at Sainsbury Laboratory to contribute developing a new phenotypic system for strawberries? We are currently designing an Arduino-based imaging set up to track developmental stages of woodland strawberry. We need you, a team of talented computer scientists knowledgeable in Python to develop the basic platform for the Arduino system and the subsequent image analysis preferably on PlantCV and/or Fiji.</p>"},{"location":"Satavia.html","title":"Satavia","text":"<p>Proposed with Microsoft</p> <p>Predictive aircraft maintenance</p> <p>Local company Satavia helps airlines to schedule engine maintenance based on the amount of exposure the components have had to air pollution, dust, volcanic eruptions and other factors. They have large data sets which could be used to train predictive models that might be added to the Microsoft Cortana Intelligence Solution Template Playbook for predictive maintenance in aerospace. You will need to deliver a data ingestion architecture for a range of global data, and also demonstrate an aircraft maintenance scheduling application that applies the results.</p> <p>Feedback:</p> <p>Unfortunately, I don\u2019t think that second year undergraduates have any significant technical knowledge of time-series analysis.</p> <p>They should be familiar with basic statistical regression, but will not have much understanding of machine learning techniques until third year. I don\u2019t believe that we teach much in the way of frequency domain analysis or autocorrelation methods in the Computer Science degree - these are topics that would be more typical of the signal processing courses taught in Electrical Engineering.</p> <p>I\u2019m afraid I can\u2019t advise on which features of Cortana would be most relevant to your problem, as I have not used the product myself. However, Google suggests that the \u201cCortana Intelligence Gallery\u201d might contain relevant stuff: https://gallery.cortanaintelligence.com/Experiment/Time-Series-Forecasting-8</p> <p>If I understand correctly, this example simply uses Azure to host an R script, but it should be relatively trivial for students to follow these instructions (if they found them!)</p> <p>So to make this into an interesting design challenge, we would need to give some thought to technical infrastructure, delivery mechanisms etc, that are appropriate for your user base. It\u2019s unlikely that any members of the team would have any prior knowledge of the aircraft maintenance industry, so we would need to come up with a relatively trivial use case that is sufficiently representative of the business issues to be interesting.</p> <p>Original suggestion:</p> <p>Environmental factors in the atmosphere, like dust, ice, sulphur, and volcanic, accelerate wear of aircraft components. Modern aircraft generate large volumes (several GB) of data per flight and digital predictive analytics technology has great potential to support asset health monitoring, and disrupt traditional maintenance and flight planning processes. The solution combines high spatio-temporal environmental factor analysis with machine-learning to provide advanced risk-based decision-making capability.</p> <p>Data driven model predictions (in this case Satavia\u2019s environmental factor analyses) inevitably contain some level of uncertainty, due to the reliance on a finite (typically small) sample of direct observational measurement data, or coarse resolution input meteorological data used to drive the NWP model. The project will demonstrate advanced environmental data analytics capability through the application of artificial intelligence (AI) techniques such as reinforcement learning (RL), to develop a framework for sequential decision-making under uncertainty. The objectives will include:</p> <p>1. Improve the skill of the NWP-based model using training data acquired from a local in situ measurement network; 2. Correlate aircraft environmental factor exposure to component wear rates and proxy data provided by engine health management; 3. Develop autonomous decision-making capability to adjust aircraft flight plans and engine maintenance plans in near-real-time.</p> <p>Aircraft original equipment manufacturers (OEM), operators, and maintenance repair organisations now increasingly share maintenance liability through \u2018power-by-the-hour\u2019 services for the lifetime of the aircraft. Unscheduled maintenance costs the industry billions of dollars each year (e.g., in 2016 sulphurous air pollution cost Rolls-Royce</p> <p>\u00a365M) and causes disruption to airline operator flight schedules. Customers currently implement highly conservative maintenance schedules at pre-defined maintenance frequency. Predicting when to do the maintenance based on environmental exposure could make huge savings for the industry. Satavia\u2019s data-as-a-service enables aircraft operators to modify aircraft flight plans and scheduling to extend engine lifetime, while engine manufacturers can proactively adjust maintenance plans to minimise unscheduled maintenance. Satavia is currently working on a series of \u2018proof-of-value\u2019 projects with a UK-based aircraft engine manufacturer.</p>"},{"location":"Science_exhibit_interaction_adviser.html","title":"Science exhibit interaction adviser","text":"<p>dave@cambridgesciencecentre.org</p> <p>The newly established Cambridge Science Centre is building a major interactive public science exhibition space in Cambridge. We want this to be the best of its kind in the world! One issue faced by interactive science exhibits is the tendency for visitors to play with the knobs and handles in a random way, without the guidance that might make the discovery experience more enjoyable and educational. The goal of this project is to make a configurable exhibit monitor (delivered via an embedded Raspberry Pi), that will prompt visitors to explore behaviours they haven't yet seen. This should have a simple authoring language associated with it (perhaps configured via a flow chart) that describes possible exploration paths, and allows a scientific adviser or exhibit designer to tag those that appear to be off-topic, incomplete or unhelpful. Configuration and review of interaction statistics should be available remotely, via a network connection to each exhibit equipped with one of these devices.</p> <p>Category:Raspberry Pi</p>"},{"location":"Science_for_AD2500.html","title":"Science for AD2500","text":"<p>Press](Cambridge_University_Press \"wikilink\") cfell@cambridge.org</p> <p>Everyone knows that peer-reviewed publication is the gold standard for scientific facts. But it is too slow for the millennial generation, who prefer fresh opinions and data \"verified\" by Facebook likes, GitHub pull requests, up-votes, blog comments or TED talks. We need a new model for science that is agile and open, but also solid enough to last another 500 years. Your task is to prototype the next Royal Society or Cambridge University Press, providing democratic public access for millenials, rapid quality control that would satisfy the next Isaac Newton, and PDF for permanent paper archives to survive the Apocalypse of 2499. Elegance and attention to detail are critical on both paper and screen - if it looks like Buzzfeed, nobody will believe it was the Transactions of the Royal Society. Don't forget the essential academic attributes of accurate and secure certificates for time, authorship, and reference to prior work.</p>"},{"location":"Scrobble_Exchange%3A_A_massively_multiplayer_game.html","title":"Scrobble Exchange: A massively multiplayer game","text":"<p>Scrobble Exchange - A Massively Multiplayer Game</p> <p>Last.fm is the world's most popular music recommendations website with tens of millions of users. Users scrobble&lt;http://www.last.fm/help/faq?category=Scrobbling&gt; tracks that they listen to, which we collate into charts which show the most popular artists and tracks and can be filtered by geography and genre. Using our extensive API&lt;http://www.last.fm/api&gt;, this project's goal is to create an online multiplayer game where users can invest in a portfolio of artists and gain returns based on the performance of their portfolio. The mechanics of the game are up to you but you should take steps to prevent cheating, and implement market dynamics so users' behaviour has a visible effect on the market price of an artist. A successful project would likely see implementation on Last.fm and be made available to our large userbase, so scability is a key design goal, as is portability to the Last.fm operating environment (Python or PHP against a Postgres database under Debian Linux).</p>"},{"location":"Self-selected.html","title":"Self selected","text":"<p>A group could potentially choose their own project through Founders and Coders Tech For Better programme: https://www.foundersandcoders.com/techforbetter/</p>"},{"location":"Semantic_Refactoring.html","title":"Semantic Refactoring","text":"<p>In many agile projects, the source code provides the master documentation of system functionality. When customers and users change their minds, refactoring tools help to adjust the source code structure, but one important documentation element can be neglected - the identifier names of variables, types, classes, and functions. In early versions of the code, these are usually clear and consistent. But after months or years of change negotiation, the names themselves get muddled, so that nobody can remember what has been agreed. Your task is to make a semantic refactoring tool, probably based on LLM technology, that updates all the identifier names in a code base, for internal consistency and to ensure agreement with user interfaces, tutorials, and contract documentation.</p>"},{"location":"Sensors_CDT_CamBike.html","title":"Sensors CDT CamBike","text":"<p>Johanna - js2303@cam.ac.uk</p> <p>Lorena Gordillo-Dagallier lmg53@cam.ac.uk</p> <p>Propose Clean Cycle, but probably with client from ARM, arranged by Centre for Global Equality</p> <p>- Path-finding algorithm for the least polluted route</p> <p>- Data redundancy and buffering algorithms for reliable LoRaWAN data transmission</p> <p>- Pattern recognition and machine learning on accelerometer data</p> <p>- Algorithm to make accelerometer data bike-independent</p>"},{"location":"Set_Builder.html","title":"Set Builder","text":"<p>mjohnson@frontier.co.uk</p> <p>In older entertainment software levels were often created very quickly through the use of specialised tools to paint and author them using basic primitives and formats, rather than the current fashion of using detailed art modelling</p> <p>Create an artistic package to allow the creation of less detailed environments through geometrical \u2018painting\u2019 with preset assets. The resulting environments should be exportable in at least one common usable format to be used in another popular package. The package must support the placement of instances of geometry, and the shaping and arrangement of walls and floors to form recognisable and sensibly navigable buildings and open spaces.</p> <p>The resulting packages aim will be to use some older creative approaches in the modern 3d medium to allow enthusiasts to quickly build creative environments, with the option of exporting them for \u2018detailing\u2019 in other more involved packages later.</p>"},{"location":"Signs_of_our_Times.html","title":"Signs of our Times","text":"<p>In times of political turmoil, media commentary is transient, with more profound understanding coming only decades later. In future years, we will find that someone really knew what was happening today, in the same way Primo Levi, for example, captured the true tragedies of the Second World War in his masterpiece If This is a Man. Levi invites us to vividly participate in his text so that the same thing is never allowed to happen again. What future tragedies might be avoided if we could bring scholarly analysis of important works like these into dialogue with current concerns and debates, especially as expressed online? Your goal is to build a prototype for an innovative digital edition of If This is a Man, that inspires thoughtful reflection through immersion and elegance far beyond the trivial claims made for the Metaverse.</p>"},{"location":"SimPrints.html","title":"SimPrints","text":"<p>nicolas@simprints.com</p> <p>With: Jonathan Heeney jlh66@cam.ac.uk</p> <p>suggestion ...</p> <p>Fever Finder</p> <p>Google Flu Trends was a famous (but unsuccessful) attempt to predict flu outbreaks on the basis of anxious people searching for symptoms. A more pressing need is to work out whether people in remote villages might be harbouring an outbreak of Lassa, Zika or Ebola. Your goal is to design a smartphone-based field station that geolocates fever symptoms for members of a family or village, using technology from Cambridge startup SimPrints to identify individual cases. With advice from an infectious disease specialist, you can use machine learning to model potential outbreaks as they occur.</p>"},{"location":"Simulated_Stock_Exchange.html","title":"Simulated Stock Exchange","text":"<p>Almost all stock trading is now done by algorithms. Early profits have reduced, and algo-trading strategies must adapt quickly to the changing economic environment, market movements and technological advancement. The most common way to evaluate a new strategy is to \u201cback-test\u201d it against historical market moves, which has the benefit of being based on real data but doesn\u2019t predict how the market will react to the introduction of a new strategy. The aim of the project is to build an online platform to allow competitive testing of algos on a shared simulated exchange with both historical and live market data. The platform will provide an API to access market data and issue orders to the exchange. The user-developed algos will compete against each other interactively and a reporting service will display the analysis of the relative profitability of each strategy and track the best algorithms on a leaderboard. Students will be provided with an algo pseudo code and examples of sources of market data</p>"},{"location":"Simulation_and_Warning_for_Cyclists.html","title":"Simulation and Warning for Cyclists","text":"<p>Simulations](Bohemia_Interactive_Simulations \"wikilink\") andy.fawkes@bisimulations.com</p> <p>Too many cyclists are injured or killed by collisions with trucks and buses, particularly at junctions. We have data that could help. All Cambridge buses have real time GPS tracking, and cyclists increasingly wear GPS-connected devices like the Pebble smartwatch. We propose a single online simulation and warning system, accessed from screens and that exploits both historic and real data, to help drivers and cyclists avoid accidents. Using historical data the simulation can be used to give drivers and cyclists an appreciation of the dangers and provide general warnings of dangerous traffic conditions for the time of day. The real time data can be fed back to cyclists out on the streets by the warning system, with coded buzzes on their wrist helping them plan routes and avoid any danger ahead.</p>"},{"location":"Smart_Bins.html","title":"Smart Bins","text":"<p>To help people become more sustainable, we would like to give them insights in their waste production. Your task is to develop a smart waste management system that keeps track of how you are disposing your waste. The idea being to make it more transparent so you can highlight areas to improve. The container would automatically weigh waste, and provide the user with insights through an app, so they see how their waste metrics compares to global and regional averages. A further feature could be to use image recognition to classify waste types, or to allow users to compete with friends on sustainability.</p>"},{"location":"Smart_Cambridge.html","title":"Smart Cambridge","text":"<p>(Smart Cambridge is a collaboration between the University and a number of local bodies)</p> <p>2018 suggestion</p> <p>Every Car in Cambridge</p> <p>2016 suggestion (did not proceed, after lack of student interest)</p> <p>The Busking Bus-Stop</p>"},{"location":"Smart_Poster_Picker.html","title":"Smart Poster Picker","text":"<p>Many people like to buy poster reproductions of famous artworks. This could be done by using a mobile phone to take a picture of the painting they would like to hang on their wall, and sending an MMS message to a poster distribution service. Design a system that retrieves and ranks probable matching candidates from a database of posters, based on a mobile phone image. A simple metric for matching might be the relative averages or variances of hue in each quadrant of the image. Where the photo is not good enough to provide an effective match, users should also be able to navigate through thumbnails of the available posters, arranged according to the match metric for aesthetic graphical navigation.</p>"},{"location":"Social_Media_Wellbeing_Filter.html","title":"Social Media Wellbeing Filter","text":"<p>victoria@dovetailed.io</p> <p>Social media is part of our everyday lives, but constant exposure can have negative effects - to the point where people remove themselves entirely from social networks. We want to make social media more positive for people, with a plugin that checks in with the user each day and can make suggestions or adjust feeds based on their mental state. How much negativity can they can deal with? Did they already have a bad day? Do they feel ready to see some bad news, but not too much? You might want to take on large platforms like Facebook or Twitter, or perhaps start with plugins or readers for a more specialist platform like Reddit.</p>"},{"location":"Soft_Music_Notation.html","title":"Soft Music Notation","text":"<p>Anyone who plays an instrument is familiar with receiving sheet music in a PDF file, but the technical facilities for enhancing that experience are terrible. This project will involve extracting the actual musical semantics (notes and their lengths) from PDF files, encoding these as MusicXML, and allowing the music to be adjusted, personalised, and optimised for performance using the advanced typographic tools created by a prize-winning group project team last year.</p>"},{"location":"Software_Inconsistency_Resolver.html","title":"Software Inconsistency Resolver","text":"<p>Proposed by Jasmin Jahi\u0107 jj542@cam.ac.uk, to be discussed with Chris Cooper-Bland of Endava for 2026</p> <p>This is currently phrased as a research project, so a specific problem and technical approach would need to be defined.</p> <p>Your task is to make a architecture design consistency tool, probably based on LLM technology, that works on the different levels of abstractions. In its basic instance, the tool works with a model of software architecture and source code. It identifies parts of code belonging to abstract architectural components, suggests issues with breaking isolation, updates all the identifier names in a code base, for internal consistency and to ensure agreement with software architectural model (interfaces, component names, identifiers, other specifications). To create a software architectural model, we will use draw.io as the tool, as it enables generating clean xml from a visual representation. Besides the main goal of the project, the students will have the opportunity to explore:</p> <p>- Can LLM read binary on any level and extract any software architecture-relevant information?</p> <p>- Can LLMs enable control of source code from architecture (e.g., \"notice\" any change in architecture and suggest changes in the source code)?</p> <p>- Can LLMs enable updates to architecture model based on the source code (back propagate any change from source code and conclude if anything should be changed in the architecture)?</p>"},{"location":"Sonic_Garden.html","title":"Sonic Garden","text":"<ol> <li>REDIRECT Sound Garden</li> </ol>"},{"location":"Sound_Garden.html","title":"Sound Garden","text":"<p>Jonathan Baldwin, Madingley Hall Jonathan.Baldwin@ice.cam.ac.uk</p> <p>Surprisingly satisfying music can be defined in terms of in terms of simple regular grammars. Simple regular grammars can be derived from observing the traversal of a graph. Your task is to make a system that automatically generates original music, according to rules that are derived from the path of visitors walking through the formal garden at Madingley Hall (http://goo.gl/maps/9utLI). A small number of infrared detectors hidden in the flowerbeds will detect people passing. A Raspberry Pi should use these signals to create a grammar that can also be viewed and modified by members of the public, in the form of source code that can be edited from any web browser via an HTTP server on the Raspberry Pi. Of course, everyone should be able to hear the resulting music, whether played over speakers in the garden, or by remote viewers from their browsers. As an example of the kind of generative music that might result, check out the video of Dave Griffiths' techno music composing robots in al-jazari.</p> <p>Category:Raspberry Pi</p>"},{"location":"Sparrho.html","title":"Sparrho","text":"<p>Client contact: Vivian Chan v.chan@cantab.net</p> <p>Project idea: Intelligent Graph Reader</p> <p>Epistora is an aggregator for scientific information. It makes discovering the latest developments much more efficient and effortless through the form of a news feed. We are a startup from the Entrepreneur First program and have a number of different projects ranging from forming relationships between the data in our news feeds to mobile/API integrations to better enhance the discovery process.</p>"},{"location":"Sparx.html","title":"Sparx","text":"<p>Have concluded that it is too far to come to Cambridge for 3 meetings.</p> <p>Last contacts with Glenn Woodcock glenn@sparx.co.uk and Tanya Morton Tanya.Morton@sparx.co.uk</p>"},{"location":"Sparx.html#2018","title":"2018","text":"<p>OpenFace is an open source facial behaviour analysis toolkit, that can monitor a webcam to detect emotional state via \"action units\u201d, such as smiling or raised eyebrows. Imagine a game that could adapt itself based on the emotions of the player. For example, it could display helpful hints when it sees the player is confused, or make it harder when the player looks bored. Your task is to implement such a game for the classroom. The choice of genre is up to you, for example a puzzle game with hints and different levels, or a platform game with procedurally generated content.</p> <p>Feedback:</p> <p>I wondered if there might be an opportunity to update this, following recent interest in the iPhone X FaceID system, which has been described as being used to select or animate emoji\u2019s? Rather than focusing on when the player looks bored (which is technically difficult - there are few facial signs other than an open mouth yawn that are both detectable and associated with boredom), they could create a game which uses a range of emotions.</p> <p>Last year's discussion with Glenn proposed:</p> <p>I Love Physics</p> <p>OpenFace is an open source facial behavior analysis toolkit that can monitor a webcam to detect emotional state via \"action units\" such as smiling or raised eyebrows. Imagine an online tutorial system that watched your face, and could provide assistance as soon as it sees that you are stuck. This would be an alternative to children's toys such as Osmo (which adapts an iPad camera for reality-based teaching games - www.playosmo.com). Your task is to implement a physics teaching game inspired by Osmo's Newton, but where objects bounce off features of the user's face, and it waits for a happy smile when you have understood the equations!</p>"},{"location":"Sparx.html#2017-proposal","title":"2017 proposal","text":"<p>The client will be Tanya Morton and Will Bolam ((will.bolam@sparx.co.uk).</p> <p>Another idea from me:</p> <p>I Love Physics</p> <p>OpenFace is an open source facial behavior analysis toolkit that can monitor a webcam to detect emotional state via \"action units\" such as smiling or raised eyebrows. Imagine an online tutorial system that watched your face, and could provide assistance as soon as it sees that you are stuck. This would be an alternative to children's toys such as Osmo (which adapts an iPad camera for reality-based teaching games - www.playosmo.com). Your task is to implement a physics teaching game inspired by Osmo's Newton, but where objects bounce off features of the user's face, and it waits for a happy smile when you have understood the equations!</p> <p>Based on two ideas from Sparx:</p> <p>1. Crowd-sourcing Human Feedback</p> <p>As we move towards a world in which the use of technology is ubiquitous within education, it\u2019s crucial to retain the personalised and insightful feedback that only a human can provide. Your task is to build a system that uses crowd sourcing techniques to integrate human feedback into an otherwise automated system. The system should allow any question to be asked - think video, audio or image as well as text based questions. Similarly the system should support answers in any format the user would like - written or drawn answers could be input using an Osmo, or a smart phone could capture video, audio or images. The answer should be uploaded to the cloud ready for marking by another human anywhere in the world. The marker should be able to overlay their feedback and comments within the answer provided, and then return the answer and feedback to the original user. We\u2019ll provide an Osmo as inspiration.</p> <p>2. Emotional Learning</p> <p>Does emotional state and heart rate impact learning? Recent advances in wearable biosensors (think fitbit) have made this a much easier question to answer. Your task is to design a system to explore this question, using biorhythm monitoring to track emotional state whilst your subjects complete various tasks. Exactly how you test people is up to you, it could be anything from a simple maths quiz to a complex game with different physical and mental tasks \u00ad of course the more engaging it is the more data you will get! At the end you\u2019ll need to analyse the data and spot correlations in order to form a conclusion and answer the question. We\u2019ll provide you with a small budget for suitable wearable tech.</p> <p>Earlier idea from me:</p> <p>Data Science for Kids</p> <p>Although public decisions in the UK often depend on statistical analysis, the public are not encouraged to get involved. Future voters could learn to participate in democratic processes involving data that will have personal consequences for them, applying evidence to local policy debates such as speed limits and road design. Your task is to create an easily accessible tool for kids to become democratic data scientists, helping their families analyse public experiments such as Cambridge traffic surveys, going beyond the usual comparison of averages to apply modern data science techniques such as time series, clustering, analysis of variance, linear regression etc.</p> <p>Original suggestion:</p> <p>Ready for Secondary Maths?</p> <p>The government has identified that some students are not secondary ready by the time they leave primary school. Mathematical ability is a key factor in this assessment. Sparx works closely with Year 7 students, some of who have a low level of mathematical skill. Sparx is keen to explore how to support these students in their final year of primary school and better prepare them for entering secondary school.</p> <p>Low ability students struggle with basic topics such as: number bonds, addition, subtraction and multiplication. Your challenge is to design an engaging and personalised software tool to help teach and re-enforce these skills. The software should include data visualisation capabilities to enable the teacher to assess student progress.</p>"},{"location":"Sparx.html#2015-project","title":"2015 project","text":"<p>Flash Mob Learning</p> <p>Idea 2:</p> <p>Running a classroom of tablets in a school over their wireless system can be pretty volatile.</p> <p>In order to teach a dynamic lesson with 30 students using individual iPads, can we create a wireless, router-less system? Can we create a network of tablets without needing a router? How many can we connect at once? What are the distance limitations?</p> <p>The implications of this for Sparx could be extensive, because if you have a group of cheap mobile devices, but no other infrastructure \u2013 as is the case in many developing countries- this solution could be the difference between accessing education and not.</p> <p>Idea 1:</p> <p>\u201cYou might not know this, but over 40% of 16 year olds fail their GCSE maths, in Britain, each year. KPMG has calculated that this costs the UK, \u00a32.4 billion every year.</p> <p>Sparx has been working for two years with 15 and 16 year olds to find out how we learn, and how to improve performance. We have been developing a platform which can teach them in the way that they respond to best.</p> <p>We know that for many of the students we have worked with, they don\u2019t have basic number sense or their times tables locked down as \u201clearnt\u2019 yet. Can you create a game which would appeal to the 11 \u2013 16 year old market, which would teach times tables, whilst helping the teacher to understand what is and isn\u2019t secure in their learning? Can you develop a game that improves their learning and can give feedback to them and the teacher and can extend each student, in a personalised and adaptive way?\"</p>"},{"location":"Speak_in_the_Country.html","title":"Speak in the Country","text":"<p>People who live in rural areas of low-income countries find it difficult to access online services. They may have low literacy, and often rely on feature phones rather than smartphones for their communication needs. The goal of this project is to help people in that situation access medical advice via the latest speech technology from Cambridge company Speechmatics, in a system that will take voice messages in a local language, transcribe and match their needs to relevant information resources, and return recorded advice or monitor disease outbreaks. Health workers at local clinics should have a dashboard to monitor issues in their region, and also to flag conversations where a human expert needs to intervene.</p>"},{"location":"Speech_Error_Detection_and_Correction.html","title":"Speech Error Detection and Correction","text":"<p>Conor.Peacock@alderhey.nhs.uk</p> <p>Children with cleft palate often experience specific speech errors that require targeted feedback to correct. Traditional speech therapy sessions are time-consuming and may not provide immediate, specific guidance during at-home practice. This project aims to develop an interactive tool that detects cleft-related speech errors and offers real-time, personalised feedback. The tool must create a baseline and then learn as the child practices how they are improving. The goal is to support speech therapists by providing patients with an engaging way to practice and improve their speech outside of clinical sessions, enhancing the overall effectiveness of treatment.</p>"},{"location":"Speeding_Up_Evidence_Synthesis_for_Conservation.html","title":"Speeding Up Evidence Synthesis for Conservation","text":"<p>Zoology](Department_of_Zoology \"wikilink\") pam79@cam.ac.uk</p> <p>A core activity of the Conservation Evidence team in the Department of Zoology is compiling and summarising research literature, to provide evidence for which management approaches are most effective for biodiversity conservation. However, this evidence is dispersed in many different scientific journals, in English and non-English language journals, and in non-academic (\u201cgrey\u201d) literature. The Group needs tools that can use natural language processing methods to constantly monitor publications across many different venues, initially classifying studies as relevant or not to different biological taxa, and then extracting key attributes such as geography, habitat, threats or interventions and organising these for thematic browsing or targeted queries. The group would also like to explore the possibility of using natural language processing to summarise study findings.</p>"},{"location":"Sport_England.html","title":"Sport England","text":"<p>Developed with Microsoft - contact Matthew.Smith@Microsoft.com</p> <p>Deriving health benefits from open data</p> <p>There are many open data initiatives in the public realm, often with the aim of supporting innovation of new products, services and especially businesses. The aim of this project is to show how consumer cloud capabilities (analytics, web service delivery etc..) can be combined with public data to efficiently generate and deliver new cloud services for societal and/or business benefits.</p> <p>The Sport England Open Data Initiative is keen to find people who can do interesting things with data that has been published through OpenActive so far. Over the past few months they have been working with activity providers (leisure operators, national governing bodies and smaller activity providers) to open up data about the opportunities they provide. This data consists of the sort of things a customer might want to know when deciding to take part in an activity - e.g. type of activity, date, time, location, difficulty, etc.</p> <p>Their focus now is to find and support people who can create customer-facing tools and services that can help people find activities and become active. They are launching an incubator early next year and are doing some work to frame the sort of implementations they are looking for, but some potential use cases could:</p> <p>\u2022 support parents and children to find activities</p> <p>\u2022 be used in a healthcare setting (e.g. GPs finding activities for their patients)</p> <p>\u2022 emphasise the social aspect of physical activity (e.g. can I find activities with other people like me?)</p> <p>The Initiative is interested in whether students, equipped with Microsoft\u2019s cloud capabilities and their data can generate cool new products. The project is very open ended\u2026 basically what cool new product/service could you propose by combining the data, technology and your own ingenuity.</p>"},{"location":"Steve_Smith%2C_CU_Management_Information_Systems_Division.html","title":"Steve Smith, CU Management Information Systems Division","text":"<p>In the past, we've had some projects that used data from the Talks.cam API. Perhaps we could do something that identified current research grants from CUFS, correlated them with research subjects at seminars advertised in talks.cam, then advertised them to students who were registered for relevant exams via CamSIS?</p> <p>Track down the experts</p> <p>Undergraduate students in Cambridge are not always given the opportunity to meet research staff whose work is related to their lectures. Some of those staff give lectures and supervise, but others are just hidden away in labs. However, there are university systems that could be combined to locate expert researchers - for example, use your CamSIS exam entry codes to find course titles and syllabus, use the university financial system to discover which research labs receive funding in related areas, correlate the teaching and research keywords using the interface to talks.cam, and find out where those researchers meet via the API to the University online map. There are some tricky technical problems in all this, but we do have permission for you to use the relevant service interfaces. Cambridge is already a world leader in producing students who are up-to-date in recent research, but a system like this could provide the most stimulating degrees in the world!</p>"},{"location":"Steve_Wade.html","title":"Steve Wade","text":"<p>Steve's profile on the Cambridge Network:</p> <p>http://www.cambridgenetwork.co.uk/directories/companies/2355/?&amp;atoz=S#profile</p>"},{"location":"Strawberry_Fields.html","title":"Strawberry Fields","text":"<p>marc.jones@antobot.ai</p> <p>Strawberry pickers currently spend a significant amount of time (approx. 20%) manually transporting trays to stations, generally at the end of the field. Autonomous logistics robots provide the opportunity to increase productivity by transporting the trays, thus reducing the demand on labour. Your challenge is to create a simulation of a typical harvesting scenario in ROS Gazebo and develop an optimised algorithm for efficient multiple robots path planning. Use this to recommend the minimum number of robots required (e.g. scheduling / logic) \u2013 too many robots will be complex and potentially too expensive, too few will create delays for the pickers and reduce efficiency. Based on the simulation results, you should identify required sensor and actuator technologies in order for the robot to optimally interact with human staff.</p>"},{"location":"Stretching_the_Score.html","title":"Stretching the Score","text":"<p>Anyone who has learned a musical instrument or taken a music lesson at school is likely to have seen printed scores created with Sibelius, one of the most famous software companies to have come from Cambridge. The Sibelius tools make it very easy to print music in the way it has looked for 200 years or more, but very hard to adapt with typographic innovations that make music easier. Your goal is to create an alternative specification language and rendering chain for music notation, perhaps using standards like MusicXML and the scripting language embedded in Sibelius. Your client is also the author of a major open source music typesetting system, and you'll be welcome to experiment with or borrow from his code base.</p>"},{"location":"Stride_Design.html","title":"Stride Design","text":"<p>Initial contact: Andrew Nairne acn36@cam.ac.uk</p> <p>Project manager on behalf of Carol Ann Duffy: Helen Taylor - pa.poetlaureate@googlemail.com</p> <p>The Poet Laureate's Web Thresholds</p> <p>The Poet Laureate Carol Ann Duffy has appointed 10 leading poets to work with Cambridge University Museums and young people from the county. Your task is to provide a novel tool that can emulate the exact layout of any page from a museum web server, but with the original text (perhaps partly) removed. Invited poets and young people should be able to substitute their own poetry or other text by typing directly over the visual layout as if in a drawing editor. These transformed pages can then be published and viewed from an alternative server that offers a \"mashed up\" version of any museum page for public viewing. The technical challenge is to give users the impression that they are really typing directly onto the rendered web page, as if onto a piece of paper, and to do so in a way that emhasises typographic freedom, allowing poets direct control over all concrete aspects of the juxtaposed text.</p> <p>Earlier draft and title to be discarded:</p> <p>Site-specific poetry mash-ups</p> <p>In most websites, the words are the real content (even Google image search relies on captions to work properly). But the goal of this project is to preserve everything except the words. Your task is to create a website mash-up tool that allows even non-technical users to modify or transform the words of a site when viewed from an alternative URL, or with an alternative client. This project is in collaboration with a scheme where six Cambridge museums will each be hosting a high-profile poet in residence. You need to design a tool that will be easily usable by a professional poet, but give them enough technical freedom to augment, interpret, or even subvert the museum's collection via its website.</p>"},{"location":"Studio_Above%26Below.html","title":"Studio Above&Below","text":"<p>Introduced by Collusion</p> <p>Daria Jelonek daria.jelonek@network.rca.ac.uk, daria@studioaboveandbelow.com</p> <p>and perry@studioaboveandbelow.com</p> <p>Final version: West Augmentation</p> <p>Alan's suggestion:</p> <p>The view from the William Gates building, once a peaceful meadow where horses from the Vet School grazed, has become an ugly building site. The public exhibition for this year\u2019s group design projects will look out at this. Your task is to create an augmented reality viewer for visitors to explore an alternative to the industrial design of modern universities. They should be able to toggle between a visualisation of the actual planned buildings, and an alternative featuring \u201ctree tenants\u201d as proposed by Hundertwasser, urban farming, wildlife sanctuary, and more radical environmental features. Visitors should be able to interact from the viewing area via multiple linked devices, including mobiles, large screens, projectors and VR headsets.</p> <p>Edited by Daria:</p> <p>The view from the William Gates building, once a peaceful meadow where horses from the Vet School grazed, has become a modern but fairly solid building. The public exhibition for this year\u2019s group design projects will look out at this. Your task is to create an augmented reality experience for visitors to explore an alternative and speculative virtual design inspired by the existing industrial side. Visitors should be able to toggle between a visualisation of the actual planned buildings, an alternative featuring \u201ctree tenants\u201d as proposed by Hundertwasser, urban farming, wildlife sanctuary, and more radical environmental features such as parametric virtual growing plants and speculative future scenarios which will bring this building and solid architecture to life. Visitors should be able to interact from the viewing area via multiple linked devices, including mobiles, large screens, projectors and VR headsets. Let's explore the future of augmented reality devices, the invention of new digital materials and the growing environment between the physical and digital.</p>"},{"location":"Supervisor_Matching_System.html","title":"Supervisor Matching System","text":"<p>timothy.jones@cl.cam.ac.uk</p> <p>Finding supervisors for courses is difficult. The CL runs a wiki where supervisors can indicate their interest for specific courses, but the information quickly becomes stale. Your task is to produce a web-based system allowing potential supervisors to mark all courses they are able to supervise along with preferences for numbers (and perhaps college), and which then indicates their remaining capacity for the relevant period. It should provide easy data entry and a convenient view for DoSes to see who is supervising what and when. When the core is complete, there are a variety of extensions envisaged.</p>"},{"location":"Supply_Chain_Resilience.html","title":"Supply Chain Resilience","text":"<p>Events such as the Covid pandemic and the Ukraine-Russia war highlight inefficiencies in global supply chains, affecting our everyday lives through energy prices, inflation, cost-of-living, unemployment and housing. This project will use publicly available datasets and APIs to build a comprehensive map investigating supply chain choices such as semiconductors for tech via China to the West, oil exports, agricultural product shipments etc. You will create metrics for supply chain efficiency and resilience, ranging from route stability to sensitivity to natural disasters. This visualisation should offer opportunities to optimise routes for delivery of different industrial products, contrasting and comparing CO2 emissions, cost, reliability, and robustness through diversity of supply options. It will be important to ensure that data is not biased, and that features are explainable, to support public accountability for decision makers.</p>"},{"location":"Support_Sustainable_Wildlife_Trade.html","title":"Support Sustainable Wildlife Trade","text":"<p>Mike.Harfoot@unep-wcmc.org</p> <p>UNEP-WCMC supports many developing countries in assessing the potential levels for sustainable trade in wildlife for particular species. You challenge is to use the data provided by existing APIs to power a tool for countries to follow a methodology for producing these reports for a given species/family. The tool must be easy to use in target developing countries and allow the user to provide additional local knowledge to supplement the global data provided by existing data APIs and finally produce a summary report for future policy use.</p>"},{"location":"Surgery_in_the_Cloud.html","title":"Surgery in the Cloud","text":"<p>New hospital treatments often involve as much computer imaging as they do scalpels. Local company Cydar manages high volumes of images and video data in the cloud using Amazon Web Services, and can even track real-time video from an operating theatre, but configuring those data flows is time-consuming and confusing. Your goal is to create a video cloud service management tool inspired by Stuart Taylor's VPlay system for live video remixing (http://vimeo.com/2738692). Users should be able to review and modify the data flow architecture on AWS virtual machines, while also getting a live view of the current streams and archive content to see where the problems might be.</p>"},{"location":"Surprise_the_Singularity.html","title":"Surprise the Singularity","text":"<p>If Singularity is achieved and a super-intelligent artificial intelligence takes over the world, Cambridge is likely to be the first target. The Singularity is not actively hostile to humanity but it will aim to control all movement of vehicles and people so it can prioritise its transport needs over humans. Unfortunately, important strategic information has been published online, where the Singularity can easily find it. For example, the Computer Lab layout is at https://www.cl.cam.ac.uk/research/dtg/openroommap/, and the University map at https://wiki.cam.ac.uk/university-map/. Your task is to confuse the Singularity by creating distractor maps, navigated in a way that a disembodied mind might not realise are impossible, for example as Moebius strips or non-Euclidean spaces. Don't show the whole map at once, where the edges will spoil the illusion. But do include a simulation of real activity - public transport synced with real-time information from Cambridge buses, simulated self-driving cars, and of course locative social media messages from the (simulated) people in the panicking crowds.</p>"},{"location":"Survey_Swarm.html","title":"Survey Swarm","text":"<p>Ashkan.Tousimojarad@arm.com</p> <p>Autonomous robots often have to work with an incomplete model of the world, and high-end devices such as the Dyson 360 Eye do their best to construct accurate image maps of the rooms they work in. But if there are many cheap robots, they can collaborate in a swarm to share information. Your task is to create sensing and coordination infrastructure so that a swarm of Pololu 3pi robots can use their reflection sensors to work out the overall design of a black and white floor pattern that they are moving over. To start with, they will have to use dead reckoning to collect single data points for the shared model. Eventually, they can reduce uncertainty (for example, if some robots seem less precise than others) by delegating individual robots to go and make further observations, navigating by the map of previous attempts.</p>"},{"location":"Sustainable_Electronic_Recycling.html","title":"Sustainable Electronic Recycling","text":"<p>Recycling is a challenges posed by electronics devices. This project involves the design and own implementation of a data gathering solution for better electronics recycling. The target is an open source populated printed circuit board.</p> <p>Proposed modification:</p> <p>Global Component Exchange</p> <p>There are many open-source designs for printed circuit boards (PCBs), making it very easy to order a small manufacturing run of an electronic device for very little cost. But a PCB is not functional without components, and the industry has a huge problem of components that are simply thrown away whenever an appliance is trashed. Your task is to create a design tool that gathers data on PCBs being discarded in rich countries, matching the components to low-cost open source PCBs that need to be populated with components elsewhere in the world, in order to solve local problems.</p> <p>Or else:</p> <p>Less Wasteful Electronics</p> <p>There are many open-source designs for printed circuit boards (PCBs), but products made this way often get thrown away, which is wasteful of components that could be recycled. Your task is to create a system that analyses which components on an open source PCB could be re-used, offering them via an online market for recycling into different products (based on other open source PCBs) in future.</p> <p>Franck's final suggestion</p> <p>Enabling electronics re-use</p> <p>Electronics recycling is one of the challenges resulting from electronics being everywhere. Full products get thrown away with working components, which is wasteful of components that could be re-used. Your task is to create a system that analyses which components could be re-used.</p>"},{"location":"Sustainable_Gaming.html","title":"Sustainable Gaming","text":"<p>Centre](UNEP_World_Conservation_Monitoring_Centre \"wikilink\") tim.wilkinson@unep-wcmc.org</p> <p>Minecraft is practically a training simulator for environmental destruction - open cast and strip mines, deforestation, large scale industrial development and more. Your task is to use an open source game engine such as Godot to prototype a new kind of game in which players (re)build a natural world rather than destroying it. Rewards and metrics can be related to biodiversity, species conservation, and re-wilding. Sustainable social dynamics and economies might also be an important factor. The challenge is to keep it exciting, but with thrills that don\u2019t come from killing and maiming.</p>"},{"location":"TPP.html","title":"TPP","text":""},{"location":"TPP.html#proposal-for-2019","title":"Proposal for 2019","text":"<p>Contact: ankit.sharma@tpp-uk.com</p> <p>Final brief: Bone Doctor</p>"},{"location":"TPP.html#discussion","title":"discussion","text":"<p>X-Ray Machine Learning</p> <p>Musculoskeletal conditions affect more than 1.7 billion people worldwide. These conditions are the most common cause of severe, long-term pain and disability, causing hundreds of millions of emergency department visits annually around the world. Successful diagnosis of musculoskeletal conditions currently requires X-ray analysis by skilled radiologists. In many parts of the world, however, access to these specialists is very limited. New advances in machine learning and medical imaging can help to solve this problem, improving outcomes for people worldwide. The task is to develop an algorithm capable of diagnosing these conditions at an expert-level, working with a new image dataset, and competing with teams from around the world.</p> <p>The licence for the open data set use is here https://stanfordmlgroup.github.io/competitions/mura/. I am not sure if you want to check you are happy with the licence first?</p>"},{"location":"TPP.html#response","title":"response","text":"<p>We do often have students from our department participate in machine learning competitions of this kind, but those are generally PhD-level specialists in machine learning, using relatively powerful compute clusters. The group design project course is for second year undergraduates, with more limited computing resource, meaning that they would not practically be able to achieve competitive results.</p> <p>As an alternative, in recent years, we have had a number of teams using pre-trained networks to implement application demonstrators in areas related to the original machine learning research but not competing with professional research teams. Do you think something like that might be possible, either working with the Stanford competition dataset, or with another medical condition? Even if pre-trained networks were not available, students could perhaps use this dataset to train their own network (likely achieving poorer performance than the Stanford benchmark), as the basis for a demonstrator in this area.</p> <p>Here\u2019s an example of a previous project from a couple of years ago that used a pre-trained network Neural Guide</p>"},{"location":"TPP.html#previous-discussion","title":"Previous discussion","text":"<p>Contact: Sara Dowrick (sara.dowrick@tpp-uk.com).</p> <p>Suggestion:</p> <p>As healthcare resources become increasingly stretched, there is an ongoing push to enable patients to monitor their own health and wellbeing. The widespread use of smartphones has seen a large rise in the number of patient-facing medical apps available to users but encouraging uptake and use of these apps is a key challenge.</p> <p>The aim of this project is to create a patient-facing, medical Android app that will improve, or aid in monitoring, the health of the user. In order to make the app more appealing and promote uptake, the app should be presented in a visually appealing 'gaming' format - e.g. a user is awarded points based on how well they adhere to their recommended salt intake etc.</p> <p>In order to provide most benefit, special attention should also be given to the particular problem, disease or illness that the app has been developed to help with. A list of suitable causes will be provided to the project participants before commencing and will ensure there is plenty of scope for creative thinking and novel implementations...</p> <p>Response:</p> <p>It would be nice to do something in the healthcare area. I think it would be necessary to refine this a bit before advertising, as there are already a lot of apps in this general area. As an example of a more specific application, several years ago we had a team do a very successful project aimed at field support for patient records and monitoring during Ebola outbreaks.</p>"},{"location":"Talk_Interactive.html","title":"Talk Interactive","text":"<p>Talk radio is incredibly popular, but doesn\u2019t (yet) have the same capability for discussion and annotation that text formats do. Your task is to create a software service that enhances the experience of listening to talk radio. Your application will listen to the audio, extract key words, and offer services such as background information on an item, programme or presenter, linked visual media, comparison to other news sources and authorities, or even AI-enabled interactive fact-checking about the claims being made.</p>"},{"location":"Talking_Music.html","title":"Talking Music","text":"<p>People with different sensory capabilities or diverse neural styles sometimes find it easier to communicate via a musical instrument or a piano keyboard than with the screen and keyboard of a laptop. The goal of this project is to make an alternative kind of music editor that works with text and sound as the elements, rather than working with music notation on the computer screen. The open source synthesiser SuperCollider generates professional quality sound, but you would replace the sclang programming language with a natural language interactive text system that could be driven from an assistive keyboard or screen reader.</p>"},{"location":"Talking_Treadmill.html","title":"Talking Treadmill","text":"<p>Private contact from Nicholas Hellawell Nicholas.hellawell@tiscali.co.uk</p> <p>Perhaps better to call this \"Audible Appliances\"?</p> <p>Many home appliances would be perfectly usable by visually impaired users, except for interaction via a display screen. An example is the exercise bicycle owned by your client. Your task is to create a simple accessory that can be attached to the bicycle display screen, using a Raspberry Pi camera to find and decode relevant parts of the display, and read necessary information out loud during an exercise session. In principle, this functionality could provide a customisable screen reader that might be attached to any kind of device to add screen reader functionality.</p> <p>Note potential to work with a \"good cause\" client - cf Sailing by sound</p>"},{"location":"Taste%3A_Movies_x_Books_x_Music.html","title":"Taste: Movies x Books x Music","text":"<p>There are many music, movie and book recommendation systems online, but each focuses on a single medium. The goal of this project is to build a web application which, when given a movie or a book, would present a cluster of books, movies and songs that are related to it by often being mentioned online together. It would be cool to see how clusters of \u201ctastes\u201d form and how books, movies and music from the same artistic movements naturally pop up together. A timeline could also give an idea of the art history context, for example the movie Easy Rider might relate to movies, books and songs popular with the hippy movement.</p>"},{"location":"TechWolf.html","title":"TechWolf","text":"<p>Client: Ben Searle ben@techwolf.be</p> <p>Title: NLProject Manager Description: Software Engineering has pioneered agility across multiple functions, however, the overhead of managing projects remains excessively high. In agile project management, people can be seen as a unique combination of skills, rather than the single dimension offered by their job title. By using these skills as the foundation, develop a platform that uses Natural Language Processing and other methods to make software project management more efficient and accurate. Your product should rely on code analysis for skill inference, which can then be used to manage the project. Some examples might include using skills to assign team members to certain issues, code reviewers to merge requests, or helpers when someone gets stuck with their work.</p> <p>Alternative proposal:</p> <p>Managing Agile Researchers</p>"},{"location":"Terabyte_threat_analysis.html","title":"Terabyte threat analysis","text":"<p>Large networks such as the BT phone network generate terabytes of routing metadata, but the size of the dataset makes it difficult to interact with that data in realtime. This means that threats to the network - whether natural disasters or intentional attacks - may not be recognised until it is too late. Your task is to create a threat visualisation and rapid response tool that uses the Hadoop distributed data framework to identify network vulnerabilities from data traffic analysis, and helps to plan and prioritise technical responses.</p>"},{"location":"Terms_and_conditions.html","title":"Terms and conditions","text":"<p>This wiki page is currently for discussion only, and does not represent confirmed policy.</p>"},{"location":"Terms_and_conditions.html#preface","title":"Preface","text":"<p>Each client and design brief is unique, and there is no intention to impose uniformity through regulation. Responding to the specific needs of a particular client and/or brief is an integral part of the group design project course. This is expected to include negotiation between the team and client over technical requirements, in order to complete the project within the allocated time budget.</p> <p>If a client, or any member of a team, is concerned that others are acting unreasonably, the first port of call should be the group project coordinators (via the address group-project@cl.cam.ac.uk). The coordinators are completely happy to offer advice or assistance, or if necessary, arbitrate where negotiations have broken down.</p>"},{"location":"Terms_and_conditions.html#parties","title":"Parties","text":"<p>In each project, the parties to any discussion of terms and conditions are the students who are members of that team, the client, who may be acting on behalf of an employer or other body, and the Computer Laboratory, represented by the group project coordinators. Any discussion of issues relating to terms and conditions below should include all of these parties.</p> <p>During the course of the group design project course, from the kick-off meeting until the end of the public demonstration, the members of the team are those assigned to that project by the group project organisers. After the completion of the project, all members of the team who have received an individual tick will continue to be recognised as members of the team. Any member who has not received an individual tick may also be included in further discussion, but at the discretion of the other members.</p>"},{"location":"Terms_and_conditions.html#framework-for-intellectual-property","title":"Framework for Intellectual Property","text":"<p>University of Cambridge policy is that individual students hold the copyright in their own work. The group design project does not constitute creative work undertaken for payment, so it can be assumed that students also own this copyright in their own work.</p> <p>Nevertheless, since this is a group project, all students are expected to make their own contribution available to other members of the group. We recommend that, if the work of the group is to be published, this should be done under an open source licence. The group may choose otherwise if they agree to do so.</p> <p>It is recognised that all parties - the client, the members of the team, and the Computer Laboratory - have contributed background IP to the project. Rights to background IP remains with the original owner.</p>"},{"location":"Terms_and_conditions.html#promotional-activities","title":"Promotional activities","text":"<p>It is generally beneficial to all parties to publicise the work achieved in the design projects. This may include press releases or promotional literature from clients, personal portfolios from CVs for students, and outreach literature and events from the Computer Laboratory. All parties should be informed in advance of any promotional activity. The activity should only continue if all parties agree to this use. It is hoped that team members may be available to participate in promotional activities after the project is complete, but there is no obligation for them to do so. They should not be expected to suffer any financial penalty (eg forgoing paid work) or academic (eg conflict with other course requirements).</p>"},{"location":"Terms_and_conditions.html#other-sections-to-be-completed","title":"Other sections to be completed","text":"<ul> <li>use of open source code (I suggest unrestricted, including use of GPL)</li> <li>subsequent use of code by team members (I suggest non-exclusive use   for non-commercial purposes by any member)</li> <li>employment of group members by client</li> <li>commercial development by the team (I suggest that partnership in   directly related commercial activity should be offered to whole team   as equal partners, subject to members having received both ticks.   Client may be offered a commercial stake, but team may decide not to   do this).</li> <li>protection of client confidential information</li> </ul>"},{"location":"TestPage.html","title":"TestPage","text":"<p>tesr</p>"},{"location":"Testing_a_Logical_Query_Language.html","title":"Testing a Logical Query Language","text":"<p>joshua@grakn.ai; Kasper Piskorski, Grakn Labs kasper@grakn.ai</p> <p>Graql is a declarative query language inspired by logic programming languages for performing real-time deductive reasoning on knowledge graphs in Grakn. Theoretical properties of query languages can be verified formally, but it is also important to be able to test language implementations for conformance. Your task is to build an automated system for testing Graql's implementation and interrogating the results, either against a formal semantics for the language or via a more pragmatic approach. If successful, your code will be contributed back to Grakn's open-source repositories.</p>"},{"location":"Testing_for_Humans.html","title":"Testing for Humans","text":"<p>Many companies rely on online programming aptitude tests to select potential employees. Unfortunately, applicants can often fool the test by finding answers online, or even generating a response automatically using an AI chatbot. Your task is to create an authoring and administration tool for aptitude question banks that automatically benchmarks them against such strategies, helping the question author to fine-tune them in a way that will guarantee human responses.</p>"},{"location":"Text_Farming.html","title":"Text Farming","text":"<p>tim@kisanhub.com</p> <p>Low-income countries often have widespread network coverage to rural areas, but the devices and data contracts available to subsistence farmers make voice and SMS more practical then web services. You need to design a subscriber service that provides automated weather, health and market updates which users can personalise to their needs from a basic feature phone. You may need to use SMS gateways, off the shelf Interactive Voice Response techniques, and public APIs for information sources. Keep in mind the need for security, accessibility to low literacy users, and simultaneous support for a large number of local languages.</p>"},{"location":"Thales.html","title":"Thales","text":"<p>No contact since 2019, when we were talking to Thales eSecurity:</p> <p>'Taylor, Neil' Neil.Taylor@thalesesecurity.com</p> <p>'Surdhar, Pali' Pali.Surdhar@thalesesecurity.com</p> <p>Previous contacts with:</p> <p>ROUX Raphael - Contractor raphael.roux@external.thalesgroup.com Jerome Euziere jerome.euziere@gmail.com</p> <p>Previous Contact: FIRTH Chris Chris.Firth@uk.thalesgroup.com</p> <p>making introduction to Thales eSecurity, with office in Cambridge</p>"},{"location":"The_Adaptive_Web.html","title":"The Adaptive Web","text":"<p>cjtf2@medschl.cam.ac.uk</p> <p>Most websites are designed on the basis that \u201cone size fits all\u201d - for any kind of user or context of use. Your task is to create a tool that allows users to author their own policies for customised appearance and behaviour, for example dark-mode viewing, text subsets, or controls suited to elderly users or those with disabilities. It should also be possible to apply data from one user-selected site (e.g. a weather forecast) to customise the appearance of another. The configuration process should be easily accessible to a wide range of users - so rather than vendor-specific browser plug-ins, a more universal solution might be a configurable online translation service that substitutes alternative CSS and JavaScript through recipes that can be shared with others. Such a powerful tool would also require security provision to guard against misuse.</p>"},{"location":"The_Automatic_Accountant.html","title":"The Automatic Accountant","text":"<p>Enterprise](Cambridge_Enterprise \"wikilink\") Mark.Parsons@enterprise.cam.ac.uk</p> <p>The Automatic Statistician is a system created by Zoubin Ghahramani and colleagues that looks for interesting patterns in data sets (by fitting Gaussian process models), and then automatically generates a research paper, including charts and natural language texts, describing the patterns that it finds. Financial accounting data is relatively constrained in its format, so it should be more straightforward to create an AI system that automatically generates professional-looking reports on a company\u2019s performance, including capabilities for audit and compliance checking that work by recognising statistical anomalies. You will need to familiarise yourself with the research from www.automaticstatistician.com, and work with your client to design an original accounting application.</p>"},{"location":"The_Automatic_Financial_Analyst.html","title":"The Automatic Financial Analyst","text":"<ol> <li>REDIRECT The Automatic     Accountant</li> </ol>"},{"location":"The_Big_Chill.html","title":"The Big Chill","text":"<p>The Terra API integrates data from all kinds of wearable devices, in a way that is very attractive for sports enthusiasts and health insurance companies. Is there any future for people who just want a quiet life, perhaps chilling with their cat, drinking beer or knitting socks? Why not use your Apple Watch or Fitbit to make your life more enjoyable rather than setting more and more performance targets? Your goal is to make an application so attractive that everyone will understand why your lifestyle is the coolest. The more devices you integrate via the API, the less you would need to worry about optimising your life.</p>"},{"location":"The_Busking_Bus-Stop.html","title":"The Busking Bus Stop","text":"<p>ijl20@cam.ac.uk</p> <p>Cambridge buses are fitted with GPS tracking equipment. This is used to predict the arrival time for the next bus, as displayed on many bus-stops around the city. It is also collected in an archive of all bus journeys. It would be nice if the display provided more information, and did so in a more entertaining way, customised depending on how long the bus will take to arrive. Information snippets might include confidence intervals (in layman's terms) for actual arrival time based on historic data, and comparisons to other journey options. Entertainment might be automatically generated poems, fictional dialogues etc, that adapt intelligently to local context such as weather information, news stories and so on - but at a length appropriate to the remaining time. With luck, we hope to deploy the resulting system - at least on the stop outside the Gates building!</p>"},{"location":"The_Carbon_Eye.html","title":"The Carbon Eye","text":"<p>We all want to be warm in winter, but how can we do it without fossil fuels? British houses are woefully poor in their level of preparation for a zero carbon economy. This project will develop an app to be used with a thermal imaging camera phone accessory like the FLIR ONE Gen 3, to estimate carbon costs of the heat escaping from a building, and directly calculate financial costs and benefits of insulation, draft reduction, secondary glazing, heat pump installation etc.</p>"},{"location":"The_Deep_Learning_Society.html","title":"The Deep Learning Society","text":"<p>Yana.Afanasyeva@morganstanley.com</p> <p>Technology companies invest billions in self-driving cars and self-playing computer games, but surprisingly little in real social problems. Your task is to use the latest deep learning technologies to create an intelligent social work assistant that can recognise and act in situations of real need. Your client will provide a GPU-accelerated system suitable for use with deep learning frameworks like Google TensorFlow. You will train it using data from online social networks such as MumsNet, to recognise and anticipate situations where people are going to use words like \u201chopeless\u201d, \u201cdepressed\u201d or \u201csuicide\". With the help of deep learning, even a simple Bag of Words, together with metadata such as time of day, location and comment feedback will be sufficient to recognise trigger conditions in large data sets and mobilise assistance.</p>"},{"location":"The_Fusion_Works.html","title":"The Fusion Works","text":"<p>Contacts David Russell david@thefusionworks.com and Lindsay Manning Lindsay@thefusionworks.com</p> <p>1) VR Motion Sickness</p> <p>Motion sickness in VR is an imprecise science. There's a number of factors that don't necessarily impact everyone in the same way. Possible causes include;</p> <p>Your brain trying to process movement whilst your body is still Images being slightly out of sync with your actions e.g. turning my head and imagery being more than 50 milliseconds behind Refresh rates on the LCD screens inside the headsets Field of view (or lack of) within a headset</p> <p>We've been caught out by it on a recent VR development and we consider ourselves experienced VR developers. NASA have recently been caught out, they did a VR app to allow users to explore the International Space Station. There was a great deal of feedback about it causing motion sickness. However some experiences do VR successfully with minimal motion sickness. An example of this would be a recent game called Star Wars Squadrons which is a mass market VR game. It contains many elements that should cause motion sickness but don\u2019t seem to. One of my colleagues believes this is due to a device they've included in-game which is a bobble head figure on your cockpit dashboard. The bobble head responds to the direction you steer your aircraft which might help in tricking the user\u2019s brain.</p> <p>There\u2019s general guidelines e.g. don\u2019t use VR if you have blocked sinuses and take frequent breaks but these relate to the symptoms rather than trying to stop it happening in the first place.</p> <p>This is of particular interest to us. Whilst VR is linked to gaming, it's not really our interest. We're doing more and more work with VR in other fields e.g. visualising architectural designs and CAD models, using VR within a medical or therapeutic for treating phobias or mental health issues. May users will be experiencing Virtual Reality for the first time and it's desirable to minimise motion sickness effects.</p> <p>I'm not sure what the end deliverable for a student project might be. A prototype VR application demonstrating best practice for example??</p> <p>Feedback:</p> <p>VR is usually popular with students, and we don\u2019t have any VR projects for next year. On the other hand, the VR headsets we have around the Lab are rapidly ageing (Oculus Rifts, largely DK1), and in the COVID era, it\u2019s a lot less attractive to strap things on your face that are being passed around students! I can imagine that students might create a reference implementation of a VR experience that is predicted to reduce motion sickness, although verifying this experimentally would make the project more appropriate for a dissertation than a group design project.</p> <p>2) Web RTC</p> <p>Feel free to ignore this bit\u2026 it\u2019s more notes for me\u2026 I\u2019m not sure how to turn this into something that students could work on\u2026</p> <p>Web RTC is a subset of the HTML5 spec and enables real time communications between browsers and devices. This might be audio/video or a real time peer to peer messaging mechanism. Whilst it\u2019s been in-use for the last decade by major sites (e.g. Facebook) the Web RTC standards have only recently been finalised. It\u2019s free, it\u2019s open source, it enables experiences that weren\u2019t possible and it\u2019s not tied to any proprietary software/company. It should, over time, begin to revolutionise web development.</p> <p>Web RTC development is hard. By it\u2019s nature its asynchronous. This is not the same kind of asynchronism as AJAX calls that many web apps currently use; those are simple by comparison. Instead, its many calls layered over each other with ever changing local and remote data. Developing, testing and debugging is tricky\u2026 how might we improve on this\u2026</p> <p>Feedback:</p> <p>Would Web RTC be suitable for taking multiple MIDI streams from different sources, time-stamping, and reassembling into a synchronised band at the other end? I recently heard a fairly impressive session at the Network Music Festival, where the band set up a four-bar riff, then each player added improvisations that would be layered on the *next* four bars. This could be set up as a blues jam, where you get on-screen queues on what chord the song is up to, and you add MIDI notes that are stored and forwarded for integration at the right time.</p> <p>Previous involvement when company name was Altfusion</p>"},{"location":"The_Headless_Bicycle.html","title":"The Headless Bicycle","text":"<p>An unfortunate accident during the 2018 group design projects resulted in us blowing up the display head of an exercise bicycle loaned to us by a project client/ Your task is to revive it with a virtual reality rolling road display, using the same sensor data supplied to the old display. One possibility would be to cycle on real roads, using Google Streetview imagery to virtually leave the Gates Building. Interactive games could also be considered.</p> <p>Has been proposed as a possible project for Smart Cambridge. in combination with public transport data feeds</p>"},{"location":"The_Hut_Group.html","title":"The Hut Group","text":"<p>Harry.Collard@thehutgroup.com</p> <p>Retail Startup Automator</p> <p>Previous discussion:</p> <p>Information Extraction from Semi-structured Web Pages</p> <p>Although content on the web is written using a common structured markup language, the implementation by different websites varies widely: Your task is to implement an information extraction system that can extract content from e-commerce websites. Your system should be able to reliably extract product content and data from a variety of semi-structured product pages. You should then build a web application around this algorithm. Examples include: an e-commerce aggregator, effectively allowing shoppers to browse products from a broad swathe of online retailers, or a comparison site for clothing that can compare competitor products across brands by intelligently matching metadata.</p> <p>Feedback:</p> <p>Harry - can you give a little more information about what new business opportunities might be possible as a result of extracting the information? I'd like to identify some more specific technical challenges - at the moment, it seems like the intention would be just to create another price comparison or retail aggregator site. This is a fairly crowded market, so it's possible that students would not see much novelty.</p> <p>Previous years:</p> <p>2014: Purchase Abandonment Predictor</p> <p>Buying Pattern Prediction</p>"},{"location":"The_New_Internet_of_Things.html","title":"The New Internet of Things","text":"<p>Research](Microsoft_Research \"wikilink\") smehan@microsoft.com</p> <p>Lives and businesses have been transformed by the pandemic, with network technology now more critical than ever. What are the implications for smart buildings and the Internet of Things? Which classic IoT use cases are now irrelevant, and what new opportunities are there? Your task is to use the Microsoft Azure Sphere IoT platform to address one of the new problems of the COVID-19 era. Your client can provide a range of accessories (e.g cameras, sensors and actuators), and your solutions should be documented openly (e.g. on GitHub) to enable broader benefits.</p>"},{"location":"The_Poet_Laureate%27s_web_thresholds.html","title":"The Poet Laureate's web thresholds","text":"<p>The Poet Laureate Carol Ann Duffy has appointed 10 leading poets to work with Cambridge University Museums and young people from the county. Your task is to provide a novel tool that can emulate the exact layout of any page from a museum web server, but with the original text (perhaps partly) removed. Invited poets and young people should be able to substitute their own poetry or other text by typing directly over the visual layout as if in a drawing editor. These transformed pages can then be published and viewed from an alternative server that offers a \"mashed up\" version of any museum page for public viewing. The technical challenge is to give users the impression that they are really typing directly onto the rendered web page, as if onto a piece of paper, and to do so in a way that emhasises typographic freedom, allowing poets direct control over all concrete aspects of the juxtaposed text.</p>"},{"location":"The_Politics_of_Wikipedia.html","title":"The Politics of Wikipedia","text":"<p>Much of the content of Wikipedia is encyclopaedia-like, but Wikipedia editors also respond to current events. The goal of this project is to highlight which parts of Wikipedia are more political (or at least contemporary), by correlating Wikipedia edits with recent traffic on Twitter. You should create a custom application for viewing Wikipedia, in which the content the user sees is customised and updated to follow Twitter traffic. Users should be able to navigate according to recency, popularity, or controversy. They should also have some way to know (through correlation analysis) when different topics or pages appear to be alternative views of the same underlying events.</p>"},{"location":"The_technical_textbook_of_the_future.html","title":"The technical textbook of the future","text":"<p>Publishers](Open_Book_Publishers \"wikilink\") rupert.gatti@openbookpublishers.com</p> <p>In fast-moving technical fields, it is hard to keep good textbooks up to date. Online resources such as wikipedia are useful ways to collect expertise, but articles written by technical experts are not always the best way to learn. It's hard work to collect good teaching examples, suggest tests and exercises and so on. Your task is to design an application that offers the best of both worlds - a book that can be accessed from browsers or mobile devices, preserving a clear voice for the author, but also allowing mashups at varying levels of granularity with other textbooks, student forums, class exercises and presentation materials, and discussion among expert teachers at any level of content. Different users (schools, teachers, or learners with special needs) should be able to create the learning paths that suit them best, and also share them with others. The final product shouldn't look like another blog, forum or wiki - you will need to think what design elements and user experiences are associated with a professional and authoritative knowledge source.</p>"},{"location":"Touch_screen_prototyping_at_school.html","title":"Touch screen prototyping at school","text":"<p>Touch screen prototyping at school</p> <p>Secondary school design and technology teaching includes an emphasis on inclusive design - creating products that are available for use by a wider range of the population. At present, school students don't get to learn about interactive software design, but they probably know that products like touch-screen smart phones are a major obstacle for their grandparents, and students should have a chance to learn about how to improve matters! Your task is to create a low cost system for prototyping new touch screen interfaces, that is sufficiently easy to use that 12 and 13 year-olds can experiment with alternative phone designs. The whole system should be sufficiently compact that it can be deployed on a Raspberry Pi (we can supply large touch screens that can be interfaced to the Pi).</p> <p>Category:Raspberry Pi</p>"},{"location":"Trading_Assistant.html","title":"Trading Assistant","text":"<p>evald.monastyrski@imc.com</p> <p>Not all trading happens on the exchange -- sometimes counterparties trade directly through human-to-human communication. In such cases, humans typically use their most natural interface: voice. Your task is to create a service which holds market data and responds to queries on demand in a human-like manner, by automating one side of the process using modern technologies (voice recognition, natural language processing and voice production).</p>"},{"location":"Trading_Reasons.html","title":"Trading Reasons","text":"<p>Client not assigned</p> <p>The valuation of commodities and investments according to their expected future value is a key part of our economy. Unfortunately, some people damage this system for a joke, as in recent scandals over GameStop and Dogecoin. The goal of this project is to create an alternative investment platform in which every trade is securely associated with a reason for the valuation, ideally with links to public sources. Other investors should be able to make judgements based on aggregated assessments of the reasons given, based on natural-language processing methods, to help assess how serious the opportunity really is, and whether they want to risk their own money for the same reasons.</p>"},{"location":"Trading_input_visualization.html","title":"Replaced by Virtual Reality Trading Desk","text":"<p>Client: Taylan Toygarlar, IMC (Netherlands) (Taylan.toygarlar@imc.nl)</p> <p>In this project you will be constrained to a single desktop grade machine with a high-end GPU. Most traders need to either monitor or take in a very large number of, often numerical, inputs and process them quickly. The aim of this project is to amalgamate this data in an easily digestible format that a human can effectively process. The visualization will consist of different views on the same data, focusing on different aspects. Apart from standard plots like scatterplots, histograms and cdfs, on-the-fly filtering and brushing techniques are an important part of this project. New gadgets like 3D goggles(oculus rift) or myo can be used for achieving extraordinary results.</p>"},{"location":"Trading_input_visualization.html#feedback","title":"feedback","text":"<p>I have quite a lot of experience with these kinds of visualisation techniques, but I know that there are commercial products that already do most of what you are proposing out of the box.</p> <p>In these design projects, I like students to have the opportunity to create a novel product of some kind. I was intrigued by your suggestion that an Oculus Rift might be used, but from our experience so far, the performance of the Oculus Rift is rather disappointing when used with graphics cards of the kind that our students have access to. I'm sure they would be excited by the opportunity to work with the device, but we would have to make arrangements to get some special hardware for them. At present, I'm not sure that the proposal is sufficiently concrete to justify this effort - but if you were particularly enthusiastic, and perhaps had hardware that you would like to loan to them, I would be happy to look for a potential technical approach.</p> <p>However, as I already discussed with Elisa, we have not had clients coming from so far away before. When Cambridge companies are involved, it is pretty straightforward to arrange equipment loans and so on. The additional expense and inconvenience of arranging all this from the Netherlands might put rather too much stress on the project team to meet high expectations.</p>"},{"location":"Training_Investigative_Interviewers.html","title":"Training Investigative Interviewers","text":"<p>soarhuang@gmail.com</p> <p>Investigative interviewing is a critical step in gathering evidence for any investigation. The types of questions posed by the investigators can make or break the accuracy of a witness' testimony. Therefore, investigators and legal professionals have to get specialised training and continuous feedback in order to keep up with best interview practice to secure best evidence. However, legal professionals and government organisations are typically working under limited resources. Your task is to build an easily accessible app for them to practice their questioning skills and get instant feedback (e.g., using large language models to detect question types and detect leading/suggestive practice) to help them continuously improve their practice beyond their training sessions. The data set you will be working with are (fully anonymised, of course) real-life child abuse cases investigative interview and court transcripts, which are extremely sensitive materials. So your contribution will really be making a difference for better justice!</p>"},{"location":"Transparent_public_identity.html","title":"Transparent public identity","text":"<p>Suggestion from Ross Anderson Ross.Anderson@cl.cam.ac.uk</p> <p>Here's an idea. I was at the Europarl yesterday and a green MEP said it would be great to have a \"tranparency app\" that would enable her and her colleagues to look up the registered interests of people who come to meetings. This would involve (a) writing apps for android and iphone (b) having a service that would go to the various registers of interests in Brussels, London etc, aggregate entries and make them available (c) some smarts to make it usable. For example it would help that if Mr Johann Schmidt were registered as getting funding from Infineon AG, that the app would say that Infineon makes smartcards for use in banking and as identity cards.</p> <p>Do you think this might make a suitable project, or is it too small? As for a user, I could ask the guys at Privacy International if one if them would volunteer, or in extremis I could be the customer myself</p>"},{"location":"Transport_Game.html","title":"Transport Game","text":"<p>Research](Cambridge_Architectural_Research \"wikilink\") steve.platt@carltd.com</p> <p>It's hard for voters and taxpayers to assess what impact different funding policies will really have on their lives. The goal of this project is to create an online game that will enable users to explore issues of transport funding and, in particular, to measure their personal costs and benefits from road pricing. An underlying model provided by the Cambridge Centre for Smart Infrastructure and Construction can be used to simulate the key features of the Cambridge transport network, with users plotting a number of their typical journeys to create a baseline. They will then be given the opportunity to \u201cpurchase\u201d benefits in the form of a range of transport infrastructure and service improvements, for example road quality and public transport. According to the choice of benefits made, the user will incur a variable mileage-based road user charge, whose proceeds are available for spending on transport. Making changes in travel behaviour - for example making a journey by bus or bicycle rather than by car - will allow the user to reduce or avoid the charge. The model will also allow users to opt for a reduced rate of charge and/or a compensating reduction in fuel duty, with a personalised benefit-cost ratio compared to other players.</p>"},{"location":"Travelling_Businesswoman_Problem.html","title":"Travelling Businesswoman Problem","text":"<p>Mike.Harfoot@unep-wcmc.org</p> <p>We all need to reduce our Carbon Footprints and for many businesses, flights are a major component of this. Your task is to prototype an online system to help a small company (~100 staff) reduce its footprint by optimising planned travel on an annual basis. Staff should be able to input potential business trips to other institutions, conferences and meetings as well as contacts or locations that it would be beneficial to visit if the opportunity arose. You should consider simple ways to collect this information and to display advice or suggestions during the planning of a trip.</p>"},{"location":"UMZC.html","title":"UMZC","text":"<p>University Museum of Zoology</p> <p>Contact: Matthew Hayes</p> <p>https://www.museum.zoo.cam.ac.uk/</p> <p>2020 project: Electronically Cataloguing Butterflies</p>"},{"location":"UNEP-WCMC.html","title":"UNEP WCMC","text":"<p>(UNEP World Conservation Monitoring Centre)</p> <p>2020 projects:</p> <ul> <li>Ecosystem Game</li> <li>Support Sustainable Wildlife   Trade</li> <li>Travelling Businesswoman   Problem</li> </ul> <p>Potential contacts for 2020:</p> <p>Mike Harfoot Mike.Harfoot@unep-wcmc.org (computational modelling)</p> <p>Ben Tregenna ben.tregenna@unep-wcmc.org (data infrastructure)</p>"},{"location":"UNEP-WCMC.html#outlines-for-2020","title":"Outlines for 2020","text":"<ul> <li>Travelling Businesswoman Problem</li> </ul> <p>We all need to reduce our Carbon Footprints and for many businesses, flights are a major component of this. Design an online system to help an SME (~100 staff) reduce its footprint by optimising planned travel on an annual basis. Staff should be able to input potential business trips to other institutions, conferences and meetings as well as contacts or locations that it would be beneficial to visit if the opportunity arose. The team should consider simple ways to collect this information and to display advice or suggestions during the planning of a trip.</p> <ul> <li>Support Sustainable Wildlife Trade</li> </ul> <p>UNEP-WCMC supports many developing countries in assessing the potential levels for sustainable trade in wildlife for particular species. The challenge for this team will be to use the data provided by existing APIs to power a tool for countries to follow a methodology for producing these reports for a given species/family. The tool must be easy to use in target developing countries and allow the user to provide additional local knowledge to supplement the global data provided by existing data APIs and finally produce a summary report for future policy use.</p> <ul> <li>Ecosystem game/visualisation</li> </ul> <p>UNEP-WCMC have been pioneering the development of an agent based model of whole ecosystems, the Madingley model. This process based formulation provides an engine that can be used in many ways. One of the key ways we would like to use the model is to engage with the public and/or decision makers. So, the challenge for the team working on this project will to consider options for improving the way the model can be used, either through a game interface or a visualisation interface for the model engine. The principal aim will be to make the model more engaging and exciting.</p>"},{"location":"UNEP-WCMC.html#previous-years","title":"Previous years:","text":"<p>Eco-Location</p> <p>Wildlife and critical ecosystems around the world are protected by over 230,000 legally recognised zones called protected areas. These protected areas range in size from local nature reserves such as at Coldhams Common https://protectedplanet.net/555561770 through to iconic national parks like the Serengeti https://protectedplanet.net/555570276.</p> <p>Many user groups need access to this data. Whether they are global extractives businesses looking to avoid environmentally sensitive areas when planning concession sites, academic researchers in the field wanting to know how a specific species interacts with the protected area network, or tourists looking for a local beauty spot.</p> <p>Whilst these areas can be visualised geospatially on https://protectedplanet.net, there\u2019s currently no quick way to discover your current proximity to nearby protected areas. Furthermore, the data is limited to technical information about the size and classification of the site. There is no information about what\u2019s inside any given protected area. Is it barren scrubland or dense forrest? Is there evidence of agriculture where there shouldn\u2019t be, or has the area been flooded? This extra level of information is extremely useful for conservationists (including park managers) to track the health of a protected area.</p> <p>Your task is to build a mobile application that enables the user to quickly orientate themselves with nearby protected areas, and serve vital contextual data about those areas by accessing other services. You should specifically include data from the European Space Agencies Global Land Cover Layer to show the percentage of cover types within the protected area (e.g. 40% Mosaic vegetation, 60% Mosaic grassland), and you may include other information such as geolocated photos from Flickr, or species from the IUCN red list of threatened species.</p>"},{"location":"UNEP-WCMC.html#ideas-for-2017","title":"Ideas for 2017:","text":""},{"location":"UNEP-WCMC.html#revised-ideas","title":"Revised ideas","text":"<p>for \"Finding Nature\"</p> <p>The European Space Agency publish a global land cover map. Students could use this to show statistics on the type of land cover and vegetation across a given protected area (e.g 40% Mosaic Grassland, 10% bare areas). Its available via an API supplied by https://ramani.ujuizi.com/ (you can view the data here https://ramani.ujuizi.com/maps/index.html#, and the classifications here https://ramani.ujuizi.com/maps/layer_simS3seriesCoverGlobal_info.html) but also directly from the ESA http://due.esrin.esa.int/page_globcover.php if they want to get into some web GIS.</p> <p>Using the ESA land cover map seems like a great idea. Mashing this up with the protected areas database should indeed be about the right level of complexity.</p> <p>What might the functional goal be? To support activism or lobbying, or perhaps eco-tourism, or citizen monitoring of development projects? For students who have only a vague engagement with current affairs, it may be necessary to give a fairly heavy hint about the benefits that could be delivered by the novel technical capability.</p>"},{"location":"UNEP-WCMC.html#finding-nature","title":"Finding Nature","text":"<p>Wildlife and critical ecosystems around the world are protected by over 230,000 legally recognised zones called protected areas. These protected areas range in size from local nature reserves such as at Coldhams Common https://protectedplanet.net/555561770 through to iconic national parks like the Serengeti https://protectedplanet.net/555570276.</p> <p>Many user groups need access to this data. Whether they are global extractives businesses looking to avoid environmentally sensitive areas when planning concession sites, academic researchers in the field wanting to know how a specific species interacts with the protected area network, or tourists looking for a local beauty spot.</p> <p>Whilst these areas can be visualised geospatially on https://protectedplanet.net, there\u2019s currently no quick way to discover your current proximity to nearby protected areas.</p> <p>Your task is to build a mobile application that enables the user to quickly orientate themselves with nearby protected areas, and serve vital contextual data about those areas by accessing other services such as the IUCN list of threatened species http://www.iucnredlist.org/ or geolocated photographs of the area.</p> <p>Consider what other information might be useful (and useable) in a mobile context such as direction &amp; distance to the boundary, or is available through open data initiatives such as https://openoil.net/</p> <p>Feedback:</p> <p>A clear and straightforward application, but slightly below the level of technical ambition that we typically aim for. It may well be possible to think of an enhancement - for example, integrating with climate data to assess effects of industrial pollution or infrastructure projects resulting from prevailing windspeed.</p>"},{"location":"UNEP-WCMC.html#unearthing-the-scale-of-illegal-wildlife-trade-facilitated-by-the-web","title":"Unearthing the scale of illegal wildlife trade facilitated by the web","text":"<p>The black market for illegal wildlife products is worth an estimated \\$19billion USD a year putting it on a par with drugs, human trafficking and arms dealing in terms of scale.</p> <p>Much of this trade is facilitated on-line either by traders knowingly breaking the law, or innocent (if misguided) consumers buying items without realising they are fuelling international crime and pushing many species to the brink of extinction.</p> <p>Your task is to analyse social media and online market places (such as eBay and Etsy) to identify possible illegal wildlife trade in specific items (such as ivory) or species in order to establish a credible, defensible figure on the scale of the problem. How will you overcome simple problems such as those people posting to raise awareness of wildlife crime, and those facilitating it?</p> <p>Once you have an efficient way of identifying the number of posts / adverts relating to illegal wildlife crime within a given time period, what other insights can you identify? Where are the biggest markets (geographically and on-line) for example?</p> <p>Feedback:</p> <p>Would the CITES database be the best reference source for a list of species that might be traded? It is easy enough to connect \u201civory\u201d with \u201celephant\u201d, but how might other species be connected with products that are made from them? One possibility would be to use wordnet to establish relationships between animals and sales descriptions, but I suspect it does not have good coverage of exotic species. Another would be to scan Wikipedia pages for endangered species, in order to find terms that might appear in advertisements. Is this the kind of thing you had in mind? This becomes rather more challenging, though we could perhaps build on Microsoft Cognitive Services APIs.</p>"},{"location":"UNEP-WCMC.html#2016-proposal","title":"2016 proposal","text":"<p>Strategic Selection</p> <p>Some species are endangered, but not very genetically interesting, while some very interesting species are (fortunately) rather common. International legislation and conservation efforts should be prioritised accordingly, but there is so much data to be taken into account that it is hard to decide where to expend one\u2019s efforts.The http://www.speciesplus.net/ application provides taxonomy, legislation, distribution and trade information on controlled species (which you can search filter and download), and the Trade Database, http://trade.cites.org/ gives historic trade data on all animals traded and which are covered under the Convention on International Trade of Endangered Species of Wild Flora and Fauna (CITES). Your task is to create an evolutionary family tree that, rather than emphasising natural selection, helps users navigate toward branches of the tree that need strategic selection.</p>"},{"location":"UNEP-WCMC.html#early-ideas","title":"early ideas","text":"<p>We work on data visualisations, on-line geospatial mapping and taxonomic databases, generally focused on trying to communicate complex data to non-specialists (policy &amp; decision makers), so we believe in taking a strong user centred development approach to our work.</p> <p>In terms of taxonomic databases a good place to start would be our http://www.speciesplus.net/ application which lists taxonomy, legislation, distribution and trade information on controlled species (which you can search filter and download), and the Trade Database, http://trade.cites.org/ which gives historic trade data on all animals traded and which are covered under the Convention on International Trade of Endangered Species of Wild Flora and Fauna (CITES). Again, you can filter and download this data freely.</p>"},{"location":"UNEP_World_Conservation_Monitoring_Centre.html","title":"UNEP World Conservation Monitoring Centre","text":"<p>tim.wilkinson@unep-wcmc.org</p> <p>2017 project:</p> <p>Eco-Location</p> <p>Previous discussion under the name:</p> <p>UNEP-WCMC</p>"},{"location":"Ubisense.html","title":"Ubisense","text":"<p>2020 project: Planning Tools for Large Scale Location Tracking</p>"},{"location":"Umbrella_Analytics.html","title":"Umbrella Analytics","text":"<p>2021 project; De-biasing the Employment Process</p> <p>Introduced via Ideaspace</p> <p>Suggestion: might it be appropriate to build an experimental prototype of some kind of \u201cbias alert\u201d app, that could integrate analysis of news coverage about a company with scanning of internal correspondence, and perhaps also whistleblower channels? To make this less commercially sensitive, it could focus on policy bias, health response, or political instability</p>"},{"location":"Uncovering_the_Unimaginable_Pace_of_Raspberry_Pi.html","title":"Uncovering the Unimaginable Pace of Raspberry Pi","text":"<p>Contact: Milos Puzovic Milos.Puzovic@mathworks.co.uk</p>"},{"location":"Uncovering_the_Unimaginable_Pace_of_Raspberry_Pi.html#modified-proposal","title":"modified proposal","text":""},{"location":"Uncovering_the_Unimaginable_Pace_of_Raspberry_Pi.html#unlocking-the-graphics-power-of-the-raspberry-pi","title":"Unlocking the graphics power of the Raspberry Pi","text":"<p>The Raspberry Pi has become incredibly popular, and it's great for hobby applications, but its appeal to children is reduced by the fact that it's a little slow (for example, the Pi Edition of Minecraft doesn't support mobile characters). However, most applications are using only a fraction of its computational power. The good news is that the Raspberry Pi's System-On-Chip BCM2835 has a hidden gem: a Graphics Processing Unit (GPU) that can significantly improve performance of applications that use large blocks of data. At the moment, the GPU on Raspberry Pi is heavily underutilised. Your task is to enable applications written in the MATLAB language to exploit the Raspberry Pi GPU. As a demonstration of what can be achieved, it should be possible to implement high performance game physics such as real time cloth dynamics on a human character with moving clothes and hair (created using MATLAB Simulink toolboxes). It's your choice whether this is a mobile character in a sandbox game, a narrative cut-scene, or even an intelligent avatar such as the Zoe talking head.</p>"},{"location":"Uncovering_the_Unimaginable_Pace_of_Raspberry_Pi.html#added-detail","title":"added detail","text":"<p>Simulink has the built-in support for Raspberry Pi to build standalone applications (http://www.mathworks.com/hardware-support/raspberry-pi.html). This support has enable access to various audio and video algorithms through toolboxes such as DSP System Toolbox (http://www.mathworks.com/products/dsp-system/) and Computer Vision Toolbox (http://www.mathworks.com/products/computer-vision/). Unfortunately, the code that is generated to run on the Raspberry Pi only targets CPU and it does not make any use of GPU that is available on the chip.</p> <p>In order to be able to generate code that targets the GPU it would be necessary to customize build process (http://www.mathworks.com/help/rtw/ug/customizing-the-target-build-process-with-the-stf-make-rtw-hook-file.html). Using the hooks provided by the Simulink Coder you would be able to analyze the generated code and replace parts of the code with code that can target VideoCore ISA (https://github.com/hermanhermitage/videocoreiv/wiki/VideoCore-IV-Programmers-Manual). There are various toolchains that can target VideoCore and students will have an opportunity to evaluate them and decide which one would be the best suitable for integration. The toolchains available are:</p> <ul> <li>vasm assembler (http://www.ibaug.de/vasm/vasm.tar.gz) and vcc compiler   (http://www.ibaug.de/vbcc/vbcc_vc4.tar.gz)</li> <li>ACK compiler and toolchain   (http://tack.hg.sourceforge.net:8000/hgroot/tack/tack)</li> <li>LLVM port (EXPERIMENTAL) - https://github.com/phire/llvm</li> </ul> <p>To demonstrate the performance improvement the students would start with one of simpler algorithms that can be found in image processing or computer vision that are already implemented and available in Simulink. Once they have demonstrated the improvement one part of the group could implement an application in Simulink that adds real physics to the gaming application such as cloth motion.</p>"},{"location":"Uncovering_the_Unimaginable_Pace_of_Raspberry_Pi.html#original-proposal","title":"original proposal","text":"<p>Raspberry Pi, the credit-card size computer, has unleashed an army of children, hobbyists and professionals who have toyed with the computer to make many interesting uses for it, from monitoring weather outside of a shed to replacing old satellite navigation systems in the car. As many more people are joining this new wave they will want to have access to faster hardware. The good news is that Raspberry Pi\u00eds System-On-Chip BCM2835 has a secret gem in the form of a Graphics Processing Unit (GPU), which can significantly improve performance of applications that use large blocks of data. At the moment, the GPU on Raspberry Pi is heavily underutilised. Your task is to enable applications written in the MATLAB language to exploit Raspberry Pi\u00eds GPU in order to maximise the performance of the application. At the end of the project, you will be able to demonstrate how applications that rely on computer graphics execute faster with your project, opening up new possibilities for users of Raspberry Pi.</p> <p>Category:Raspberry Pi</p>"},{"location":"United_Nations_Environment_Programme_World_Conservation_Monitoring_Centre.html","title":"United Nations Environment Programme World Conservation Monitoring Centre","text":"<p>(via 'Chris Sandbrook' cgsandbrook@gmail.com</p> <p>Proposed client for Race the wild</p> <p>Waiting for confirmation</p>"},{"location":"University_Information_Services.html","title":"University Information Services","text":"<p>Contact for 2022: Abraham Martin amc203@cam.ac.uk</p> <p>Ian Leslie also suggested that Kate Livingstone might be interested in future</p> <p>Previously: The Busking Bus-Stop</p> <p>Cambridge buses are fitted with GPS tracking equipment. This is used to predict the arrival time for the next bus, as displayed on many bus-stops around the city. It is also collected in an archive of all bus journeys. It would be nice if the display provided more information, and did so in a more entertaining way, customised depending on how long the bus will take to arrive. Information snippets might include confidence intervals (in layman's terms) for actual arrival time based on historic data, and comparisons to other journey options. Entertainment might be automatically generated poems, fictional dialogues etc, that adapt intelligently to local context such as weather information. news stories and so on - but at a length appropriate to the remaining time. With luck, we hope to deploy the resulting system - at least on the stop outside the Gates building!</p>"},{"location":"Unlocking_the_graphics_power_of_the_Raspberry_Pi.html","title":"Unlocking the graphics power of the Raspberry Pi","text":"<p>Milos.Puzovic@mathworks.co.uk</p> <p>The Raspberry Pi has become incredibly popular, and it's great for hobby applications, but its appeal to children is reduced by the fact that it's a little slow (for example, the Pi Edition of Minecraft doesn't support mobile characters). However, most applications are using only a fraction of its computational power. The good news is that the Raspberry Pi's System-On-Chip BCM2835 has a hidden gem: a Graphics Processing Unit (GPU) that can significantly improve performance of applications that use large blocks of data. At the moment, the GPU on Raspberry Pi is heavily underutilised. Your task is to enable applications written in the MATLAB language and models designed in Simulink to exploit the Raspberry Pi GPU. As a demonstration of what can be achieved, it should be possible to implement high performance game physics such as real time cloth dynamics on a human character with moving clothes and hair (created using MATLAB and Simulink toolboxes). It's your choice whether this is a mobile character in a sandbox game, a narrative cut-scene, or even an intelligent avatar such as the Zoe talking head. Contact the client for access to the Simulink target development tools, and advice on the GPU porting process.</p> <p>Category:Raspberry Pi</p>"},{"location":"Urban_Stories.html","title":"Urban Stories","text":"<p>david@thefusionworks.com</p> <p>The what3words service has become very successful, with its pitch that three random words can identify any location on the planet. If you\u2019ve used it, you may have noticed that the random words are often strangely relevant to the Cambridge locations being specified - if not for one particular cell, then quite likely for the cell next to it. Your task is to use a combination of natural language processing and path optimisation methods to turn these into engaging stories, starting from the creative seed of places you have visited, or perhaps would like to visit.</p>"},{"location":"VR_AI_Ping_Pong_Trainer.html","title":"VR AI Ping Pong Trainer","text":"<p>mjohnson@frontier.co.uk</p> <p>AI and VR are the most exciting areas in computer science today, and this is a chance to bring them together. We would like you to create a VR application displaying a simple view of a Table Tennis table, bats, and ball, and an environment to administer a game of Ping-Pong. However, we would like the opponent to be an AI which you are attempting to coach. It may be useful to have the option to run fast automatic training also to refine your bots, but the ultimate aim is to provide some human training, and to be able to play them directly in VR. It may also be interesting to pitch two independently trained bots against each other, and see how they behave. Rather than arcade games using different function buttons, ping pong can be controlled wholly from position, rotation and motion of a bat, suggesting that all user interaction might be implemented using a Wiimote controller.</p>"},{"location":"VR_Algorave_DJ.html","title":"VR Algorave DJ","text":"<p>mjohnson@frontier.co.uk</p> <p>Why can't a DJ be more like an orchestra conductor, remixing instrumental sections and adding new expressive content, instead of simply selecting from a library of prerecorded tracks? In the future this will be possible, using gesture controllers in virtual reality. Your task is to create a VR space in which the DJs of the future will edit and configure algorave-style music synthesis programs. You can use APIs for the Sonic Pi music language from Cambridge's Sam Aaron as a back end to produce professional-standard musical results. We can provide an Oculus Rift and Myo gesture control armband for an immersive experience (and some professional audio gear for the demonstration day).</p>"},{"location":"VR_Avatar.html","title":"VR Avatar","text":"<p>mjohnson@frontier.co.uk</p> <p>With the growth of online VR spaces, users lack a consistent identity, and a way of expressing themselves to each other. Create 1) a VR Avatar API that provides an customisable animating model representing the user, and 2) an example app to demonstrate its application. The model must smoothly animate to reflect the user's physical pose from the hand controller and headset position and orientation data (perhaps employing inverse kinematics). Provide some means by which a user could drive emotive animations and expressions (such as shows of surprise, pity or anger). Consider customisations for the Avatars, and provide some back end service or 'Shop' for extensions or customisations to be downloaded.</p>"},{"location":"Vet_School.html","title":"Vet School","text":"<p>Department of Vetinary Medicine</p> <p>Heidi Radke, &lt;https://www.research.vet.cam.ac.uk/research-staff-directory/principal-investigators/systems-pathology/Heidi-Radke&gt;</p> <p>2020 project: Remote Animal Recovery Monitoring</p>"},{"location":"Veterinary_Medicine.html","title":"Veterinary Medicine","text":"<p>Potential client: Heidi Radke hr264@cam.ac.uk</p> <p>Like humans, dogs often suffer from injuries and problems in their joints. But while medical research constantly collects data on treatment and outcomes for humans, there is no data resource to monitor postoperative recovery in small animals. A mobile phone app would allow the dog carers to monitor progress of their dogs during recovery after orthopaedic surgery, would provide information on what to expect, and would allow dog carers to connect with their consultant easily and efficiently. You have a chance to work with a leading veterinary orthopaedic surgeon specialising in treatment of these conditions, with the potential to significantly improve the quality of life for many animals with this new form of remote patient support.</p>"},{"location":"Video_Bones.html","title":"Video Bones","text":"<p>The trombone is a beautiful instrument, at its best when viewed from multiple sides and heard from a distance, as in this video by Phil Cambridge: https://www.youtube.com/watch?v=dAM2qJ0m7Oc. Like Phil, we could all do with better tools for composing and publishing multitrack audio and video streams of the kind that became familiar during lockdown. Your task is to create a music-specific multitrack video editor with everything a brass player needs, perhaps incorporating solo and chorus, virtual camera pan and rotate of instruments and chamber groups, hip hop loops and video stutters, or other effects suited to your favourite music genres.</p>"},{"location":"Virtual_Agronomist.html","title":"Virtual Agronomist","text":"<p>charles.gentry@niab.com</p> <p>Each year NIAB publishes its Agronomy Strategy to help farmers grow successful crops. The comprehensive advice is based on NIAB's internal research and covers a range of topics including: crop choice and rotation, seed rate and establishment, weed control and fungicide strategies. NIAB would like to use this guide to produce a 'virtual agronomist', an expert system which can be used by farmers to answer their questions. The system should be able to accept a basic natural language question, e.g. \"What seed rate should I use for late sown wheat?\" and either show the relevant answer, or prompt for more information with further questions, e.g. \"What variety of wheat have you sown?\", and so on. The virtual agronomist should be accessed through either a website or messenger platform (e.g. WhatsApp). Basic reporting should be made available to administrators, such as frequent query subjects, to identify where to direct new research.</p>"},{"location":"Virtual_Reality_Cylinder_Seal.html","title":"Virtual Reality Cylinder Seal","text":"<p>Cylinder seals, as used by the Babylonians, are beautiful things. They are carved with the inverse of a linear design, so that when rolled across wet clay they will create a strip relief. But they are hard to create, because they involve making an inverse carving. With modern technology, we could carve a cylinder seal by looking outward from the inside, carving the surface around the 360 degrees of the cylinder, but working from underneath the surface. In this project you will create software tools to allow an Oculus Rift user to carve a cylinder seal from the inside, then generate the input to a 3D printer that will make the actual cylinder.</p> <p>Idea arose from a discussion with Fred Baker. He wants to use it himself in a film production proposal, and wants to retain all intellectual property in the idea of using cylinder seals in virtual reality, so not suitable for group project at this stage.</p>"},{"location":"Virtual_Reality_Trading_Desk.html","title":"Virtual Reality Trading Desk","text":"<p>(Netherlands)](IMC_(Netherlands) \"wikilink\") (Taylan.toygarlar@imc.nl)</p> <p>Financial markets today are one of the biggest raw data generators of our time, with billions of data points per day for some products. Most traders need to digest a very large number numerical and graphical inputs - they use four, six, eight or more screens - but can't see or reach all the data they need. In this project, you will use an Oculus Rift VR headset to distribute market data and visualisations in the virtual space around a trader. By turning their head, or looking up and down, they should be able to review rapidly changing data in various formats, and have their attention drawn to the most urgent changes if they need to act. The design of the visualisations could emulate those found in products such as Thomson Reuters Eikon - but it will be necessary to adjust these to the display characteristics of the Oculus Rift.</p>"},{"location":"Virtual_Science_Ambassador.html","title":"Virtual Science Ambassador","text":"<ol> <li>REDIRECT Robot Science     Ambassador</li> </ol>"},{"location":"Virtual_World_Generator.html","title":"Virtual World Generator","text":"<p>Simulations](Bohemia_Interactive_Simulations \"wikilink\") andy.fawkes@bisimulations.com</p> <p>It is possible to make accurate 3D scans of indoor scenes using depth cameras such as Google Tango or expensive LIDAR scanners. Although the overall geometry is accurate, individual objects cannot be distinguished. Your task is to use a simple SLAM algorithm to recover overall room dimensions, but populate a navigable virtual world in OpenGL using standard 3D library models of furniture and other objects that have been recognised as belonging to relevant categories using pre-trained deep neural net models such as NeuralTalk Model Zoo.</p>"},{"location":"Visiting_the_Forest_Stream.html","title":"Visiting the Forest Stream","text":"<p>There are many Spotify playlists featuring the sound of nature, but it's hard to visit the places those sounds were recorded, or meet the people that live there. This project is an environmental update on music artists who make more money from concert visits and merchandise than they do from streaming licenses. Your client has been working with a forest community in Ghana, where the environmental soundscape doesn't bring any revenue to the village. The goal is to create a geolocated mobile app and business model, connecting distinctive sounds to new revenues from ecotourism.</p>"},{"location":"VisualDNA.html","title":"VisualDNA","text":"<ol> <li>REDIRECT Personal/national mood     tracker</li> </ol>"},{"location":"Visual_Analytics_for_Hardware_Design.html","title":"Visual Analytics for Hardware Design","text":"<p>CIRCT recently introduced an open software stack for hardware design, which SiFive has used to build and ship production RISC-V chips. Understanding how hardware designs are optimised and translated to a physical layout is difficult due to the overwhelming amount of data. In this project, you will build a visual data analytics tool that helps hardware compiler engineers analyse the lowering process in detail. We propose to connect the open-source CIRCT (circt.llvm.org) EDA stack with the recently released Google Model Explorer (https://github.com/google-ai-edge/model-explorer) and augment the product with CIRCT-specific interactive analyses, as well as bi-directional analysis-transformations that allow to visualise and influence the compilation process. If successful, your tool will make a complex compilation process visually accessible to a broad community.</p>"},{"location":"Visual_Pick_and_Place.html","title":"Visual Pick and Place","text":"<p>We have a LitePlacer robot that can automatically assemble circuit boards (https://youtu.be/t__ybwOufyg), with a machine vision system based on OpenPnP. Unlike many computer vision problems, the cameras could in principle be moved around, getting better field of view or details of specific regions. Our robot currently uses the vision capabilities for simple tasks such as recognising board features and component tapes to align components it is placing. We would like to extend the capabilities of the system to automate the setup of the machine, for instance printing part numbers from CAD data on sticky labels that the vision system reads; configuring placement of component tapes; recognising parts from their shape or markings to rotate the tape; detecting parts and boards from text printed on them; and guiding the user through setup with augmented image views.</p>"},{"location":"Vitali.html","title":"Vitali","text":"<p>Proposed to: Stephen Devlin sd2030@cam.ac.uk</p> <p>Many older people find the full functionality of a system like Android, with its multiple apps, too confusing or difficult to use. Your task is to design a customisable replacement that can be configured remotely by a trusted person such as a child or sibling, and displays only a very small range of options to the user (e.g. \u201ccall Stephen\u201d, \u201cListen to Radio 4\u201d, \u201cWatch Last episode Eastenders\u201d). There will be difficult design decisions as you trade off generality with security.</p>"},{"location":"VoIP_Network_Quality_Tester.html","title":"VoIP Network Quality Tester","text":"<p>Networks](Metaswitch_Networks \"wikilink\") John.Palombo@metaswitch.com</p> <p>VoIP and Video calls are very sensitive to latency, jitter and packet loss in IP networks, but there aren\u2019t many good end-user tools available to determine how good a network is. This project creates a probe that users can run on a standard end user device (e.g. desktop, tablet or smart phone) that communicates with a remote server and provides an indication of how good the network is and predicts the quality of calls through it. Ease of use is essential \u2013 both to install/run and presenting the results in a user friendly manner. Idea could be extended for example to crowd-sourcing across many users in order to build a much wider picture of the network, or to predict quality of a gaming connection.</p> <p>Feedback: Very timely. However, students may not have suitable signal processing skills. Would this use separate audio hardware to inject and capture controlled signals, or rely on intercept of system audio? Would capture and analysis of video quality be an alternative?</p> <p>Response: The project can actually be much simpler than you are thinking and wouldn't need to sniff the network. You'd have two end point boxes, each sending a stream of packets to the other at a fixed rate (like a VoIP call, but you can think of it like a fast ping). The remote end would then gather stats about the packet arrival times, specifically packet delay (latency), the variation in packet delay (jitter) and lost packets. That data alone would be very useful to characterise how good a connection you have.</p> <p>You are right that the next step to interpret how that affects a call from knowledge of the codecs might be a bit tougher, but they could make an empirical judgement by actually making a VoIP call over the same network connection and judging the voice quality and correlating that with the packet stats. In order to have a suitably poor network connection to get some good data, they might need to get a bit creative by connecting over a poor wifi or mobile network, but that should be quite doable.</p>"},{"location":"Way_to_the_Clinic.html","title":"Way to the Clinic","text":"<p>reichelt.stefanie@gmail.com</p> <p>One of the group project coordinators recently attended an outpatient audiology clinic at Addenbrooke\u2019s hospital, cycling from the William Gates Building. His navigation tools totally let him down \u2013 after entering the Addenbrooke\u2019s site, half his route was by bike, while the other half was a maze of indoor corridors. Your task is to build an outdoor/indoor navigation app that helps Cambridge locals get to their hospital appointments, using APIs to the University Map, and adapting the open source OpenRoomMap for specialised hospital data.</p>"},{"location":"Wearable_Sleep_Coach.html","title":"Wearable Sleep Coach","text":"<p>Terra API unlocks health and fitness data from diverse sources, including popular wearables and fitness apps like Fitbit, Apple Watch, Oura, and 70+ others. Your challenge is to leverage the Terra API to develop an AI coach that advises people on how to improve their sleep habits. The coach can be trained using data already acquired by Terra. Throughout the process you will be prompted to deploy and evaluate the performance with real users, do user interviews, and iterate on your product with the goal of attaining 100 users - this stage will also involve ethical review for deployment of instrumented software.</p>"},{"location":"Wearable_house_control.html","title":"Wearable house control","text":"<p>In recent years, smart IOT hardware has become mainstream and affordable. Common household devices include smart lights, sound systems, curtains or thermostats. In principle, a smart hub allows home-owners to control all of these. However, logging in to websites and control apps is more of a pain than just using light switches. Your goal is to provide integrated control from a wearable device (Android smart watch provided), that can be used to customises all functions in a room according to the combination of people present. At the least, the system should switch on the lights if one person is there, but it should also be programmable (or learn preferences and priorities) for music, privacy, temperature etc.</p>"},{"location":"West_Augmentation.html","title":"West Augmentation","text":"<p>Above&amp;Below](Studio_Above&amp;Below \"wikilink\") daria@studioaboveandbelow.com</p> <p>The view from the William Gates building, until recently a peaceful meadow for grazing horses, is now a building site. The public exhibition for this year\u2019s group design projects will look out at it. Your task is to create an augmented reality experience for visitors to explore an alternative speculative design. Visitors should be able to toggle between an AR visualisation of the buildings currently planned for that site, and a radically different style of building including parametrically generated plants and environmental features such as \u201ctree tenants\u201d (after Hundertwasser), urban farming, wildlife sanctuary etc. Visitors should be able to explore and interact with the augmented scene via multiple linked devices, including mobiles, large screens, projectors and VR headsets.</p>"},{"location":"West_Cambridge_Airfreight.html","title":"West Cambridge Airfreight","text":"<p>fciriell@mathworks.com</p> <p>You are tasked with the development of an autonomous drone delivery system for light-weight package transportation around the West Cambridge site. By using high-fidelity drone models from the new MathWorks UAV Toolbox, you will develop an autonomous ground control system that coordinates one (or more!) drones around the site. Consider how to incorporate path and task planning, motor and plant control, and sensing &amp; perception for navigation and obstacle avoidance. Evaluation in the realistic UE4 simulation will include simulated sensor data from 3D LIDAR readings and simulated camera input.</p>"},{"location":"What_makes_a_good_project.html","title":"What makes a good project","text":"<p>In general, a good project topic includes some combination of technical challenge, business opportunity, human interest, and opportunity for students to experiment with new technologies. We would suggest aiming for at least two of these properties, perhaps three, but all four in a single project would be excessive. It is worth scanning some examples of design briefs from previous years: 2025 list, 2024 list, 2023 list.</p>"},{"location":"What_makes_a_good_project.html#technical-challenge","title":"Technical challenge:","text":"<p>There should be a variety of technical challenges within each project, so that different members of the team can focus on different aspects. A challenge that is already a focus of intense commercial competition, such as \"invent a machine learning algorithm to predict stock-market prices\", will be beyond the ability of undergraduates, and will lead to disappointment because the result is certain to perform poorly by comparison to the state of the art as achieved by well-funded teams of PhDs.</p>"},{"location":"What_makes_a_good_project.html#business-opportunity","title":"Business opportunity:","text":"<p>A novel product or business model is more interesting than a \"me-too\" idea. Business viability is a relatively low priority - anything with a vaguely plausible market opportunity is fine. We understand that most technical start-ups pivot from their initial pitch anyway, so we don't expect computer science students to achieve anything beyond a concept that attracts popular attention.</p>"},{"location":"What_makes_a_good_project.html#human-interest","title":"Human interest:","text":"<p>Many students appreciate the chance to think how the world can be improved through technology. We are happy to see students address problems related to disability, inclusion, or economic and social inequality - either locally, nationally or globally (note that in some years, over 50% of our undergraduates come from outside the UK).</p>"},{"location":"What_makes_a_good_project.html#new-technology","title":"New technology:","text":"<p>Almost all computer scientists are gadget freaks. They love to work with the latest hardware and systems, and those opportunities inspire some creative teams. In recent years, we have seen great projects using VR headsets, wearable devices, location technologies, microprojectors and so on. If you have a particular device you'd like to see the students use, the teams often work with technology loaned by clients. The one thing to keep in mind is that they do not have much time to acquaint themselves either with new languages or complex API stacks.</p>"},{"location":"What_makes_a_good_project.html#things-that-have-failed-in-the-past","title":"Things that have failed in the past","text":"<p>See the list of projects that were pitched to students, but for which we weren't able to put together a team because too few students were willing to work on them. It's not always easy to see why these turned out to be unappealing, so may be no clear patterns, but at least these give some idea of what to avoid.</p> <p>https://wiki.cam.ac.uk/cl-design-projects/Main_Page#Projects_that_have_been_offered.2C_but_not_assigned_to_groups</p> <p>After keeping that list for a few years, some emerging patterns would seem to be that: our students are not motivated by projects related to road transport; they are not inspired by wine and food (apart from chocolate); they may be worried by projects related to surgical procedures; and they are not interested in poetry or dance. Despite this, we are always happy to explore the limits of their interests, so don't be too discouraged from proposing projects in these areas - just make sure they are appealing, and be prepared for cancellation.</p>"},{"location":"Who%27s_at_my_party%3F.html","title":"Who's at my party?","text":"<p>richard.jones16@boeing.com</p> <p>It's always disappointing when you've had a great night out, but you can't remember the details the next day. It would be creepy to photograph everyone, but simple to take a short video with a quick scan of the room. Your goal is to build a social media platform with video upload as the main user interface. Your back-end processing will apply open source machine vision libraries such as OpenCV, OpenFace and others to capture faces, match them against known friends, see who is talking to who (from head orientation) and so on. You should package the results as a fun and engaging social media site. Consider making a plugin using the WeChat Video API - or perhaps this could be the next Facebook!</p>"},{"location":"Who_Pays_for_Roads.html","title":"Who Pays for Roads","text":"<p>Proposed to Christopher Newfield chris.newfield@isrf.org</p> <p>You may have noticed that many roads in Cambridge are not in good repair. How are decisions made, on the mathematical relationship between the weight of a car or lorry and how much it wears the road surface, the seasonal and climate factors in repairing potholes, the cost of treating an undergraduate cyclist for a broken arm in A&amp;E, or the economic impact of a change to their final degree class? Heterodox economic modelling is a strategy for considering all the relevant factors, rather than being driven by culture wars that distract political debate from the reality of physics. Your task is to create a model that can be used to plan road network changes in a way that optimises all social factors, not just the result of the next general election.</p>"},{"location":"Wiki_Editor-Editor.html","title":"Wiki Editor Editor","text":"<p>gkgospo@amazon.co.uk</p> <p>Wikipedia editors are among the few remaining public servants who we can rely on to distinguish between truth and lies. Many of the first generation of editors are still around, but the future of human knowledge might depend on newcomers acquiring better understanding of how to do this effectively. Your task is to analyse what makes a Wikipedia editor effective, using the WikiData corpus to identify which patterns of editing deal with controversies, result in lasting consensus, and so on. Using the results of this analysis, create an automated interactive training guide for new editors, giving them feedback on their own patterns of response, and helping them identify how they might deal with different cases.</p>"},{"location":"Wild_Pet_Science.html","title":"Wild Pet Science","text":"<p>Francesco.Petrogalli@arm.com</p> <p>Children are often strong supporters of wildlife conservation, but also have pets of their own. The goal of this project is to help them engage with the science of wildlife tracking (via public data sources such as movebank.org), comparing that data to monitoring information that they collect themselves. Although Movebank uses GPS, sonar and other expensive techniques, you could use simple image analysis from a Raspberry Pi time-lapse camera to identify the position of a goldfish, a guinea pig or a hamster in its cage (you can use toy animals for the public demo). Children should be able to use the data they collect to make comparisons between their own pets and wild animals - this might include foraging behaviour, \"migrations\" or seasonal variation in activity.</p>"},{"location":"Wine_Goggles.html","title":"Replaced by Locally Augmented Retail","text":"<p>Client: Paul Bowes, Bacchanalia Team@winegod.co.uk</p> <p>One of the group project coordinators has an excellent memory for wine, but a poor memory for names. When he walks into Bacchanalia, his local wine shop, he (like many other customers) often says \"I'd like another bottle of that tasty Pinot Grigio you sold me last week\". Paul's response is always the same: \"It's my job to recommend the wine - it's your job to remember it\". A simple Android app could solve all our woes. Satisfied wine drinkers just photograph the label, perhaps with a tasting note to share with others. The app recognises the wine from the label, and sends an email to Paul for later reference. This can link to a reference site with notes of specific wines and regions each customer likes, and even build up a taste profile for recommendations. If the label recognition works well enough, it should be possible to point a web cam at the shelves, automatically recording what wines are still in stock, or automatically responding to urgent online queries in the spirit of the Trojan Room coffee pot.</p>"},{"location":"Wine_Goggles.html#problem-existing-product","title":"problem - existing product","text":"<p>This doesn\u2019t really provide the retail support that you were asking for, but it provides quite a lot of the features we discussed \u2026</p> <p>https://www.vivino.com/</p>"},{"location":"Workable_backups_for_small_offices.html","title":"Workable backups for small offices","text":"<p>rrw@semiramis.org.uk</p> <p>Considering replacing this with Auto-Archive</p> <p>Your client\u2019s office has half a dozen staff using networked PCs, who generate moderately large quantities of data - about 1Gb per month for each person, with permanent storage of maybe 8Tb each. They would like an off-site backup system. They are prepared to use USB hard discs to physically carry data off site, but really important data should be uplinked to somewhere in the cloud. You have to locate what has changed (these machines are in constant use, so you can\u2019t take the hard disk offline to scan it), and decide if it is important or duplicates existing material. Remember that it takes time to transfer data on their 1Gbit network, and even more to the net, with a connection of about 200Mbit down / 20Mbit up. You need to make the backups incremental, but with a naming / navigation scheme so that they can be retrieved by reference to the originals. You should also consider security.</p>"},{"location":"Workout_Help_with_Android_and_WearOS.html","title":"Workout Help with Android and WearOS","text":"<p>alexwilson@google.com</p> <p>Interval training, where the user performs an exercise for a set time before moving to the next, is increasingly popular but poorly supported by technology. Your task is to produe a proof-of-concept system allowing a user to easily create or download a workout schedule (\u201cpress ups for 20s, star jumps for 15s\u2026\u201d) on their phone and push it to a smartwatch app that then leads them through the session using visual output and haptics to indicate transitions. For those working out together we want to synchronise their watches to make a better social experience.\u00a0</p>"},{"location":"World_Craft.html","title":"World Craft","text":"<p>Google Earth, Google Maps and Google Streetview have turned surveillance data into commercial opportunities ranging from Deliveroo to Down My Street. But coverage tends to focus on sponsored business opportunities, rather than the livelihoods and communities of real women and men. Your task is to prototype an infrastructure of an interactive globe, where viewers can fluidly zoom in to connect to people's \"best self\", using their own verified images to represent their streets, homes and families. You\u2019ll have the opportunity to share ideas with a leading game developer, on how to make the world fairer and more peaceful.</p>"},{"location":"Youth-led_Future.html","title":"Youth led Future","text":"<p>Life](Curriculum_for_Life \"wikilink\") oli@curriculumforlife.com</p> <p>Most young people (in wealthy countries) now have their education controlled via virtual learning environments. But preparation for the future will involve challenging the curriculum, not just accepting the status quo. Your task is to create an alternative mobile browser that school students can use to construct a customised view which collaboratively annotates, critiques, adjusts and (re)evaluates the front end facilities of their school\u2019s VLE. Just like the school strikes for climate, it shouldn\u2019t be necessary to wait for permission, when creating youth-led alternatives to established skills and qualifications. This can\u2019t be just another social media platform - Facebook is clearly the wrong model!</p>"},{"location":"Zeitgeist_Map.html","title":"Zeitgeist Map","text":"<p>You land in a new country and suddenly you hear new songs on the radio, new songs being played in the club, and you hear people referencing artists you\u2019ve never heard of. People also dress differently and follow trends you never knew existed. Because of the internet and social media, you would expect most of the current trends to be present everywhere, but every country is still different in its own way. The goal of this project is to create a web-based world map with which one can easily visualize how popular different music trends are in certain countries. The user can select either a genre or an artist, and the map lights up with a gradient where they are mostly listened to. Or, conversely, a user selects a specific country (let\u2019s say their next study exchange destination) and can see all the current music trends: top songs, artists, genres. It would be great if the user could also play short snippets of the displayed songs and genres, and even visualize their popularity over time - to see how trends come and go. The basic idea can then also be expanded to include movies, series, and books, if there's time.</p>"},{"location":"Zombie_for_a_Day.html","title":"Zombie for a Day","text":"<p>Many people are vaguely aware that their home PC may be part of a botnet, but have no idea what this means in practice. The goal of this project is to create an educational botnet based on the Raspberry Pi to help people learn about computer security. Using Raspberry Pi means that there is minimal financial risk if things go wrong, and the owner of a node can reliably close it down simply by removing the SD card. Your job is to create a Raspberry Pi boot image that can be installed and used by a person having minimal technical knowledge - allowing them to \"take over\" in a controlled manner the Raspberry Pis of other volunteers (wherever they are), and simulate some of the behaviours of a botnet. A little bit of spooky paranoia wouldn't hurt - perhaps making mysterious sounds or unpredictably flashing lights after their node gets taken over. The distribution, location and status of the net should be visualised in a way that can be accessed from any web browser, but nodes should be able to find each other without any user intervention or central control. Of course, all this has to be achieved in a secure sand-boxed manner - real hackers shouldn't be allowed to get out of the sandbox!</p> <p>Category:Raspberry Pi</p>"},{"location":"Zoom_into_Books.html","title":"Zoom into Books","text":"<p>vladimir.vilde@dxan.co.uk</p> <p>Art and travel books often have beautiful images, but it\u2019s frustrating that you can\u2019t pinch to zoom as you would with a phone, to see arbitrarily high resolution details. The purpose of this project is to identify those times when a picture in a book or magazine corresponds to an existing high resolution image that is available online. Your Android app should work in augmented reality style, starting with a view of the book through the phone camera, but then seamlessly zooming by substituting high-resolution online data.</p>"},{"location":"Doug_Macfarlane/Emma_Salgard_Cunha.html","title":"Emma Salgard Cunha","text":"<ol> <li>REDIRECT Emma Salgard Cunha</li> </ol>"},{"location":"Ecosystem_game/visualisation.html","title":"Visualisation","text":"<ol> <li>REDIRECT Ecosystem Game</li> </ol>"},{"location":"Friend_meeting/tracking_application_for_the_Elderly.html","title":"tracking application for the Elderly","text":"<p>Austin.Donnelly@microsoft.com</p> <p>Elderly people sometimes need help to remain active and social. This project explores how a smartphone can arrange social gatherings/ meetings for them. This might include encouraging people to meet up by locating their friends, perhaps notifying them that a friend is nearby, and maybe even suggesting a location to meet. It may also be useful as a monitoring device for patients who make a habit of wandering off, distressing their family and carers. The user interface is important, since it must be accessible to those with less good eyesight and hand coordination. There will be little credit for boilerplate features such as user registration, account maintenance and database design, rather we expect to see innovative technical solutions to the user interface, messaging, security (privacy) and identity. The final goal is a Windows Phone 7 application that has been accepted into the Marketplace for general availability. Phones will be provided for testing.</p> <p>Note that Windows Phone 7 development requires .NET tools, so the development language for this project will either be C#, F# or VB.</p>"},{"location":"Future_First_/_JPMorgan.html","title":"JPMorgan","text":"<p>Careers from Here</p>"},{"location":"Lucid_/_Cycorp.html","title":"Cycorp","text":"<p>On 25 Oct 2017, at 04:17, Kay Firth-Butterfield kay@ai-austin.org wrote:</p> <p>Hi Alan,</p> <p>I don\u2019t think that Lucid would be able to work with you. Their focus has changed and I have moved.</p> <p>On 22 Oct 2017, at 16:53, Alan Blackwell afb21@cam.ac.uk wrote:</p> <p>I\u2019m just checking, after our exchanges for the past couple of years, that Lucid are not yet operating in the UK, and that there is not yet any interest in the possibility you and I discussed that Cambridge students might work with Lucid technology in their annual design project course?</p> <p>I do not use this email. Please contact me at kay@krwmail.com</p> <p>Original contact Kay Firth-Butterfield kay@lucid.ai</p> <p>Michael Witbrock at Cycorp and Michael Stewart of Lucid are interested</p>"},{"location":"Personal/national_mood_tracker.html","title":"National mood tracker","text":"<p>National wellbeing is the aggregate of the population mood, but it's difficult to know whether mood estimates are accurate or not. In fact, even individuals find it difficult to estimate how their mood has changed over time. The goal of this project is to automatically estimate a number of factors that effect national mood - news, weather, economic indicators - and aggregate these with personal mood estimates measured via your mobile phone's sensors. These could include movement or orientation data (facing into the wind?), feeds from a Facebook profile, or other data. If users are unsure what mood they are in, they can check their phone. And a longitudinal graph might help to review the year, or forecast important mood transitions - like when the end of term is approaching.</p>"}]}