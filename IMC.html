
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://cambridge-group-projects.github.io/website/IMC.html">
      
      
      
      
      <link rel="icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.15">
    
    
      
        <title>IMC - Cambridge - CS Group Projects</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.342714a4.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#2023-projects" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="Cambridge - CS Group Projects" class="md-header__button md-logo" aria-label="Cambridge - CS Group Projects" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Cambridge - CS Group Projects
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              IMC
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/cambridge-group-projects/website/wiki" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="Cambridge - CS Group Projects" class="md-nav__button md-logo" aria-label="Cambridge - CS Group Projects" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Cambridge - CS Group Projects
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/cambridge-group-projects/website/wiki" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="Intellectual_property.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Intellectual Property
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Clients
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Clients
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="Logistics_for_Clients.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Logistics for Clients
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Historic Design Briefs
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Historic Design Briefs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2024_list.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2024
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2023_list.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2023
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2022_list.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2022
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2021_list.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2021
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2020_list.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2020
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2019_list.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2019
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2018_list.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2018
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2017_list.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2017
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2016_list.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2016
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2015_list.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2015
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2014_-_final_list_of_design_briefs.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2014
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2013_-_final_list_of_design_briefs.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2013
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2010.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2010
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2009.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2009
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2008.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2008
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2006.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2006
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#2023-projects" class="md-nav__link">
    <span class="md-ellipsis">
      2023 projects
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2022-projects" class="md-nav__link">
    <span class="md-ellipsis">
      2022 projects
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2021-projects" class="md-nav__link">
    <span class="md-ellipsis">
      2021 projects
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2020-projects" class="md-nav__link">
    <span class="md-ellipsis">
      2020 projects
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2020 projects">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#develop-a-voice-assistant-for-trading" class="md-nav__link">
    <span class="md-ellipsis">
      Develop a voice assistant for trading
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#green-eyes-develop-environmentally-aware-goggles" class="md-nav__link">
    <span class="md-ellipsis">
      Green eyes: Develop environmentally aware goggles
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-ocean-cleanup" class="md-nav__link">
    <span class="md-ellipsis">
      The Ocean Cleanup
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2019-projects" class="md-nav__link">
    <span class="md-ellipsis">
      2019 projects
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2019 projects">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#previous-discussion" class="md-nav__link">
    <span class="md-ellipsis">
      (previous discussion)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2018-projects" class="md-nav__link">
    <span class="md-ellipsis">
      2018 projects
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2018 projects">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#earlier-discussion-for-2018" class="md-nav__link">
    <span class="md-ellipsis">
      Earlier discussion for 2018
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2017-proposals" class="md-nav__link">
    <span class="md-ellipsis">
      2017 proposals
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2017 proposals">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#24000-words-per-second" class="md-nav__link">
    <span class="md-ellipsis">
      24000 words per second
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-networks-in-fpga" class="md-nav__link">
    <span class="md-ellipsis">
      Neural Networks in FPGA
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shelved-for-2017-tamagotchi-brief" class="md-nav__link">
    <span class="md-ellipsis">
      Shelved for 2017: Tamagotchi Brief
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2016-projects" class="md-nav__link">
    <span class="md-ellipsis">
      2016 projects
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2016 projects">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#earlier-ideas" class="md-nav__link">
    <span class="md-ellipsis">
      earlier ideas
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2015-project" class="md-nav__link">
    <span class="md-ellipsis">
      2015 project:
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2014-as-imc-netherlands" class="md-nav__link">
    <span class="md-ellipsis">
      2014 (as IMC (Netherlands))
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/cambridge-group-projects/website/wiki/IMC/_edit" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


  <h1>IMC</h1>

<p>Careers Europe <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#67;&#97;&#114;&#101;&#101;&#114;&#115;&#69;&#117;&#114;&#111;&#112;&#101;&#64;&#105;&#109;&#99;&#46;&#99;&#111;&#109;">&#67;&#97;&#114;&#101;&#101;&#114;&#115;&#69;&#117;&#114;&#111;&#112;&#101;&#64;&#105;&#109;&#99;&#46;&#99;&#111;&#109;</a></p>
<h2 id="2023-projects">2023 projects</h2>
<ul>
<li><a href="ModularSynth.io" title="wikilink">ModularSynth.io</a></li>
</ul>
<h2 id="2022-projects">2022 projects</h2>
<p>Plan to propose three, for selection of two</p>
<p>Admin contact for 2022 will be Sanne Cuperus <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#83;&#97;&#110;&#110;&#101;&#46;&#67;&#117;&#112;&#101;&#114;&#117;&#115;&#64;&#105;&#109;&#99;&#46;&#99;&#111;&#109;">&#83;&#97;&#110;&#110;&#101;&#46;&#67;&#117;&#112;&#101;&#114;&#117;&#115;&#64;&#105;&#109;&#99;&#46;&#99;&#111;&#109;</a></p>
<h2 id="2021-projects">2021 projects</h2>
<p>Confirmed:</p>
<ul>
<li><a href="Aerial_Video_Selfies" title="wikilink">Aerial Video Selfies</a></li>
</ul>
<!-- -->

<ul>
<li><a href="Remote_Reading" title="wikilink">Remote Reading</a></li>
</ul>
<p>Original suggestions from Ben Catterall <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#98;&#101;&#110;&#46;&#99;&#97;&#116;&#116;&#101;&#114;&#97;&#108;&#108;&#64;&#105;&#109;&#99;&#46;&#99;&#111;&#109;">&#98;&#101;&#110;&#46;&#99;&#97;&#116;&#116;&#101;&#114;&#97;&#108;&#108;&#64;&#105;&#109;&#99;&#46;&#99;&#111;&#109;</a>:</p>
<p>Drone assisted filming Drones have become an essential tool for many
filmmakers, but they require manual control usually from additional
staff as the subject cannot operate the drone themselves. This
constraint also limits the number of perspectives that can be captured
in a scene to the number of pilots available. There is great value in
reducing the required number of staff as well as capturing multiple
views on a single scene without hassle. A swarm of drones that are aware
of their surroundings, including each other, and basic cinematography
setups could achieve such results. Develop a solution for capturing
video recordings of moving subjects such as a cyclist or rower from
multiple drones. The drones should be aware of their surroundings, make
sure to avoid filming each other and to deliver tasteful and usable
footage. A minimum viable product would consist of a drone filming and
following an object, perhaps using a Bluetooth tracker. Support for more
drones, each providing footage with a specific perspective, could then
be added as an extension. You will be provided with a drone.</p>
<p>Smart Fridge Food waste is a major part of the impact of agriculture on
climate change, amounting to between one-third and one-half of all food
produced. This problem can be tackled at home, by reducing the amount of
out-of-date food that is thrown away. Your task is to design a device
that helps users manage the food in their fridge. It should notify users
when food is about to go out of date, assist them with finding tasteful
recipes for using their food, and consequently help them reduce their
food waste. You will be provided with a tablet.</p>
<p>Remote reading The ability to read is the foundation of a person's
education, transforming children into life-long independent learners.
Especially in the early stages of learning, human-to-human interaction
is critical to the teaching process.</p>
<p>The focus of this project is to design an interactive remote reading
app. It should enable children to connect with their teachers and/or
family members by allowing them to read a story together. This project
will likely involve designing an interactive reading interface, as well
as building the back-end video/audio streaming service. Possible
extensions can include support for multiple languages with live
translation to better connect non-native speakers and/or facilitate
language learning. You will be provided with a tablet.</p>
<h2 id="2020-projects">2020 projects</h2>
<p>Confirmed:</p>
<ul>
<li><a href="Green_Eyes" title="wikilink">Green Eyes</a></li>
<li><a href="Trading_Assistant" title="wikilink">Trading Assistant</a></li>
</ul>
<p>Three possibles in discussion:</p>
<h3 id="develop-a-voice-assistant-for-trading">Develop a voice assistant for trading</h3>
<p>Not all the trading happens on exchange, sometimes counterparties trade
directly, with human-to-human communication. For such trading humans use
their most natural interface - voice. What is our purpose? We want to
automate one side of the process using modern technologies (voice
recognition, natural language processing and voice production). What
will be my task? Create a service which holds market data and shares the
data on demand in a human-like manner.</p>
<h3 id="green-eyes-develop-environmentally-aware-goggles">Green eyes: Develop environmentally aware goggles</h3>
<p>We live in a consumer society, often buying more things than we really
need. Everything we buy has some environmental cost. For example, it
takes 2700 liters of water to make one cotton T-shirt. If your garment
is made out of polyester, it will take it 20 – 200 years to decompose.
What is our purpose? It would be great if we were all a bit more aware
of the impact we can have on the environment by buying less things or
buying things that are more environmentally friendly. What will be my
task? Develop a HoloLens application that given a picture of an item
calculates the impact of that item on the environment.</p>
<h3 id="the-ocean-cleanup">The Ocean Cleanup</h3>
<p>Over 5 trillion pieces of plastic currently litter the ocean. The
largest collection is in the Great Pacific Garbage Patch. Unfortunately,
such statistics are rather intangible. What is our purpose? We want to
bring home to people how devastating the impact on our actually oceans
is by letting them experience it themselves. What will be my task?
Design a virtual reality experience of the collection process allowing
users to interact with the rubbish collected by System 001.</p>
<h2 id="2019-projects">2019 projects</h2>
<p>Two projects confirmed:</p>
<ul>
<li><a href="Eyes_on_the_Road" title="wikilink">Eyes on the Road</a></li>
</ul>
<!-- -->

<ul>
<li><a href="Eyes_in_the_Sky" title="wikilink">Eyes in the Sky</a></li>
</ul>
<h4 id="previous-discussion">(previous discussion)</h4>
<p>If the program allows for it, we would like to be the client for two
groups again this year as we would like to give this an extra dimension
by soft-linking the two projects together:</p>
<ul>
<li>Group 1 would design a project where the output is a driving
  mindstorms car (we are contemplating a project driving a car with VR
  experience - storyline remote driving a car).</li>
</ul>
<!-- -->

<ul>
<li>Group 2 would design a project where the input is a driving mindstorms
  car (we are contemplating a project with a drone following a car with
  wifi/bluetooth/visual beacon - storyline safety monitoring of high
  value transport).</li>
</ul>
<p>The success of the groups does not depend on each other (we have
multiple mindstorms sets). Both projects can be developed, presented and
demonstrated independently but a combined demonstration (probably not
during the public demonstrations sessions) would be awesome!</p>
<h2 id="2018-projects">2018 projects</h2>
<p><a href="Wearable_house_control" title="wikilink">Wearable house control</a></p>
<p><a href="Autonomous_highway_system" title="wikilink">Autonomous highway system</a></p>
<h3 id="earlier-discussion-for-2018">Earlier discussion for 2018</h3>
<p>• Automated Highway System</p>
<p>Highway congestion is a never ending problem. One way to increase the
throughput of the highway is to group vehicles into platoons to shorten
the distance between two consecutive cars. Further advantages of vehicle
platooning are decreased fuel consumption and emissions and increased
safety and comfort. Design an automated platooning system in which
multiple vehicles autonomously follow the leader. Safety is of paramount
importance, each vehicle should do its best to avoid collisions.</p>
<p>Tools: 3 - 4 sets of Lego Windstorms Responsible: Jan Kis
jan.kis@imc.com</p>
<p>Feedback: It looks like fun, and autonomous vehicles are a timely area
of interest. It’s nice for both students and the demo day audience to
have something concrete to see, so I’m certainly happy to base something
on Mindstorms. However, we had a swarm robot project last year, in which
relatively trivial issues (mechanical reliability, sensor accuracy,
battery charge cycles) dominated the computing questions. I wonder if we
might consider a hybrid system design, in which the students simulate
larger platoons in software, and build a mechanical testbed (still using
Lego) to evaluate or calibrate the inter-vehicle dynamics?</p>
<p>• Autorad</p>
<p>A recent article in New Yorker magazine has explored the triumphs of
algorithms in the diagnostic arena. Teleradiology is generally regarded
as being the forerunner in employing technology to automate and
streamline workflows to better quality of care, more accurate diagnosis
and better treatment outcomes. Design a service that would receive DICOM
studies and identify Subdural hematomas in CT scans and return its
findings. This service would serve as a diagnostic assistant to a
radiologist and provide a second level of confidence on the findings.
All relevant DICOM data should be extracted and used to create studies
and associated reports. Bonus: Ascertain the technical accuracy of the
scan (position, dosage etc)</p>
<p>Tools: An extensive medical image source is required for this project.
Responsible: Arindam Paul arindam.paul@imc.com</p>
<p>Feedback: If I understand correctly, the core of this appears to be a
relatively straightforward computer vision application, which would
require training with a substantial dataset of segmented and labelled
images. Did you have access to a suitable dataset, or would we need to
find a source?</p>
<p>• GreenPi</p>
<p>Large-scale agriculture has the unenviable task of feeding the world’s
ever-expanding population which is gradually headed towards unimaginable
numbers. Food as we know it today will become a scarcer and far more
expensive commodity. Sustainable home gardens can make a difference like
all small measures do but not all of us have the privilege of the space
required. With solar panels, raspberry pi’s, fans and other sensors
create a small greehouse that could be packaged and sold for an
affordable amount. The kit should be easy to setup and mostly automated
in its operation besides the initial setup effort. There should be an
accompanying app/web page to guide the user through setting up the
greenhouse and monitoring all its operations and health of the plants
inside. Given the time challenges of this project I propose growing
radishes, green beans and peas</p>
<p>Tools: All required sensors, solar panels and raspberry pi kits will be
supplied Responsible: Arindam Paul arindam.paul@imc.com</p>
<p>Feedback: Are you a keen gardener? As you note, timescale is a problem -
what kinds of plants grow indoors in February? I suspect that the
control regime for successful plant growing is fairly simple - the more
light the better, and water delivery to maintain optimum water content.
Could we perhaps use one or two larger plants, and do more intrusive
condition monitoring (tissue conductivity, internal water content,
mechanical properties of the plant fibres)?</p>
<p>• Smart House</p>
<p>Over the last years smart IOT hardware has become main stream and
affordable to consumers. Commonly seen smart electronics in average
households may consist of smart lights, smart solar panels, smart
curtains or smart thermostats. Together with a smart hub a consumer can
control all smart devices. However, the smart devices only perform their
own tasks and are unaware of other devices. A smart house should combine
multiple smart devices. Create a service that controls all smart devices
together. For example, download sun rise and sun set times and
automatically switch on lights and close curtains. There should also be
a UI that can be loaded on a web browser or as app for mainstream OS'es.</p>
<p>Tools: IOT hardware / smartwatch Responsible: William Bakker
william.bakker@imc.com</p>
<p>Feedback: This is a rapidly growing area, with products such as IoTool
and IFTTT delivering this kind of generic functionality. We might want
to think of a slightly more specific use case, or interaction approach,
selected for convenient demonstration to the audience we will get at our
public event in March. From experience, this means avoiding room
thermostat functionality (because it’s hard to vary the temperature of
our room) and other functionality with time constants greater than a few
minutes (so not relying on sunset time etc). I noticed with interest
your idea to integrate smartwatch functionality - I wonder whether we
might shift this toward some kind of body-based (single user) or
collaborative (multi-device) policy specification language. Did you have
a particular smartwatch model in mind?</p>
<p>• Geographical Pattern Recognition</p>
<p>Within the next few years, 5G will be the successor of 4G. This
introduces the need for new placement of transmission towers. The United
Kingdom has been fully covered by high quality satellite images. This
opens the opportunity to optimize this placement problem. Analyze the
geographical properties from the satellite images where to find suitable
locations. Then, cross reference with average property prices to
determine the optimal location. The user interface should show a
graphical overlay of signal coverage and cost.</p>
<p>Tools: (license for) high quality satellite data. Responsible: William
Bakker william.bakker@imc.com</p>
<p>Feedback: I’ve had an intern this summer using UK government open data
from Ordnance Survey, which might be more appropriate than satellite
imagery. However, they have struggled with licensing terms. Data is
available for free, but via interfaces built to resist large-scale
scraping. I like the idea of optimising by property price - perhaps you
were thinking of cost of acquiring land for tower placement (though my
experience is that planning permission, rather than land acquisition, is
the main constraint). Perhaps even more interesting would be to optimise
coverage according to the income of the people who live there, and
charge higher rates for the service? A geographical auction optimisation
algorithm seems pretty interesting.</p>
<p>• Proof-of-work for crypto currencies</p>
<p>A proof of work is a piece of data which is difficult (costly,
time-consuming) to produce but easy for others to verify, and is used to
define the requirement for the generation of a new set of transactions
("block") to be added to a distributed transaction database ("block
chain"). In the case of Bitcoin this is a hash algorithm (“hashcash”)
which requires a minimum level of computing power to solve. This is
referred to as the process of ‘mining’ which ultimately controls the
rate of deflation/inflation of the crypto currency. The Bitcoin mining
concept is not completely without risk, eg what happens if the cost of
mining would increase significantly due to fossil power shortage, or
mining has become extremely easy with the use of quantum computers? As
proof of work can be anything, we’d like the students to come up with a
new, original and difficult to solve problem which can be used to add
new blocks to the block chain. It should require effort to do, protected
from exploitation and sustainable over time.</p>
<p>• Block chain for OTC trading</p>
<p>Another idea we discussed was to use the Etheruem platform, and set up a
private net, which can be used for OTC (Over The Counter) trading. OTC,
or off-exchange, trading is directly between two parties and often
non-electronic. Therefore likely to result in discrepancies between
buyer and seller of what was really agreed as part of the trade. A
platform based on an immutable block chain mechanism completely reduces
this risk including the need to reconcile after the fact between buyer,
seller and the clearing bank.</p>
<p>Design your own crypto currency Alternatively we could ask students to
define a new crypto currency from scratch, although that might be a lot.</p>
<p>Responsible: Renier Eijkelestam – renier.Eijkelestam@imc.com</p>
<p>Feedback: Your proposals to work with block chain technologies seem a
good idea to me, and likely to inspire students. We did include a
block-chain based design brief two years ago, with your colleague Jan
Kis (copied here) as the client, but perhaps a little ahead of the curve
at that time, and students struggled to come up with an innovative
concept. You might be interested to compare the design brief that we
used then:
<a href="https://wiki.cam.ac.uk/cl-design-projects/Digital_Currency_for_Public_Good">https://wiki.cam.ac.uk/cl-design-projects/Digital_Currency_for_Public_Good</a></p>
<p>I still like the idea that proof-of-work can be something that delivers
public good, as opposed to the Bitcoin proof-of-work, which seems
designed expressly to waste natural resources on as large a scale as
possible. Do you think that we might be able to come up with a concept
along these lines? If you see Jan, you might ask his opinion. I agree
with your specification of requirements as the need for a "new, original
and difficult to solve problem”. It’s a great research challenge, but
experience is that these undergraduate teams need a little more guidance
(or constraint) toward a particular direction.</p>
<h2 id="2017-proposals">2017 proposals</h2>
<p>Confirmed:</p>
<p><a href="Hololens_Escape_Room" title="wikilink">Hololens Escape Room</a></p>
<p>More ideas:</p>
<p><a href="Neural_Guide" title="wikilink">Neural Guide</a></p>
<h4 id="24000-words-per-second">24000 words per second</h4>
<p>Ben Catterall : ben.catterall@imc.com</p>
<p>Many fields in machine learning, from image recognition to machine
translation have recently received a tremendous boost using deep
learning. Deep architectures have sparked a renewed interest in
artificial intelligence, and resulted in a lot of cool applications. It
has also arrived together with a new wave of peer-reviewed research,
where people share and publish all of their code online. Most big
companies race to provide their pre-trained models online for free. In
this project we will focus on automatic video captioning, and the aim is
to build a prototype system for a real-time captioning system, using
already published research. The resulting product could be used by
visually impaired people, or to create automatic tags on instagram.</p>
<p>Feedback:</p>
<p>Quite a lot of our students enjoy playing around with pre-trained deep
neural nets, so this is certainly feasible. However, it seems at present
like a one-person project, and would have to be expanded to suit work
from a team. We already have some projects planned for this year that
involve training a deep net, but this involves some ingenuity in
identifying suitably labelled training data, as well as getting hold of
a machine suitable for running the GPU-intensive deep learning
frameworks that are currently popular.</p>
<p>Do you want to provide a reference to the specific piece of published
research that you thought might be applied, and we can see where we
might go from there?</p>
<p>Response:</p>
<p>The image captioning is from Andrej Karpathy:</p>
<p><a href="http://cs.stanford.edu/people/karpathy/deepimagesent/">http://cs.stanford.edu/people/karpathy/deepimagesent/</a></p>
<p>I think in order to create an interesting application from this
research, we can extend the problem to include audio captions through a
mobile application. The students will have to:</p>
<p>- Write a server application that accepts images, and produces
captions - Convert captions into audio files - Write a mobile
application which shoots images and uploads to server - Replays the
audio that comes back from the server</p>
<p>I believe this is already not a one person project.</p>
<p>If you want we can further extend the project to include training of
custom captions as well. This can be used to train an 'audio guide' for
a particular location for example. We can even think about creating a
meta-trainer which receives images and captions for a particular
building(museum, or even the computer lab), and automatically forms an
audio guide. But personally, I think we are entering a dangerous area,
where the project becomes prone to failure.</p>
<p>More:</p>
<p>My understanding is that it’s relatively straightforward to run the
Karpathy libraries on novel images using one of their trained models. I
agree that it would be much more of a challenge to collect a
sufficiently large dataset (and computational resources) to train your
own model.</p>
<p>As you say, there is far more chance of failure if doing something other
than image labelling, which is already a research topic rather than a
design project. Nevertheless, we are taking a chance on this with the
project brief I sent you - and I’m hoping that looking at text rather
than image encoding will make that one feasible. I got one of our
machine learning profs to check it out for sanity.</p>
<p>I would have thought that converting the captions into audio is also an
API-calling job, rather than involving any substantial software
engineering. I’ve used Festival for this:
<a href="http://www.cstr.ed.ac.uk/projects/festival/">http://www.cstr.ed.ac.uk/projects/festival/</a></p>
<p>I think the issue with both deep learning image recognition techniques
and speech synthesis is that in both cases, there are fairly good
libraries and APIs that allow you to create acceptable results with a
few lines of Python, while any improvement over the off-the-shelf
libraries is way beyond the capability of undergrads.</p>
<h4 id="neural-networks-in-fpga">Neural Networks in FPGA</h4>
<p>Taylan.Toygarlar@imc.com</p>
<p>We are entering a new era in computing, where the services provided are
becoming more and more dependent on machine learning and artificial
intelligence, with deep learning at the forefront of this new gold-rush.
The introduction of deep learning architectures were only possible due
to the use of GPUs, and they have done a great job training more and
more complex models. However, FPGAs offer huge benefits over GPUs in
terms of power savings, which is crucial when web-scale applications are
considered. There are many exciting developments in this field, but
unfortunately, contrary to GPUs, there are close to no public tooling
available for FPGAs. We would like to develop a code generator, which
takes as input a commonly used neural-network definition file, and spits
out fpga code. This project could potentially help fuel the next
generation systems for which all of us interact with daily.</p>
<p>Feedback:</p>
<p>I've discussed with a couple of the staff who teach our hardware course,
and they confirm that the dev boards the students use do have FPGA that
might be used here.</p>
<p>I wasn't suggesting online learning - rather that they might see how
fast they can train a simple image classifier.</p>
<p>Our research team have recently implemented something along these lines.
Here are some relevant papers:</p>
<p>Neural nets in custom hardware:
<a href="http://www.cl.cam.ac.uk/~atm26/papers/fccm2012-bluehive.pdf">http://www.cl.cam.ac.uk/~atm26/papers/fccm2012-bluehive.pdf</a></p>
<p>Custom hardware v vector processing
<a href="http://www.cl.cam.ac.uk/~atm26/pubs/FPL2013-BlueVec.pdf">http://www.cl.cam.ac.uk/~atm26/pubs/FPL2013-BlueVec.pdf</a></p>
<p>Video and background
<a href="http://www.cl.cam.ac.uk/research/comparch/research/bimpa.html">http://www.cl.cam.ac.uk/research/comparch/research/bimpa.html</a></p>
<p>An undergrad group could perhaps work with their code, rather than build
something from scratch?</p>
<h4 id="shelved-for-2017-tamagotchi-brief">Shelved for 2017: Tamagotchi Brief</h4>
<p>Jan Kis : jan.kis@imc.com</p>
<p>(‘Creative’) Pokemon Go took the world by storm. Now it’s your turn!
Remember those cute, egg-shaped devices with the dancing critters you
all played with when you were younger? Well, this task will involve the
exciting opportunity of creating an interactive online Tamagotchi world!
Your aim is to entice users to explore the fascinating concept of
optimal parameter selection, critical to many real world problems such
as Machine Learning and automated trading, through their Tamagotchi’s.
Develop a mobile application allowing users to view their Tamagotchi and
exchange limited resources with each other by agreeing a fair value for
their exchange. Once acquired, users should be able to modify the
appearance of their Tamagotchi using these resources. Users will thus
need to carefully optimize their basket of resources to build their
ultimate Tamagotchi. They want to recreate that incredible wig they saw
at last night’s bop but only have two bundles of cloth? Well, they trade
six spindles of thread for two bundles of cloth, apply some suspect
sowing skills and ta dah!</p>
<p>(Formal) Optimal selection of parameters is an important aspect of many
exciting real world problems from Machine Learning to automated trading
in world markets. This project aims to get users to explore this
concept. The task is to build an interactive online mobile application
to enable users to view and build their ultimate Tamagotchi. Users will
need to exchange limited resources with each other by coming to an
agreement about a fair value. These resources can then be used to alter
the appearance of their Tamagotchi. Consequently, users will need to
carefully select their optimal basket of resources.</p>
<p>Feedback:</p>
<p>Thanks for your “Tamagotchi” suggestion for the Cambridge design project
course. Sorry that I’ve left yours to last – I have been discussing
other projects with your colleagues that were either more obvious or
more problematic.</p>
<p>My initial reaction was that current undergraduates might be unlikely to
remember Tamagotchi, so an alternative creature focus might have been
necessary. Pokemon would be the obvious choice.</p>
<p>We do already have a design brief for next year that shares some
similarities with your proposal, so if we did do something in this area,
I’d like to reduce surface resemblance:
<a href="https://wiki.cam.ac.uk/cl-design-projects/Learn_to_be_an_Alien">https://wiki.cam.ac.uk/cl-design-projects/Learn_to_be_an_Alien</a></p>
<p>I noted the market-making aspect of your more formal version. I found
this reminiscent of other market-making projects we have done in the
past, such as these two:</p>
<p><a href="https://wiki.cam.ac.uk/cl-design-projects/Scrobble_Exchange:_A_massively_multiplayer_game">https://wiki.cam.ac.uk/cl-design-projects/Scrobble_Exchange:_A_massively_multiplayer_game</a></p>
<p><a href="https://wiki.cam.ac.uk/cl-design-projects/AI_racing_market">https://wiki.cam.ac.uk/cl-design-projects/AI_racing_market</a></p>
<p>We don’t yet have a “market” proposal for this year, so could perhaps
think of a Pokemon Go variant that included this aspect?</p>
<h2 id="2016-projects">2016 projects</h2>
<ul>
<li><a href="Fly-past_Finance" title="wikilink">Fly-past Finance</a></li>
</ul>
<!-- -->

<ul>
<li><a href="Digital_Currency_for_Public_Good" title="wikilink">Digital Currency for Public
  Good</a></li>
</ul>
<h3 id="earlier-ideas">earlier ideas</h3>
<p>Maksym Korotkiy Maksym Korotkiy <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#77;&#97;&#107;&#115;&#121;&#109;&#46;&#75;&#111;&#114;&#111;&#116;&#107;&#105;&#121;&#64;&#105;&#109;&#99;&#46;&#110;&#108;">&#77;&#97;&#107;&#115;&#121;&#109;&#46;&#75;&#111;&#114;&#111;&#116;&#107;&#105;&#121;&#64;&#105;&#109;&#99;&#46;&#110;&#108;</a></p>
<p>Prototype a 2D visualization for an execution of a genetic algorithm
(GA) applied to a multi-dimensional search problem. The visualization
should provide insights into all stages of GA (selection, crossover,
mutation) as well as into evolution of candidate solutions. We can
assume that number of dimensions is between 10 and 50, number of
candidate solutions (population size) is 500 and number of generations
is around 100. The visualization should make it easy to understand
internal workings of GA and to show an impact of different selection and
crossover strategies or mutation rates. Students can use any general GA
implementation and can apply it to any multi-dimensional search problem.</p>
<p>Taylan Toygarlar <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#84;&#97;&#121;&#108;&#97;&#110;&#46;&#84;&#111;&#121;&#103;&#97;&#114;&#108;&#97;&#114;&#64;&#105;&#109;&#99;&#46;&#110;&#108;">&#84;&#97;&#121;&#108;&#97;&#110;&#46;&#84;&#111;&#121;&#103;&#97;&#114;&#108;&#97;&#114;&#64;&#105;&#109;&#99;&#46;&#110;&#108;</a></p>
<p>Radmilo Racic <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#114;&#97;&#100;&#109;&#105;&#108;&#111;&#46;&#114;&#97;&#99;&#105;&#99;&#64;&#105;&#109;&#99;&#46;&#110;&#108;">&#114;&#97;&#100;&#109;&#105;&#108;&#111;&#46;&#114;&#97;&#99;&#105;&#99;&#64;&#105;&#109;&#99;&#46;&#110;&#108;</a></p>
<p>Visualization techniques for large set of financial markets data This
project develops techniques for visualizing multiple data sets of
financial data, including ticker states of global futures and
significant stocks, bonds and currencies. The end goal is not only to
unearth hidden relationships and correlations between global markets but
also to convey trader sentiment and pin point market moving trades. As
global market landscape is quite complex and correlated, we will be
using Oculus Rift as the principal display tool. Students will be
provided with data from Eurostoxx, DAX, CAC, KOSPI, Nikkei, ES, EUR/USD,
T-Note, GBL, etc.</p>
<h2 id="2015-project">2015 project:</h2>
<ul>
<li><a href="Building_the_Matrix" title="wikilink">Building the Matrix</a></li>
</ul>
<h2 id="2014-as-imc-netherlands">2014 (as <a href="IMC_(Netherlands)" title="wikilink">IMC (Netherlands)</a>)</h2>
<ul>
<li><a href="Virtual_Reality_Trading_Desk" title="wikilink">Virtual Reality Trading
  Desk</a></li>
</ul>
<!-- -->

<ul>
<li><a href="Algo-Trading_Game" title="wikilink">Algo-Trading Game</a></li>
</ul>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": ".", "features": ["content.action.edit"], "search": "assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="assets/javascripts/bundle.56ea9cef.min.js"></script>
      
    
  </body>
</html>